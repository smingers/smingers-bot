name: Run Metaculus Forecasting Bot

on:
  workflow_dispatch:
    inputs:
      test_question_id:
        description: 'Single question ID to test (leave empty for normal tournament run)'
        required: false
        type: string
      mode:
        description: 'Run mode for single question test'
        required: false
        type: choice
        default: 'live'
        options:
          - live
          - preview
          - test
  schedule:
    - cron: "*/30 * * * *"  # Every 30 minutes

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false  # Don't cancel in-progress forecasts

# =============================================================================
# JOB 1: Quick API check for new questions (runs in ~10s)
# Skips the full forecast job if there's nothing to do.
# =============================================================================
jobs:
  check:
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      has_work: ${{ steps.check_new.outputs.has_work }}
    steps:
      - name: Check for new questions
        id: check_new
        env:
          METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
        run: |
          # Manual dispatch with test question always has work
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ github.event.inputs.test_question_id }}" ]; then
            echo "has_work=true" >> $GITHUB_OUTPUT
            echo "Manual dispatch with test question — skipping API check"
            exit 0
          fi

          # Get user ID for forecast lookup
          USER_ID=$(curl -sf -H "Authorization: Token $METACULUS_TOKEN" \
            "https://www.metaculus.com/api/users/me/" | jq -r '.id')
          echo "User ID: $USER_ID"

          HAS_WORK=false

          for TOURNAMENT in 32916 minibench; do
            sleep 1.5  # Rate limiting

            # Get open question IDs (filtered by default_project)
            if [ "$TOURNAMENT" = "minibench" ]; then
              JQ_FILTER='.results[] | select(.projects.default_project.slug == "minibench") | .id'
            else
              JQ_FILTER=".results[] | select(.projects.default_project.id == $TOURNAMENT) | .id"
            fi

            OPEN_IDS=$(curl -sf -H "Authorization: Token $METACULUS_TOKEN" \
              "https://www.metaculus.com/api/posts/?tournaments=$TOURNAMENT&statuses=open&limit=100&order_by=scheduled_close_time" \
              | jq -r "$JQ_FILTER" | sort -n)
            OPEN_COUNT=$(echo "$OPEN_IDS" | grep -c '[0-9]' || true)

            sleep 1.5

            # Get my forecasted question IDs for this tournament
            MY_IDS=$(curl -sf -H "Authorization: Token $METACULUS_TOKEN" \
              "https://www.metaculus.com/api/posts/?forecaster_id=$USER_ID&tournaments=$TOURNAMENT&limit=500" \
              | jq -r '.results[].id' | sort -n)
            MY_COUNT=$(echo "$MY_IDS" | grep -c '[0-9]' || true)

            # Find IDs in OPEN but not in MY
            NEW_COUNT=$(comm -23 <(echo "$OPEN_IDS") <(echo "$MY_IDS") | grep -c '[0-9]' || true)

            echo "$TOURNAMENT: $OPEN_COUNT open, $MY_COUNT forecasted, $NEW_COUNT new"

            if [ "$NEW_COUNT" -gt 0 ]; then
              HAS_WORK=true
            fi
          done

          echo "has_work=$HAS_WORK" >> $GITHUB_OUTPUT

          if [ "$HAS_WORK" = "false" ]; then
            echo "No new questions in any tournament — skipping forecast job"
          fi

  # =============================================================================
  # JOB 2: Full forecast pipeline (only runs if check found new questions)
  # =============================================================================
  forecast:
    needs: check
    if: needs.check.outputs.has_work == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
        timeout-minutes: 2
        continue-on-error: true

      - name: Retry poetry install on failure
        if: failure()
        run: |
          sleep 30
          pip install poetry
          poetry config virtualenvs.create true
          poetry config virtualenvs.in-project true

      - name: Load cached venv
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        id: install_deps
        continue-on-error: true
        run: poetry install --no-interaction --no-root

      - name: Retry install on failure (clear cache)
        if: steps.install_deps.outcome == 'failure'
        run: |
          echo "First install failed, clearing cache and retrying..."
          rm -rf .venv
          poetry cache clear --all -n
          poetry install --no-interaction --no-root

      # ============================================================
      # BROWSER SCRAPING SUPPORT (Xvfb + Playwright)
      # Required for scraping community predictions on meta-questions
      # ============================================================
      - name: Install Xvfb
        run: sudo apt-get update && sudo apt-get install -y xvfb

      - name: Install Playwright Chromium
        run: poetry run playwright install --with-deps chromium

      # ============================================================
      # TEST MODE: Single question forecast
      # ============================================================
      - name: Forecast single test question
        if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.test_question_id != '' }}
        run: |
          poetry run python main.py \
            --question ${{ github.event.inputs.test_question_id }} \
            --mode ${{ github.event.inputs.mode || 'live' }}
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
          ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
          ASKNEWS_CLIENT_SECRET: ${{ secrets.ASKNEWS_CLIENT_SECRET }}
          SERPER_API_KEY: ${{ secrets.SERPER_API_KEY }}
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}

      # ============================================================
      # AIB TOURNAMENTS (ENABLED)
      # ============================================================

      - name: Forecast spring-aib-2026
        if: ${{ github.event_name == 'schedule' || github.event.inputs.test_question_id == '' }}
        id: forecast_spring_aib
        continue-on-error: true
        run: |
          poetry run python run_bot.py \
            --tournament 32916 \
            --question-selection new-only \
            --limit 50
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
          ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
          ASKNEWS_CLIENT_SECRET: ${{ secrets.ASKNEWS_CLIENT_SECRET }}
          SERPER_API_KEY: ${{ secrets.SERPER_API_KEY }}
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}

      - name: Forecast MiniBench
        if: ${{ github.event_name == 'schedule' || github.event.inputs.test_question_id == '' }}
        id: forecast_minibench
        continue-on-error: true
        run: |
          poetry run python run_bot.py \
            --tournament minibench \
            --question-selection new-only \
            --limit 50
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
          ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
          ASKNEWS_CLIENT_SECRET: ${{ secrets.ASKNEWS_CLIENT_SECRET }}
          SERPER_API_KEY: ${{ secrets.SERPER_API_KEY }}
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}

      # ============================================================
      # OPTIONAL TOURNAMENTS (DISABLED - uncomment to enable)
      # These use 1x/week re-forecasting to manage costs
      # ============================================================

      # - name: Forecast Metaculus Cup
      #   run: |
      #     poetry run python run_bot.py \
      #       --tournament 32917 \
      #       --question-selection reforecast \
      #       --reforecast-days 7 \
      #       --limit 20
      #   env:
      #     OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      #     METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
      #     ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
      #     ASKNEWS_CLIENT_SECRET: ${{ secrets.ASKNEWS_CLIENT_SECRET }}

      # - name: Forecast Main Site
      #   run: |
      #     poetry run python run_bot.py \
      #       --tournament main-site \
      #       --question-selection reforecast \
      #       --reforecast-days 7 \
      #       --limit 10
      #   env:
      #     OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      #     METACULUS_TOKEN: ${{ secrets.METACULUS_TOKEN }}
      #     ASKNEWS_CLIENT_ID: ${{ secrets.ASKNEWS_CLIENT_ID }}
      #     ASKNEWS_CLIENT_SECRET: ${{ secrets.ASKNEWS_CLIENT_SECRET }}

      # ============================================================
      # COMMIT FORECAST DATA
      # Commits any new forecast artifacts back to the repo
      # ============================================================
      - name: Commit forecast data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/
          if git diff --staged --quiet; then
            echo "No new forecast data to commit"
          else
            git commit -m "Add forecast data from automated run

          Run: ${{ github.run_id }}
          Triggered by: ${{ github.event_name }}"
            git pull --rebase
            git push
          fi

      # ============================================================
      # FAIL IF ANY FORECASTS HAD ERRORS
      # This runs after data is committed, so we preserve artifacts
      # but still get a red X on the workflow
      # ============================================================
      - name: Check for forecast failures
        if: ${{ steps.forecast_spring_aib.outcome == 'failure' || steps.forecast_minibench.outcome == 'failure' }}
        run: |
          echo "::error::One or more forecast steps failed!"
          echo ""
          if [ "${{ steps.forecast_spring_aib.outcome }}" == "failure" ]; then
            echo "::error::spring-aib-2026 had failures - check logs for SUBMISSION ERRORS or EXTRACTION ERRORS"
          fi
          if [ "${{ steps.forecast_minibench.outcome }}" == "failure" ]; then
            echo "::error::MiniBench had failures - check logs for SUBMISSION ERRORS or EXTRACTION ERRORS"
          fi
          echo ""
          echo "To retry failed questions manually:"
          echo "  python main.py --question <QUESTION_ID> --mode live"
          exit 1
