# Metaculus AI Forecasting Bot Configuration
# Panshul42 Integration - 5-Agent Ensemble Pipeline

# =============================================================================
# RUN MODE
# =============================================================================
# Controls model selection and submission behavior:
#   - "dry_run": Cheap models (Haiku), no submission - for testing pipeline
#   - "dry_run_heavy": Production models, no submission - for evaluating quality
#   - "production": Production models, submits to Metaculus
#
# Override with --mode flag: python main.py --question 12345 --mode production

mode: "dry_run"

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Models used for research query generation and other utility tasks.
# All models accessed via OpenRouter (set OPENROUTER_API_KEY).
#
# The 5-agent ensemble is configured separately below.

models:
  # Models for dry_run mode (cheap, fast)
  cheap:
    query_generator: "openrouter/anthropic/claude-3.5-haiku"
    article_summarizer: "openrouter/anthropic/claude-3.5-haiku"
    agentic_search: "openrouter/anthropic/claude-3.5-haiku"

  # Models for dry_run_heavy and production modes
  production:
    query_generator: "openrouter/openai/o3"
    article_summarizer: "openrouter/anthropic/claude-sonnet-4.5"
    agentic_search: "openrouter/openai/o3"

# =============================================================================
# 5-AGENT ENSEMBLE CONFIGURATION (Panshul42 Structure)
# =============================================================================
# The ensemble uses 5 forecasting agents with equal weights:
#   - forecaster_1: Claude (weight 1.0)
#   - forecaster_2: Claude (weight 1.0)
#   - forecaster_3: o3-mini-high (weight 1.0)
#   - forecaster_4: o3 (weight 1.0)
#   - forecaster_5: o3 (weight 1.0)
#
# Cross-pollination structure (from Panshul42):
#   - Agent 1 receives Agent 1's step 1 output (Outside view)
#   - Agent 2 receives Agent 3's step 1 output (Outside view)
#   - Agent 3 receives Agent 2's step 1 output (Outside view)
#   - Agent 4 receives Agent 4's step 1 output (Inside view)
#   - Agent 5 receives Agent 5's step 1 output (Inside view)

ensemble:
  # Agents for dry_run mode (all Haiku - cheap, fast)
  cheap:
    - name: "forecaster_1"
      model: "openrouter/anthropic/claude-3.5-haiku"
      weight: 1.0

    - name: "forecaster_2"
      model: "openrouter/anthropic/claude-3.5-haiku"
      weight: 1.0

    - name: "forecaster_3"
      model: "openrouter/anthropic/claude-3.5-haiku"
      weight: 1.0

    - name: "forecaster_4"
      model: "openrouter/anthropic/claude-3.5-haiku"
      weight: 1.0

    - name: "forecaster_5"
      model: "openrouter/anthropic/claude-3.5-haiku"
      weight: 1.0

  # Agents for production
  production:
    - name: "forecaster_1"
      model: "openrouter/anthropic/claude-sonnet-4.5"
      weight: 1.0

    - name: "forecaster_2"
      model: "openrouter/anthropic/claude-sonnet-4.5"
      weight: 1.0

    - name: "forecaster_3"
      model: "openrouter/openai/o3-mini-high"
      weight: 1.0

    - name: "forecaster_4"
      model: "openrouter/openai/o3"
      weight: 1.0

    - name: "forecaster_5"
      model: "openrouter/openai/o3"
      weight: 1.0

  aggregation: "weighted_average"

# =============================================================================
# RESEARCH CONFIGURATION (Panshul42 Pipeline)
# =============================================================================
# Research is integrated into each handler. The pipeline:
# 1. Generate historical queries (outside view context)
# 2. Generate current queries (inside view context)
# 3. Execute searches via Google (Serper) and AskNews
# 4. Extract and summarize content
#
# This replaces the previous separate research phase.

research:
  # Google search via Serper API
  google_enabled: true
  google_max_results: 10

  # AskNews integration
  asknews_enabled: true
  asknews_max_results: 10
  asknews_hours_back: 72

  # Agentic search (iterative LLM-guided research)
  agentic_search_enabled: true
  agentic_search_max_steps: 7

  # Article scraping
  scraping_enabled: true
  max_articles_to_scrape: 10
  max_content_length: 15000

  # Legacy settings (for backward compatibility)
  sources:
    - type: "llm_knowledge"
      enabled: true

    - type: "asknews"
      enabled: true
      cache_mode: "no_cache"

    - type: "asknews_wiki"
      enabled: true
      max_results: 5

    - type: "article_scraping"
      enabled: true
      max_articles: 5
      max_content_length: 5000

# =============================================================================
# SUBMISSION CONFIGURATION
# =============================================================================
submission:
  store_reasoning: true
  tournament_id: null

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
storage:
  base_dir: "./data"
  database_path: "./data/forecasts.db"
  snapshot_configs: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"
  log_llm_calls: true
  track_costs: true

# =============================================================================
# API KEYS (Set in .env file)
# =============================================================================
# Required:
#   OPENROUTER_API_KEY - For all model calls
#   METACULUS_TOKEN - For question fetching and submission
#
# For research:
#   SERPER_API_KEY - Google search (free tier: 2,500/month)
#   ASKNEWS_CLIENT_ID - AskNews (free for tournament participants)
#   ASKNEWS_CLIENT_SECRET - AskNews secret
