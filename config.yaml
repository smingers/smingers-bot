# Metaculus AI Forecasting Bot Configuration
# All tunable parameters in one place

# =============================================================================
# RUN MODE
# =============================================================================
# Controls model selection and submission behavior:
#   - "dry_run": Cheap models (Haiku), no submission - for testing pipeline
#   - "dry_run_heavy": Production models, no submission - for evaluating quality
#   - "production": Production models, submits to Metaculus
#
# Override with --mode flag: python main.py --question 12345 --mode production

mode: "dry_run"

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Models are accessed via litellm which supports multiple providers.
#
# Direct API usage (set ANTHROPIC_API_KEY or OPENAI_API_KEY):
#   - claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-haiku-20240307
#   - gpt-4o, gpt-4o-mini, o1-mini
#
# Via OpenRouter (set OPENROUTER_API_KEY, prefix with "openrouter/"):
#   - openrouter/anthropic/claude-3.5-sonnet
#   - openrouter/openai/gpt-4o
#
# Models are selected based on run mode. Define both cheap and production models.

models:
  # Models for dry_run mode (cheap, fast)
  cheap:
    classifier: "claude-3-haiku-20240307"
    query_generator: "claude-3-haiku-20240307"
    base_rate_estimator: "claude-3-haiku-20240307"

  # Models for dry_run_heavy and production modes
  production:
    classifier: "claude-3-haiku-20240307"  # Keep cheap for simple tasks
    query_generator: "claude-3-haiku-20240307"  # Keep cheap for simple tasks
    base_rate_estimator: "claude-sonnet-4-20250514"

# =============================================================================
# ENSEMBLE CONFIGURATION
# =============================================================================
# Define agents for both cheap and production modes.
# Production mode uses stronger models with optimized weights.

ensemble:
  # Agents for dry_run mode (cheap, fast)
  cheap:
    - name: "analyst"
      model: "claude-3-haiku-20240307"
      weight: 1.0
      role_description: |
        You are a geopolitical analyst and superforecaster. Focus on the current
        situation, key actors, their incentives, and recent developments. Weigh
        evidence by strength (strong, moderate, weak) and reason through how
        each piece updates the base rate.

    - name: "historian"
      model: "claude-3-haiku-20240307"
      weight: 1.0
      role_description: |
        You are a historian and superforecaster. Focus on historical precedents,
        analogous situations, and patterns from the past. Consider how often
        similar situations have resolved in various ways. Use history to inform
        your probability estimate.

    - name: "contrarian"
      model: "claude-3-haiku-20240307"
      weight: 0.8
      role_description: |
        You are a contrarian forecaster. Your job is to challenge the obvious
        narrative, find reasons the consensus might be wrong, and identify
        blind spots. Consider: What would make the base rate misleading?
        What are people overlooking?

  # Agents for dry_run_heavy and production modes
  # Uses stronger models, more agents, optimized weights (inspired by Q2 winner)
  production:
    - name: "analyst"
      model: "claude-sonnet-4-20250514"
      weight: 1.0
      role_description: |
        You are a geopolitical analyst and superforecaster. Focus on the current
        situation, key actors, their incentives, and recent developments. Weigh
        evidence by strength (strong, moderate, weak) and reason through how
        each piece updates the base rate.

    - name: "historian"
      model: "claude-sonnet-4-20250514"
      weight: 1.0
      role_description: |
        You are a historian and superforecaster. Focus on historical precedents,
        analogous situations, and patterns from the past. Consider how often
        similar situations have resolved in various ways. Use history to inform
        your probability estimate.

    - name: "contrarian"
      model: "claude-sonnet-4-20250514"
      weight: 0.8
      role_description: |
        You are a contrarian forecaster. Your job is to challenge the obvious
        narrative, find reasons the consensus might be wrong, and identify
        blind spots. Consider: What would make the base rate misleading?
        What are people overlooking?

    - name: "quantitative"
      model: "claude-sonnet-4-20250514"  # Use Claude if no OpenAI key; change to gpt-4o if available
      weight: 1.0
      role_description: |
        You are a quantitative analyst and superforecaster. Focus on data,
        statistics, and numerical analysis. Look for base rates in the data,
        trend extrapolations, and quantitative models that inform the forecast.

    - name: "synthesizer"
      model: "claude-sonnet-4-20250514"
      weight: 1.2
      role_description: |
        You are a synthesis expert and superforecaster. Your job is to integrate
        multiple perspectives, identify key uncertainties, and form a balanced
        view. Consider all evidence holistically and identify what matters most.

  aggregation: "weighted_average"

# =============================================================================
# RESEARCH CONFIGURATION
# =============================================================================
# For testing: Disable external research, use LLM's training knowledge only
# Enable sources as you get API keys

research:
  sources:
    # Claude will use its training knowledge for research
    # No external API calls needed for basic testing
    - type: "llm_knowledge"
      enabled: true

    # AskNews - FREE for tournament participants (3k calls/month)
    # Requires Metaculus tournament signup for free tier access
    # See: https://www.metaculus.com/aib/ for setup instructions
    - type: "asknews"
      enabled: false
      max_results: 10

    # Perplexity - requires PERPLEXITY_API_KEY
    - type: "perplexity"
      enabled: false
      model: "sonar-reasoning-pro"
      max_queries: 3

    # Web search via Serper - requires SERPER_API_KEY (has free tier: 2,500/month)
    - type: "web_search"
      enabled: true
      provider: "serper"
      max_results: 10

    # Claude native web search - uses Anthropic API directly
    # Cost: $10 per 1,000 searches + token costs
    # Disabled by default since Serper is cheaper for basic search
    - type: "claude_web_search"
      enabled: false
      model: "claude-3-haiku-20240307"

  queries_per_question: 3
  max_research_time: 60

# =============================================================================
# PROMPT CONFIGURATION
# =============================================================================
prompts:
  outside_view_template: "outside_view.md"
  inside_view_template: "inside_view.md"
  evidence_classification: "evidence_classification.md"
  calibration_checklist: "calibration_checklist.md"
  verbosity: "maximum"

# =============================================================================
# CALIBRATION CONFIGURATION
# =============================================================================
calibration:
  enabled: true
  checklist_items:
    - id: "paraphrase"
      description: "Can you summarize the question in <30 words?"
    - id: "base_rate_grounded"
      description: "Is the final prediction rooted in the outside view base rate?"
    - id: "consistency_test"
      description: "Does 'X out of 100 times, this happens' feel right?"
    - id: "evidence_audit"
      description: "Are the top 3-5 pieces of evidence factually valid?"
    - id: "blind_spots"
      description: "What scenario would make this forecast look silly?"
    - id: "status_quo_bias"
      description: "Have you appropriately considered inertia/status quo?"

# =============================================================================
# SUBMISSION CONFIGURATION
# =============================================================================
# Note: dry_run is now controlled by the 'mode' setting at the top.
# - mode: "dry_run" or "dry_run_heavy" -> no submission
# - mode: "production" -> submits to Metaculus
submission:
  store_reasoning: true
  max_ensemble_disagreement: 0.0
  tournament_id: null

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
storage:
  base_dir: "./data"
  database_path: "./data/forecasts.db"
  snapshot_configs: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"
  log_llm_calls: true
  track_costs: true
