# Metaculus AI Forecasting Bot Configuration
# All tunable parameters in one place

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# All models accessed via OpenRouter (using OPENROUTER_API_KEY)
# Metaculus provides FREE credits for OpenAI and Anthropic models via OpenRouter
#
# To get free credits: Fill out the Metaculus form, then set OPENROUTER_API_KEY
# Model names use OpenRouter format: "openai/model-name" or "anthropic/model-name"
#
# Available via donated credits (OpenAI + Anthropic only):
#   OpenAI: gpt-4o, gpt-4o-mini, o1, o1-mini, o3-mini, gpt-4o-search-preview
#   Anthropic: claude-3.5-sonnet, claude-3-haiku, claude-3-opus
#
# IMPORTANT: Do NOT use ":online" suffix - that uses Exa which isn't covered!
# Instead use: openai/gpt-4o-search-preview (has built-in search)

models:
  # Fast/cheap model for question analysis and query generation
  classifier: "openai/gpt-4o-mini"
  query_generator: "openai/gpt-4o-mini"

  # Reasoning model for outside view base rate estimation
  base_rate_estimator: "anthropic/claude-3.5-sonnet"

# =============================================================================
# ENSEMBLE CONFIGURATION
# =============================================================================
ensemble:
  agents:
    - name: "evidence_reasoner"
      model: "anthropic/claude-3.5-sonnet"
      weight: 1.0
      role_description: |
        You are an evidence-focused forecaster. Your job is to carefully weigh
        all available evidence, classify each piece by strength (strong, moderate, weak),
        and reason through how the evidence updates the base rate.

    - name: "contrarian"
      model: "anthropic/claude-3.5-sonnet"
      weight: 1.0
      role_description: |
        You are a contrarian forecaster. Your job is to find counterarguments,
        identify reasons the consensus might be wrong, and consider scenarios
        that would make the base case prediction look foolish.

    - name: "calculator"
      model: "openai/gpt-4o"
      weight: 1.5
      role_description: |
        You are a quantitative forecaster. Your job is to focus on numbers,
        statistics, and mathematical reasoning. Look for base rates,
        historical frequencies, and quantifiable trends.

    - name: "integrator"
      model: "openai/o1-mini"
      weight: 2.0
      role_description: |
        You are an integrating forecaster. Your job is to synthesize multiple
        perspectives, resolve conflicts between different lines of evidence,
        and produce a well-calibrated final estimate.

  # Aggregation method: "weighted_average", "median", "trimmed_mean"
  aggregation: "weighted_average"

# =============================================================================
# RESEARCH CONFIGURATION
# =============================================================================
# AskNews is FREE for tournament participants - contact Metaculus to set up
# You can also use openai/gpt-4o-search-preview which has built-in search

research:
  sources:
    # OpenAI's search-enabled model (covered by donated credits)
    - type: "openai_search"
      enabled: true
      model: "openai/gpt-4o-search-preview"
      max_queries: 3

    # AskNews - FREE for tournament participants
    # Get credentials by following "Getting AskNews Setup" in Metaculus docs
    - type: "asknews"
      enabled: false  # Set to true once you have credentials
      max_results: 10

    # Perplexity - NOT covered by donated credits (requires own account)
    - type: "perplexity"
      enabled: false
      model: "sonar-reasoning-pro"
      max_queries: 3

    # Web search via Serper - NOT covered (requires own account, has free tier)
    - type: "web_search"
      enabled: false
      provider: "serper"
      max_results: 10

  # How many search queries to generate per question
  queries_per_question: 5

  # Maximum total research time per question (seconds)
  max_research_time: 60

# =============================================================================
# PROMPT CONFIGURATION
# =============================================================================
prompts:
  # Prompt template file locations (relative to src/bot/prompts/)
  outside_view_template: "outside_view.md"
  inside_view_template: "inside_view.md"
  evidence_classification: "evidence_classification.md"
  calibration_checklist: "calibration_checklist.md"

  # Verbosity level: "maximum", "balanced", "minimal"
  # maximum = full chain-of-thought, all evidence cited (~1000+ words per agent)
  # balanced = key reasoning steps, main evidence (~300-500 words per agent)
  # minimal = brief justification only (~100-150 words per agent)
  verbosity: "maximum"

# =============================================================================
# CALIBRATION CONFIGURATION
# =============================================================================
calibration:
  enabled: true
  checklist_items:
    - id: "paraphrase"
      description: "Can you summarize the question in <30 words?"
    - id: "base_rate_grounded"
      description: "Is the final prediction rooted in the outside view base rate?"
    - id: "consistency_test"
      description: "Does 'X out of 100 times, this happens' feel right?"
    - id: "evidence_audit"
      description: "Are the top 3-5 pieces of evidence factually valid?"
    - id: "blind_spots"
      description: "What scenario would make this forecast look silly?"
    - id: "status_quo_bias"
      description: "Have you appropriately considered inertia/status quo?"

# =============================================================================
# SUBMISSION CONFIGURATION
# =============================================================================
submission:
  # If true, don't actually submit to Metaculus (for testing)
  dry_run: false

  # Save full reasoning artifacts for every forecast
  store_reasoning: true

  # Skip submission if ensemble standard deviation exceeds this threshold
  # (0.0 = always submit, 0.3 = skip if agents disagree by >30%)
  max_ensemble_disagreement: 0.0

  # Metaculus tournament ID (update for each tournament)
  tournament_id: null  # Set this to the current tournament ID

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
storage:
  # Base directory for all artifacts
  base_dir: "./data"

  # SQLite database for analytics
  database_path: "./data/forecasts.db"

  # Keep config snapshots for reproducibility
  snapshot_configs: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR

  # Log all LLM prompts and responses
  log_llm_calls: true

  # Log API costs
  track_costs: true
