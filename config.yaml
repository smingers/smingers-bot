# Metaculus AI Forecasting Bot Configuration
# All tunable parameters in one place

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Models are accessed via litellm which supports multiple providers.
#
# Direct API usage (set ANTHROPIC_API_KEY or OPENAI_API_KEY):
#   - claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-haiku-20240307
#   - gpt-4o, gpt-4o-mini, o1-mini
#
# Via OpenRouter (set OPENROUTER_API_KEY, prefix with "openrouter/"):
#   - openrouter/anthropic/claude-3.5-sonnet
#   - openrouter/openai/gpt-4o
#
# Current config: Uses Anthropic directly (cheapest to start testing)

models:
  # Fast/cheap model for question analysis and query generation
  classifier: "claude-3-haiku-20240307"
  query_generator: "claude-3-haiku-20240307"

  # Reasoning model for outside view base rate estimation
  # Using Haiku for testing to minimize costs (switch to Sonnet for production)
  base_rate_estimator: "claude-3-haiku-20240307"

# =============================================================================
# ENSEMBLE CONFIGURATION
# =============================================================================
# Start simple: Single Claude agent for testing, expand to multi-model ensemble later

ensemble:
  agents:
    # For testing: just one agent with cheapest model
    # Switch to claude-sonnet-4-20250514 for production quality
    - name: "forecaster"
      model: "claude-3-haiku-20240307"
      weight: 1.0
      role_description: |
        You are a superforecaster. Your job is to carefully weigh all available
        evidence, classify each piece by strength (strong, moderate, weak),
        reason through how the evidence updates the base rate, and produce
        a well-calibrated probability estimate.

    # Uncomment these for full ensemble (will use more API credits):
    # - name: "contrarian"
    #   model: "claude-sonnet-4-20250514"
    #   weight: 1.0
    #   role_description: |
    #     You are a contrarian forecaster. Find counterarguments and reasons
    #     the consensus might be wrong.
    #
    # - name: "calculator"
    #   model: "gpt-4o"  # Requires OPENAI_API_KEY
    #   weight: 1.5
    #   role_description: |
    #     You are a quantitative forecaster. Focus on numbers, statistics,
    #     and mathematical reasoning.

  aggregation: "weighted_average"

# =============================================================================
# RESEARCH CONFIGURATION
# =============================================================================
# For testing: Disable external research, use LLM's training knowledge only
# Enable sources as you get API keys

research:
  sources:
    # Claude will use its training knowledge for research
    # No external API calls needed for basic testing
    - type: "llm_knowledge"
      enabled: true

    # AskNews - FREE for tournament participants (3k calls/month)
    # Requires Metaculus tournament signup for free tier access
    # See: https://www.metaculus.com/aib/ for setup instructions
    - type: "asknews"
      enabled: false
      max_results: 10

    # Perplexity - requires PERPLEXITY_API_KEY
    - type: "perplexity"
      enabled: false
      model: "sonar-reasoning-pro"
      max_queries: 3

    # Web search via Serper - requires SERPER_API_KEY (has free tier)
    - type: "web_search"
      enabled: false
      provider: "serper"
      max_results: 10

  queries_per_question: 3
  max_research_time: 60

# =============================================================================
# PROMPT CONFIGURATION
# =============================================================================
prompts:
  outside_view_template: "outside_view.md"
  inside_view_template: "inside_view.md"
  evidence_classification: "evidence_classification.md"
  calibration_checklist: "calibration_checklist.md"
  verbosity: "maximum"

# =============================================================================
# CALIBRATION CONFIGURATION
# =============================================================================
calibration:
  enabled: true
  checklist_items:
    - id: "paraphrase"
      description: "Can you summarize the question in <30 words?"
    - id: "base_rate_grounded"
      description: "Is the final prediction rooted in the outside view base rate?"
    - id: "consistency_test"
      description: "Does 'X out of 100 times, this happens' feel right?"
    - id: "evidence_audit"
      description: "Are the top 3-5 pieces of evidence factually valid?"
    - id: "blind_spots"
      description: "What scenario would make this forecast look silly?"
    - id: "status_quo_bias"
      description: "Have you appropriately considered inertia/status quo?"

# =============================================================================
# SUBMISSION CONFIGURATION
# =============================================================================
submission:
  dry_run: true  # Start with dry_run for testing!
  store_reasoning: true
  max_ensemble_disagreement: 0.0
  tournament_id: null

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
storage:
  base_dir: "./data"
  database_path: "./data/forecasts.db"
  snapshot_configs: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"
  log_llm_calls: true
  track_costs: true
