# Metaculus AI Forecasting Bot Configuration
# All tunable parameters in one place

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Models are accessed via litellm which supports multiple providers.
#
# Direct API usage (set ANTHROPIC_API_KEY or OPENAI_API_KEY):
#   - claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-haiku-20240307
#   - gpt-4o, gpt-4o-mini, o1-mini
#
# Via OpenRouter (set OPENROUTER_API_KEY, prefix with "openrouter/"):
#   - openrouter/anthropic/claude-3.5-sonnet
#   - openrouter/openai/gpt-4o
#
# Current config: Uses Anthropic directly (cheapest to start testing)

models:
  # Fast/cheap model for question analysis and query generation
  classifier: "claude-3-haiku-20240307"
  query_generator: "claude-3-haiku-20240307"

  # Reasoning model for outside view base rate estimation
  # Using Haiku for testing to minimize costs (switch to Sonnet for production)
  base_rate_estimator: "claude-3-haiku-20240307"

# =============================================================================
# ENSEMBLE CONFIGURATION
# =============================================================================
# Start simple: Single Claude agent for testing, expand to multi-model ensemble later

ensemble:
  agents:
    # All agents use Haiku for testing (switch to Sonnet for production)
    - name: "analyst"
      model: "claude-3-haiku-20240307"
      weight: 1.0
      role_description: |
        You are a geopolitical analyst and superforecaster. Focus on the current
        situation, key actors, their incentives, and recent developments. Weigh
        evidence by strength (strong, moderate, weak) and reason through how
        each piece updates the base rate.

    - name: "historian"
      model: "claude-3-haiku-20240307"
      weight: 1.0
      role_description: |
        You are a historian and superforecaster. Focus on historical precedents,
        analogous situations, and patterns from the past. Consider how often
        similar situations have resolved in various ways. Use history to inform
        your probability estimate.

    - name: "contrarian"
      model: "claude-3-haiku-20240307"
      weight: 0.8
      role_description: |
        You are a contrarian forecaster. Your job is to challenge the obvious
        narrative, find reasons the consensus might be wrong, and identify
        blind spots. Consider: What would make the base rate misleading?
        What are people overlooking?

  aggregation: "weighted_average"

# =============================================================================
# RESEARCH CONFIGURATION
# =============================================================================
# For testing: Disable external research, use LLM's training knowledge only
# Enable sources as you get API keys

research:
  sources:
    # Claude will use its training knowledge for research
    # No external API calls needed for basic testing
    - type: "llm_knowledge"
      enabled: true

    # AskNews - FREE for tournament participants (3k calls/month)
    # Requires Metaculus tournament signup for free tier access
    # See: https://www.metaculus.com/aib/ for setup instructions
    - type: "asknews"
      enabled: false
      max_results: 10

    # Perplexity - requires PERPLEXITY_API_KEY
    - type: "perplexity"
      enabled: false
      model: "sonar-reasoning-pro"
      max_queries: 3

    # Web search via Serper - requires SERPER_API_KEY (has free tier: 2,500/month)
    - type: "web_search"
      enabled: true
      provider: "serper"
      max_results: 10

    # Claude native web search - uses Anthropic API directly
    # Cost: $10 per 1,000 searches + token costs
    # Disabled by default since Serper is cheaper for basic search
    - type: "claude_web_search"
      enabled: false
      model: "claude-3-haiku-20240307"

  queries_per_question: 3
  max_research_time: 60

# =============================================================================
# PROMPT CONFIGURATION
# =============================================================================
prompts:
  outside_view_template: "outside_view.md"
  inside_view_template: "inside_view.md"
  evidence_classification: "evidence_classification.md"
  calibration_checklist: "calibration_checklist.md"
  verbosity: "maximum"

# =============================================================================
# CALIBRATION CONFIGURATION
# =============================================================================
calibration:
  enabled: true
  checklist_items:
    - id: "paraphrase"
      description: "Can you summarize the question in <30 words?"
    - id: "base_rate_grounded"
      description: "Is the final prediction rooted in the outside view base rate?"
    - id: "consistency_test"
      description: "Does 'X out of 100 times, this happens' feel right?"
    - id: "evidence_audit"
      description: "Are the top 3-5 pieces of evidence factually valid?"
    - id: "blind_spots"
      description: "What scenario would make this forecast look silly?"
    - id: "status_quo_bias"
      description: "Have you appropriately considered inertia/status quo?"

# =============================================================================
# SUBMISSION CONFIGURATION
# =============================================================================
submission:
  dry_run: true  # Start with dry_run for testing!
  store_reasoning: true
  max_ensemble_disagreement: 0.0
  tournament_id: null

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
storage:
  base_dir: "./data"
  database_path: "./data/forecasts.db"
  snapshot_configs: true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"
  log_llm_calls: true
  track_costs: true
