{
  "context": "\n<Summary source=\"https://digital-strategy.ec.europa.eu/en/policies/eu-age-verification\">\n# Summary of Article: \"The EU approach to age verification\"\n\n**Source:** Shaping Europe's digital future (official EU digital policy website)\n\n## Key Facts and Developments:\n\n1. **Commission Initiative**: The European Commission is developing a harmonized EU-wide approach to age verification in collaboration with Member States to help online platforms implement user-friendly and privacy-preserving age verification methods.\n\n2. **Initial Scope**: The initiative initially targets users proving they are over 18 years of age for accessing adult-restricted online content, including pornography, gambling, and alcohol purchases.\n\n3. **Blueprint Release**: On July 14, 2025, the Commission released a blueprint for an age verification solution that:\n   - Allows users to prove they are over 18 without sharing other personal information\n   - Is privacy-preserving and user-friendly\n   - Is fully interoperable with future EU Digital Identity Wallets\n   - Can be easily adapted to prove other age ranges (e.g., 13+)\n\n4. **Technical Details**: The solution, also called the 'mini wallet', is built on the same technical specifications as the European Digital Identity Wallets, which are scheduled to be rolled out by the end of 2026.\n\n5. **Current Status**: The solution is entering a pilot phase of testing with Member States, online platforms, end users, and other interested parties including software solution providers.\n\n6. **Digital Services Act Connection**: This initiative is described as \"a key step in supporting the implementation of the Digital Services Act.\"\n\n7. **Recent Updates**: A second version of the age verification blueprint has been introduced with additional features, including the use of passports and ID cards for onboarding.\n\n8. **Broader Context**: This is part of the Strategy for a better Internet for kids (BIK+), aimed at ensuring children are protected, respected, and empowered online.\n\n**Note:** This appears to be an official EU Commission webpage describing ongoing policy development rather than a news article reporting on legislative adoption.\n</Summary>\n\n<Summary source=\"https://www.taylorwessing.com/en/interface/2025/predictions-2026/enhancement-and-enforcement\">\n## Summary of Article: \"Online safety in 2026: enhancement and enforcement in the EU and UK\"\n\n**Source:** Taylorwessing  \n**Date:** December 02, 2025\n\n### Key Facts and Developments:\n\n**EU-Level Actions:**\n- The European Commission ramped up Digital Services Act (DSA) enforcement during 2025, including:\n  - Opening formal proceedings against porn providers regarding age verification practices and failures to protect minors\n  - Finding breaches of Article 34 risk mitigation requirements\n  - Preliminary findings that Meta's Facebook and Instagram failed to provide simple mechanisms for notifying illegal content\n  \n- In September 2025, the Commission sent requests for information to Apple (re: App Store) and Microsoft (re: Bing) about identifying and mitigating financial scam risks under the DSA\n\n- In October 2025, the Commission sent requests for information to social media companies including Snapchat and Apple regarding safeguarding steps to protect minors\n\n- **EU Commission released a prototype of an EU-wide age verification app in 2025** that allows users to prove they are over 18 when accessing restricted adult content. It is currently being piloted by Denmark, France, Greece, Italy, and Spain, with further take-up expected in 2026\n\n**National-Level Developments:**\n\n**Germany:**\n- Federal Youth Protection Act (JuSchG) reformed in 2021 to apply to online services, requiring platforms to implement age ratings, child-friendly terms, default settings, notice-and-takedown mechanisms, and age verification\n- Interstate Treaty reforms introducing new rules for operating system (OS) and app providers became effective December 1, 2025\n- OS providers whose services are typically used by minors must ensure their OS includes parental control mechanisms\n- Provisions will only apply one year after regulator designates in-scope OS providers\n\n**France:**\n- Act No. 2024-449 (SREN law) imposes robust age verification obligations on website operators to prevent minors from accessing online pornographic content\n- French regulator (ARCOM) rolled out standards for age verification in October 2024\n- During 2025, several major platforms chose to voluntarily block or suspend access from France rather than implement the stringent age verification requirements\n\n**UK:**\n- On November 3, 2025, Ofcom launched a call for evidence on the use and effectiveness of age assurance under the Online Safety Act and on the role of app stores in children's exposure to harmful content\n- Ofcom will submit a report on age assurance by the end of July 2026 and a report on app stores by January 2027\n\n### Author Opinions/Analysis:\n- The article notes that \"public opinion trends to more rather than less regulation of the online world, especially where children are concerned\"\n- Authors suggest the UK government may find itself under \"considerable political pressure to bolster the OSA by adding further priority offences, or even by bringing other types of content in scope\"\n- The article characterizes the regulatory landscape as \"evolving rapidly across Europe\" with \"an increasingly demanding compliance environment\"\n\n**Note:** The article appears to be cut off at the end.\n</Summary>\n\n<Summary source=\"https://euperspectives.eu/2025/07/age-verification-app/\">\n# Summary of \"EU sets out blueprint for Age Verification App\"\n\n**Source:** EU Perspectives, July 14, 2025\n\n## Key Facts and Developments:\n\n### Age Verification Blueprint Initiative\n- The EU is developing an Age Verification Blueprint as a temporary solution until the EU Digital Identity Wallet launches in 2026\n- The initiative supports the Digital Services Act and aims to protect children online\n- The prototype system checks whether users are over 18 years old without sharing or storing personal data besides the user's age\n- The model will be open-source and adaptable by all EU member states and digital platforms\n- Countries can customize the system according to their legal age limits\n\n### Testing and Implementation\n- The prototype will first be tested in five countries: Denmark, France, Greece, Italy, and Spain\n- The tool is designed to eventually integrate with the European Digital Identity Wallet (expected 2026) but may also operate as a standalone app\n- Technical information for developers is available at ageverification.dev\n\n### Context and Statistics\n- One in three internet users in Europe is a child\n- One in six young people reports experiencing cyberbullying\n- Minors frequently encounter risky content including drugs, pornography, and gambling\n\n### Official Statements\n- **Henna Virkkunen** (Executive Vice-President for Tech Sovereignty, Security and Democracy): \"The guidelines on the protection of minors for online platforms, combined with the new age verification blueprint, are a huge step forward. Platforms have no excuse to be continuing practices that put children at risk.\"\n- **Caroline Stage Olsen** (Denmark's Minister for Digital Affairs): \"Children deserve a safe digital childhood. This is one of the main priorities for me during the Danish Presidency. Without proper age verification, we fail to protect children online.\"\n\n### Platform Guidelines\nThe Commission's new guidelines recommend:\n- Limiting exposure to harmful content and reducing manipulative design practices\n- Default settings for minors should restrict camera and location access and prevent messages from unknown users\n- Functions like \"likes\" or joining chat groups should require clear consent\n- Push notifications should be switched off during nighttime hours\n- Removal of features like read receipts or streaks that encourage constant engagement\n- Recommender systems should prioritize users' explicit feedback over algorithmic predictions\n\n### Political Support\n- Several Member States, including Denmark, France, and Germany, are pushing for stronger enforcement of children's rights online\n- Denmark (currently hosting the EU Presidency) has pledged to make child online safety a political priority\n</Summary>\n\n<Summary source=\"https://www.lemonde.fr/en/france/article/2026/01/27/eu-confirms-france-has-the-right-to-ban-social-media-for-under-15s_6749855_7.html\">\n# Summary of Article: \"France has right to ban social media for under-15s, EU says\"\n\n**Source:** Le Monde with AFP, published January 27, 2025\n\n## Key Facts and Statements:\n\n1. **EU Commission Position on French Ban:**\n   - The European Commission confirmed France has the right to ban social media platforms for under-15s\n   - A bill containing this proposition was passed by France's lower house of parliament\n   - Enforcement of the measure would lie with the European Union\n\n2. **Official EU Statement:**\n   - Commission spokesperson Thomas Regnier stated: \"The French authorities have the right to establish a digital age for their citizens\"\n   - Online service companies have an \"obligation\" to \"respect the national legislation\"\n   - If the French bill conforms with EU law, \"the commission will enforce it towards the Very Large Online Platforms\" under the Digital Services Act (DSA)\n\n3. **Age Verification Enforcement:**\n   - The EU would be responsible for ensuring platforms implement adequate age verification tools\n   - A European age-verification tool is currently being tested by several countries, including France\n   - Member states are obliged to offer this tool or an equivalent by the end of the year (2025)\n\n4. **French Legislative Status:**\n   - The bill has passed the lower house of parliament\n   - Still needs approval from the S\u00e9nat to become law\n   - Championed by President Emmanuel Macron\n\n5. **Implementation Timeline:**\n   - Proposed ban would be enforced from the start of the 2026 school year for new social media accounts\n   - Age verification for all users would be in place by January 1, 2027\n\n6. **International Context:**\n   - France would be the second country to take such a step after Australia's ban on social media platforms for under-16s in December (2024)\n   - Part of a broader international push to combat alleged harms to child development and mental health linked to excessive screen use and social media\n</Summary>\n\n<Summary source=\"https://www.dw.com/en/eu-lawmakers-back-plan-for-social-media-age-rules/a-74909572\">\n# Summary of Article: \"EU lawmakers back plan for social media age rules\"\n\n**Source:** dw.com  \n**Author:** Richard Connor  \n\n## Key Facts and Statistics:\n\n1. **European Parliament Vote (Wednesday):** The European Parliament adopted a non-legislative resolution by 483 votes in favor, 92 against, and 86 abstentions calling for:\n   - A default minimum age of 16 for accessing social media platforms (unless parents/guardians authorize otherwise)\n   - A harmonized EU digital age limit of 13, below which no minor would be permitted to access social media\n   - Same minimum age requirements would apply to video-sharing platforms and \"AI companions\"\n\n2. **Legal Status:** The resolution is **not legally binding** and does not create or change policy. Any future legislation would require:\n   - A full proposal from the European Commission\n   - Negotiations with EU governments and the European Parliament\n\n3. **Current Platform Requirements:** Most major platforms (TikTok, Facebook, Snapchat) require users to be at least 13\n\n4. **Existing National Measures in EU Countries:**\n   - **Belgium (since 2018):** Children must be at least 13 to create accounts without parental permission\n   - **France (2023 law):** Requires parental consent for under-15s, though enforcement has lagged due to technical issues\n   - **Germany:** Children aged 13-16 may use social media only with parental consent (enforcement reportedly insufficient)\n   - **Italy:** Children under 14 need parental permission; from 14 onward, no consent required\n   - **Netherlands:** No legal minimum age, but mobile phones banned in classrooms since January 2024\n\n5. **Non-EU Examples:**\n   - **Norway (October 2024 proposal):** Raising age of consent from 13 to 15\n   - **Denmark:** Government reached agreement for minimum age of 15 on certain platforms\n   - **Australia (November 2024 law):** Platforms must block minors under 13; fines up to A$49.5 million for violations; full ban took effect December 10\n   - **UK (Online Safety Act 2023, enforced since 2025):** Mandates stricter age-appropriate protections but no clear legal age limit\n\n## Notable Opinions/Context:\n\n- **Supporters' view:** Higher digital age threshold could reduce exposure to harmful content and limit addictive design features\n- **Critics' view:** Enforcement would be difficult and might drive children to circumvent age checks\n- **Child-protection groups:** Current safeguards are weak; data shows large numbers of under-13s with accounts across European countries\n- **European Commission:** Has not indicated whether it plans to pursue the proposal\n</Summary>\n\n<Summary source=\"https://www.europarl.europa.eu/news/en/press-room/20251120IPR31496/children-should-be-at-least-16-to-access-social-media-say-meps\">\n# Summary of Article: \"Children should be at least 16 to access social media, say MEPs\"\n\n**Source:** European Parliament (Europarl.europa.eu)  \n**Date:** November 26, 2025\n\n## Key Facts and Statistics:\n\n1. **Vote Results:** MEPs adopted a non-legislative report on Wednesday with 483 votes in favor, 92 against, and 86 abstentions.\n\n2. **Proposed Minimum Age:** Parliament proposes a harmonized EU digital minimum age of **16** for access to social media, video-sharing platforms, and AI companions, with allowance for 13- to 16-year-olds to access with parental consent.\n\n3. **Youth Online Usage Statistics (referenced in report):**\n   - 97% of young people go online every day\n   - 78% of 13 to 17-year-olds check their devices at least hourly\n   - One in four minors display 'problematic' or 'dysfunctional' smartphone use with behavioral patterns mirroring addiction\n\n4. **Public Opinion (2025 Eurobarometer):**\n   - Over 90% of Europeans believe action to protect children online is urgent\n   - 93% concerned about social media's negative impact on mental health\n   - 92% concerned about cyberbullying\n   - 92% support effective ways to restrict access to age-inappropriate content\n\n## Key Policy Proposals:\n\n- **Age Verification Systems:** MEPs support the Commission's work to develop an EU age verification app and European digital identity (eID) wallet, insisting that age assurance systems must be accurate and preserve minors' privacy\n- **Platform Accountability:** Platforms remain responsible for ensuring products are safe and age-appropriate by design\n- **Enforcement:** MEPs suggest senior managers could be made personally liable in cases of serious and persistent non-compliance, particularly regarding protection of minors and age verification\n- **Bans on harmful practices:** Calls for bans on the most harmful addictive practices\n\n## Named Source Opinion:\n\n**Rapporteur Christel Schaldemose (S&D, Denmark)** stated: \"Together with strong, consistent enforcement of the Digital Services Act, these measures will dramatically raise the level of protection for children. We are finally drawing a line. We are saying clearly to platforms: your services are not designed for children. And the experiment ends here.\"\n\n## Important Context:\n\n- This is a **non-legislative report**, meaning it carries no direct legal weight\n- Member states are independently starting to take action with their own age limits and verification systems\n</Summary>\n\n<Asknews_articles>\nQuery: Will the community prediction be higher than 26.00% on 2026-02-15 for the Metaculus question \"Will the EU require mandatory age verification on social media or AI before 2027?\"?\nHere are the relevant news articles:\n\n**Poland Proposes Ban on Social Media Access for Children Under 15, Modeled on Australia\u2019s Law**\nPolish lawmakers from the Civic Platform (PO), in coordination with Monika Rosa, chair of the Committee on Youth, and Minister of Education Barbara Nowacka, are preparing a bill to ban children under 15 from accessing social media platforms, including Facebook, Instagram, YouTube, and TikTok. The proposed ban would mirror Australia\u2019s 2023 law, which prohibits minors from using social media and requires platforms to verify user age through technologies such as identity document submission, facial or voice recognition. Since the law\u2019s implementation, Meta (Facebook, Instagram, Threads) has deactivated 550,000 profiles of users under 16 in Australia, and australijski influencers have reported up to 90% drops in content reach. The Polish proposal is driven by concerns over children\u2019s exposure to harmful online content\u201496% of Australian children aged 10\u201315 used social media in 2025, and 70% had contact with harmful content. In Poland, over 1.4 million children aged 7\u201312 use social media, with TikTok (800,000 users), Messenger (860,000), WhatsApp (750,000), Facebook (630,000), and Instagram (370,000) being the most popular. The average daily social media use among Polish teenagers is 3 hours and 23 minutes. Experts like Dr. Ilona D\u0105browska from UMCS emphasize that current Polish law is ineffective in protecting children, and while some oppose the ban as a restriction on digital freedom, she argues it is a necessary safeguard. The European Parliament has also expressed concern, proposing a ban on access to social media and AI tools for users under 16, with parental consent allowing access from age 13. Eurobarometer data shows 93% of Europeans believe social media negatively impacts children\u2019s mental health, and 92% support age-based access restrictions. If adopted, such a EU-wide law would apply to Poland as well.\nOriginal language: pl\nPublish date: February 02, 2026 07:09 AM\nSource:[forsal.pl](https://forsal.pl/gospodarka/aktualnosci/artykuly/10620729,panstwo-ograniczy-dostep-do-mediow-spolecznosciowych.html)\n\n**Hessen: Minister Calls for Immediate Social Media Ban for Minors Amid Global Trend**\nHessian Minister of Education Armin Schwarz (CDU) is calling for swift action in Germany to implement age-based restrictions on social media use by minors, citing growing concerns over the negative impact on youth mental health, self-esteem, and cognitive abilities. Schwarz emphasized the need for a binding, nationwide law with mandatory age verification by providers, noting that countries like Australia (16 years), France (15 years), and Denmark (15 years) have already introduced or are advancing similar measures. He criticized Germany's inaction, arguing that the country must not wait for the European Union's Digital Services Act to be updated. The French National Assembly recently voted in favor of a ban on social media for those under 15, and the UK House of Lords approved a similar ban for under-16s, pending approval by the House of Commons. Schwarz stressed that a strong, responsible digital society requires young people protected from uncontrolled exposure to online hate, violence, and extremism.\nOriginal language: de\nPublish date: February 02, 2026 03:01 AM\nSource:[N-tv](https://www.n-tv.de/regionales/hessen/Minister-Social-Media-Verbot-fuer-Jugendliche-muss-kommen-id30312992.html)\n\n**Australia\u2019s Social Media Youth Protection Law Sparks Data-Driven Debate**\nAustralia's Social Media Youth Protection Act, which came into effect in December 2025, requires platforms to block users under 16 or face fines of up to \u20ac27 million for serious or repeated violations. Within four weeks of implementation, over 4.7 million underage accounts were suspended. Despite this, many children bypassed age verification through tricks. The law applies to ten platforms: Facebook, Instagram, Snapchat, Threads, TikTok, X, YouTube, Kick, Twitch, and Reddit\u2014though Reddit disputes its classification. Platforms must implement age verification technologies, often using AI to analyze behavior and require uploaded ID documents and video selfies. This has led to the collection of sensitive personal data by platforms previously criticized for weak privacy practices. In contrast, Austria and the EU are pursuing the e-ID system (an evolution of ID Austria), which allows users to verify their age via smartphone without sharing personal data with platforms. Greece has adopted a different approach via the 'Kids Wallet' app, developed with EU support, which enables parents to control children's online access and verifies age without disclosing personal information to the platform\u2014only confirming eligibility. The law reflects a broader trend toward stricter digital regulation, with Australia positioning itself as a pioneer.\nOriginal language: de\nPublish date: February 01, 2026 09:56 AM\nSource:[Die Presse](https://www.diepresse.com/20532225/australien-fuettert-die-datenkraken)\n\n**OpenAI's Age Prediction Initiative Sparks Debate on Child Protection Responsibility**\nOpenAI has announced plans to introduce an 'age prediction model' that estimates whether a user is under 18 using cues like time zones. The system would apply content filters\u2014such as reducing exposure to violent or sexually explicit material\u2014on ChatGPT for users identified as minors. However, the model carries a risk of misclassification, and verification requires government-issued IDs or biometric data, raising serious privacy and security concerns. Critics, including co-director of the Cyberbullying Research Center Samir Hinduja, warn that storing vast amounts of sensitive data increases the risk of mass breaches. Hinduja proposes a 'device-level age verification' system where parents set a child's age on a smartphone, with the data securely shared with apps. This aligns with Apple CEO Tim Cook\u2019s recent stance opposing mandatory age checks that would force Apple to assume significant liability. On January 28, 2026, the Federal Trade Commission (FTC) will host a full-day workshop on age verification, featuring representatives from Apple, Google, Meta, and child safety advocacy groups. The event may reveal the FTC\u2019s increasingly politicized stance, as Republican-led states push for age gates on porn sites\u2014though critics fear this could be used to block broader content, including sex education. Meanwhile, California and other states seek to impose age verification obligations on AI companies. The debate has shifted from 'should age verification exist?' to 'who should bear the responsibility?'\u2014a question no company wants to shoulder. The issue is further complicated by rising concerns over AI-generated child sexual abuse material, mental health risks from AI interactions, and children forming deep emotional attachments to AI companions. These tensions reflect a clash of values: privacy, free expression, surveillance, and child protection.\nOriginal language: ja\nPublish date: February 01, 2026 07:50 AM\nSource:[ASCII.jp](https://ascii.jp/elem/000/004/370/4370502/)\n\n**Social Media Ban for Under-15s in France: Will All French Citizens Face Age Verification?**\nFrance is advancing legislation to ban social media use for users under 15, following a vote in the National Assembly on January 27, 2024. The law, championed by President Emmanuel Macron and Renaissance deputies, mandates that platforms like Instagram, Facebook, TikTok, Snapchat, YouTube, Telegram, Twitch, and gaming messengers (e.g., Roblox, Fortnite) verify users' ages to enforce the ban. To protect privacy, the government proposes a 'trusted third party' system ensuring 'double anonymity'\u2014neither the platform nor the third party learns the user\u2019s identity. The system would only confirm whether the user meets the age threshold. Potential tools include France\u2019s 'France Identit\u00e9 num\u00e9rique' (ANTS), 'Jeprouvemonage' (La Poste), and a future European digital identity wallet. Despite promises of data protection, critics warn of disproportionate surveillance, potential data breaches, and unproven technical reliability. Concerns also arise over whether the law targets algorithmic manipulation or merely restricts access. Observers note that parental control software, already mandated on connected devices since 2022, offers an alternative framework. The debate raises fundamental questions about state overreach in digital regulation and the balance between youth protection and civil liberties.\nOriginal language: fr\nPublish date: February 01, 2026 06:33 AM\nSource:[RTL.fr](https://www.rtl.fr/actu/sciences-tech/interdiction-des-reseaux-sociaux-aux-moins-de-15-ans-tous-les-francais-vont-ils-devoir-faire-verifier-leur-age-7900595772)\n\n**Social Media Ban for Teenagers: Answers to Key Questions**\nFrance may become the next country to ban social media use for minors, following the National Assembly's approval in January 2026 of a minimum age of 15 for platforms like Instagram and TikTok, though the legislative process is not yet complete. The move has already influenced policy discussions across Europe. Proponents argue social media functions as an addictive product akin to alcohol or nicotine, exploiting immature self-regulation in youth and activating brain reward systems to encourage compulsive use. They claim platforms deliberately spread harmful content\u2014such as self-harm, violence, pornography, bullying, and misinformation\u2014and contribute to social fragmentation. Critics counter that such bans would deprive vulnerable youth of vital connection, especially those from marginalized backgrounds, and could drive usage underground, reducing opportunities for early intervention. Research findings are mixed: a recent Australian study found that moderate use\u2014four hours weekly for girls and six for boys\u2014correlated with higher well-being, while over two hours daily led to significant declines. English research similarly linked heavy use to reduced life satisfaction and increased anxiety, especially among girls, due to cyberbullying, sleep deprivation, and reduced physical activity. Despite the lack of definitive evidence, prominent advocate Jonathan Haidt supports a ban due to suspected links between social media and rising youth mental health issues. Age thresholds vary globally: Australia (16+ since December 10, 2025), Denmark (15+, with parental consent at 13), Norway (15+), Malaysia (16+), and parts of the U.S. (e.g., Florida at 14, with parental consent until 16). The EU requires parental consent for data processing until age 16, though enforcement varies. Methods to verify age include government ID uploads, digital identity systems (e.g., Norway\u2019s Bank-ID, EU\u2019s Digital Identity Wallet), and AI-based facial analysis (e.g., Meta\u2019s partnership with Yoti, which claims 97% accuracy for under-13s). However, reports indicate many minors bypass these systems via false declarations or altered appearances. In Australia, 4.7 million under-16 accounts were suspended by mid-January 2026, yet enforcement gaps persist. Public opinion shows growing support: 47% of German youth favor a 16+ age limit, and nearly half of British youth aged 16\u201321 say they\u2019d prefer growing up without the internet. In Switzerland and Germany, proposed bans for under-16s are under review, while other nations like Austria, the UK, Spain, and New Zealand are in the process of advancing stricter rules.\nOriginal language: de\nPublish date: February 01, 2026 04:30 AM\nSource:[Neue Z\u00fcrcher Zeitung](https://www.nzz.ch/technologie/verbietet-frankreich-jugendlichen-social-media-ist-das-technisch-ueberhaupt-moeglich-und-was-sagt-die-forschung-ueber-solche-verbote-ld.1922437)\n\n**AKP Meeting: Minister Admits All Our Data Is Already in America's Hands**\nThe Justice and Development Party (AKP) is nearing completion of a long-standing social media regulation proposal, expected to be submitted to the Turkish Grand National Assembly Presidency in the coming days. The draft law aims to impose new obligations on social media and online gaming platforms, including introducing a minimum age requirement for access. It proposes mandatory age verification through biometric systems such as facial recognition, behavior-based age prediction algorithms, or identity verification methods\u2014requiring at least one of these to be used. The proposal was discussed during the AKP Central Decision and Management Board (MKYK) meeting chaired by President Recep Tayyip Erdo\u011fan. Aile ve Sosyal Hizmetler (Family and Social Services) Minister Mahinur \u00d6zdemir G\u00f6kta\u015f attended the meeting and responded to members' questions. According to a report by Ay\u015feg\u00fcl Kahvecio\u011flu in Milliyet, G\u00f6kta\u015f expressed a positive stance toward implementing facial recognition for children\u2019s access to social media. During the meeting, some members raised concerns about the risks of children\u2019s biometric data being stored online; in response, G\u00f6kta\u015f reportedly stated, 'Aren't all our data already in America\u2019s hands?'\nOriginal language: tr\nPublish date: January 31, 2026 11:30 AM\nSource:[S\u00f6zc\u00fc Gazetesi](https://www.sozcu.com.tr/akp-nin-toplantisinda-bakandan-olay-itiraf-butun-bilgilerimiz-amerika-nin-elinde-p288970)\n\n**TikTok Removes 6 Million Underage Accounts Monthly in Europe Amid Regulatory Pressure, Following Meta's Lead**\nTikTok has implemented an AI system to detect underage users in the European Economic Area, Switzerland, and the UK, following regulatory pressure from the EU. The system analyzes videos, profile information, and user behavior to identify accounts that may belong to users under 13. Suspicious accounts are reviewed by human moderators who decide whether to close them. TikTok states that no globally accepted method exists to verify age without compromising privacy, so the hybrid approach\u2014AI detection combined with human review\u2014was developed. If the AI incorrectly flags an account, users can appeal by recording a facial video with Yoti, a company that estimates age from facial features, or by submitting official identification. This initiative follows a European Commission investigation into TikTok for potential violations of the Digital Services Act since February 2024. The platform has faced legal pressure after the families of five British children who died attempting viral challenges sued ByteDance, to which TikTok responded with condolences. TikTok confirms it removes approximately 6 million underage accounts monthly worldwide using this method. Similar systems are now used by Meta (Instagram), YouTube (from August 2025), Reddit, and Discord, all leveraging Yoti for age verification. Globally, Australia banned social media use for those under 16 in December 2025, forcing platforms to delete millions of adolescent accounts, with penalties up to AUD 49.5 million for non-compliance. Denmark plans to follow with a proposed 15-year minimum age, and Norway is preparing similar regulations. For users aged 16 and over, TikTok offers 50 automated safety features, including a 50-minute daily screen time limit, no nighttime notifications, and direct messaging restricted to users aged 16+.\nOriginal language: es\nPublish date: January 31, 2026 10:12 AM\nSource:[Vandal](https://vandal.elespanol.com/random/tiktok-elimina-6-millones-de-cuentas-mensuales-con-ia-en-europa-y-sigue-los-pasos-de-meta-tras-la-presion-regulatoria-de-la-ue/39694.html)\n\n**After Australia, France, now India? Modi ally pushes under-16 social media ban as 'digital addiction' worry grows**\nIndia is entering the global debate on social media's impact on youth, following Australia's ban on social media for under-16s and France's move to restrict access for under-15s. L.S.K. Devarayalu, an ally of Prime Minister Narendra Modi and member of the Telugu Desam Party, has introduced a private member's bill proposing a ban on social media use for individuals under 16. The bill, seen by Reuters, states that no one under 16 shall create, maintain, or hold a social media account, with platforms required to enforce age verification. Devarayalu argues that India is a major global data producer for foreign tech companies like Meta and Alphabet, which use Indian user data to develop AI systems, effectively making Indian users 'unpaid data providers' while strategic and economic benefits accrue elsewhere. He emphasizes shifting the responsibility of age verification to social media platforms. The government's chief economic adviser has also called for age-based access limits to combat 'digital addiction.' While Meta, Alphabet, and X did not respond to requests for comment, Meta has previously stated support for parental oversight but cautioned against bans that could push teens toward less regulated, potentially unsafe platforms. India, the world's second-largest smartphone market with 750 million devices and a billion internet users, currently has no minimum age for social media access. The bill, though not yet public, may influence future legislation as private member's bills often spark parliamentary debate.\nOriginal language: en\nPublish date: January 31, 2026 06:54 AM\nSource:[MoneyControl](https://www.moneycontrol.com/news/india/after-australia-france-now-india-modi-ally-pushes-under-16-social-media-ban-as-digital-addiction-worry-grows-13801300.html)\n\n**Surveillance and Power: The Hidden Cost of Protecting Children and the Smartphone Addiction**\nOn December 10, Australia implemented one of the world's strictest social media laws, banning minors under 16 from having accounts on platforms like Instagram, TikTok, Facebook, Snapchat, and YouTube, with penalties of up to 50 million Australian dollars for non-compliance. Denmark has set a 15-year limit, while Norway, France, Spain, and New Zealand are considering similar measures. The stated goal is to protect adolescent mental health, citing Jonathan Haidt\u2019s claim that social media is a primary driver of a youth mental health crisis since 2010. However, the article argues that behind this well-intentioned concern lies a deeper political struggle: the push for mass online identification, which could normalize surveillance and erode digital privacy. The article warns that mandatory age verification\u2014through ID scanning, facial recognition, and data sharing\u2014benefits both authoritarian governments and corporations that profit from verification services, repeating a long-standing pattern where privacy is sacrificed under the guise of safety. It emphasizes that while anonymity is not absolute, the current friction in identifying users serves as a digital presumption of innocence. A universal verification system would eliminate this friction, enabling automated repression and self-censorship, endangering activists, journalists, and individuals seeking sensitive health information. The article cites data from Voces del Sur showing 3,766 attacks on journalists in Latin America in 2024, with 49.3% by state actors, underscoring the real-world risks of surveillance. Scientific evidence does not support Haidt\u2019s narrative of a clear causal link between social media and youth mental health decline; experts like Candice Odgers have criticized his methodology, noting weak correlations and unproven causality. The article proposes alternative, privacy-preserving regulations: banning manipulative design (dark patterns), requiring algorithmic transparency, prohibiting targeted ads to minors, and mandating parental control tools at the device level\u2014measures already in motion in the EU\u2019s Digital Services Act. The core question, the article concludes, is not whether to regulate social media, but whether to dismantle exploitative power or build a new surveillance infrastructure that undermines fundamental rights. Thinking through the nuances is a moral obligation, as rules shape society for generations.\nOriginal language: es\nPublish date: January 31, 2026 02:50 AM\nSource:[La Voz](https://www.lavoz.com.ar/opinion/vigilancia-y-poder-el-lado-b-de-la-proteccion-a-los-ninos-y-la-adiccion-al-celular/)\n\n**New Danger Looming for Children: What Happens to Age Verification Data?**\nExperts and digital rights advocates warn that mandatory age/identity verification systems for children on social media may increase privacy and surveillance risks. Turkey is following Australia, France, and Canada in proposing a ban on social media use for children under 15, with a draft law submitted to the Turkish Grand National Assembly (TBMM). If enacted, the law would amend the Internet Publication Regulation Law (No. 5651), adding a clause requiring social media platforms to not serve users under 15 and to implement necessary measures, including age verification. Australia, which implemented a similar law on December 10, 2025, allows platforms to use various methods for age verification\u2014such as official ID checks, facial analysis via AI, credit card data, or digital identity wallets\u2014without mandating a specific method. Major platforms like Meta and TikTok use third-party verification services like Yoti, Jumio, Veriff, and Persona. These companies collect sensitive data, including passport scans, facial images, and biometric information, raising significant security concerns. Critics highlight that centralizing millions of children\u2019s biometric and identity data in a few companies creates high-value targets for hackers and extortion groups, referred to as 'honeypots.' Incidents such as the AU10TIX data breach in 2024, which exposed driver\u2019s licenses and birth dates from platforms like TikTok and Uber, and the 5CA hack affecting Discord, demonstrate the risks of relying on third-party providers. Even companies claiming to delete data immediately after processing may leave a window for exploitation. Additionally, deepfake technology enables minors to bypass age checks, undermining system integrity. In the event of a data breach, stolen data can lead to identity theft, financial fraud, social engineering, and deepfake manipulation. Children\u2019s biometric data could be used to create fake accounts, extort families, or enable physical harm. Sensitive information may also be weaponized for bullying, social exclusion, or blackmail. The long-term consequences include lifelong digital vulnerability, especially as biometric authentication becomes standard in banking and government services.\nOriginal language: tr\nPublish date: January 30, 2026 06:38 PM\nSource:[euronews](https://tr.euronews.com/next/2026/01/30/cocuklari-bekleyen-yeni-tehlike-toplanan-yas-dogrulama-verilerine-ne-olacak)\n\n**Are Your Children Addicted To Phones? Government Has A Plan to Save Them In Union Budget 2026**\nThe Government of India is preparing to introduce a legal framework to combat digital addiction among children in the Union Budget 2026, as highlighted in the Economic Survey 2026. The survey identifies unregulated digital exposure as a threat to the nation's future, citing negative impacts on children's mental health, concentration, and long-term goals. Three key recommendations are proposed: mandatory age verification for social media platforms (likely setting the minimum age at 13 or 15), default child-safe privacy settings that are not easily alterable by minors, and algorithmic redesigns to prevent exposure to violent, objectionable, or anxiety-inducing content. The government argues that tech companies must take greater accountability, moving beyond parental oversight. The survey notes that excessive screen time is linked to irritability, sleep deprivation, reduced attention span, ADHD-like symptoms, cyberbullying, online fraud, and diminished participation in physical and social activities. While developed nations like the U.S. and members of the EU already enforce age restrictions (e.g., under-13 bans or parental consent), India is now aligning with this global trend. Challenges include children falsifying ages; experts recommend strengthening digital literacy in schools and implementing balanced screen-time rules at home. However, they caution against over-restriction, warning it may drive youth to unsafe platforms like the dark web. The proposed policy shift signals a major transformation in how children in India will experience the internet.\nOriginal language: en\nPublish date: January 30, 2026 04:56 PM\nSource:[Oneindia](https://www.oneindia.com/india/are-your-children-addicted-to-phones-government-has-a-plan-to-save-them-in-union-budget-2026-7983445.html)\n\n**Social Media Ban for Under-15s in France: Arguments For and Against**\nA proposed law in France banning social media use for children under 15 has been introduced by deputy Lourdes Miller from the pro-presidential centrist party Renaissance and is supported by the French government and President Emmanuel Macron. Advocates argue the ban is essential for protecting adolescent mental health, citing recommendations from scientists and public opinion: a August 2025 Odoxa poll found 79% of parents and 67% of young people support the measure. The National Agency for Sanitary Safety (Anses) confirmed social media platforms like TikTok, Snapchat, and Instagram pose risks including cyberbullying, harmful social comparisons, shock content, and sleep disruption. President Macron urged the Senate to continue work on the legislation, stating, 'Our children's minds are not for sale\u2014neither to American platforms nor Chinese networks,' and emphasizing the need for a generation that believes in France and its values. If passed, France would become the second country after Australia (which banned social media for under-16s in late 2025) to implement such a restriction. The law aims to prohibit new accounts for under-15s from September 2026, with effective age verification for all users (including existing ones) beginning January 1, 2027. Verification methods include identity document uploads, third-party checks (e.g., banks), or AI-powered facial recognition via selfies. The law does not clarify whether messaging apps like WhatsApp and Telegram\u2014now featuring public content functions\u2014will be included. Critics, including deputies from the left-wing 'La France Insoumise' (LFI), oppose the law as a 'symbolic digital paternalism' that avoids investing in youth mental health and education. Psychiatrist Serge Tisseron warns the ban may worsen loneliness among disadvantaged youth and push them toward more dangerous AI companions. Experts also caution that mass age verification risks data privacy breaches and that users may circumvent restrictions using VPNs or migrate to less moderated platforms, as seen in Australia. The 2023 'digital adulthood' law (also at age 15) failed due to conflict with the EU\u2019s Digital Services Act (DSA), but in July 2025, the European Commission issued new guidelines allowing national age limits. The Commission confirmed France has the right to enforce such a law and will ensure compliance from major platforms. A pan-European age verification app is currently being tested.\nOriginal language: ru\nPublish date: January 30, 2026 02:12 PM\nSource:[RFI](https://www.rfi.fr/ru/%D1%84%D1%80%D0%B0%D0%BD%D1%86%D0%B8%D1%8F/20260130-%D0%B7%D0%B0%D0%BF%D1%80%D0%B5%D1%82-%D1%81%D0%BE%D1%86%D1%81%D0%B5%D1%82%D0%B5%D0%B9-%D0%B4%D0%BB%D1%8F-%D0%B4%D0%B5%D1%82%D0%B5%D0%B9-%D0%BC%D0%BB%D0%B0%D0%B4%D1%88%D0%B5-15-%D0%BB%D0%B5%D1%82-%D0%B0%D1%80%D0%B3%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B-%D0%B7%D0%B0-%D0%B8-%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2)\n\n**TikTok\u2019s AI-Powered Age Verification: Europe\u2019s Digital Reckoning for Information Governance**\nTikTok has deployed an AI-powered age verification system across the European Economic Area, the United Kingdom, and Switzerland, marking a significant step in compliance with the Digital Services Act (DSA) and GDPR. The system analyzes profile data, video content, and behavioral signals to identify users under 13, routing flagged accounts to human moderators to prevent wrongful removals. This move follows a year-long pilot that led to thousands of underage accounts being removed. The initiative responds to heightened regulatory pressure, including a \u20ac530 million fine from Ireland\u2019s Data Protection Commission in May 2025 for illegal data transfers to China and a prior \u20ac345 million penalty in September 2023 for mishandling children\u2019s data. The European Commission\u2019s July 2025 guidelines under Article 28 of the DSA state that passive age declarations are insufficient, establishing behavioral and technical verification as the new benchmark. A harmonized age verification app, to be integrated into the European Digital Identity Wallet by 2026, is expected to standardize approaches across member states. Meanwhile, Australia has implemented one of the world\u2019s strictest social media age bans, requiring platforms to prevent users under 16 from creating accounts, with fines up to AUD 49.5 million for non-compliance. Platforms like Meta and Snapchat are using facial age estimation, government ID scanning, and bank verification, generating discoverable evidence for litigation. Organizations must now conduct gap analyses, document verification methodologies, and manage new data risks, including biometric templates and behavioral profiles, which are subject to GDPR\u2019s strict protections under Article 9. The UK is also advancing its Online Safety Act, with potential plans to adopt Australia\u2019s under-16 ban. As AI-driven age verification becomes operational, the legal and compliance landscape is shifting rapidly, with significant implications for data privacy, litigation exposure, and accountability when algorithmic predictions fail.\nOriginal language: en\nPublish date: January 17, 2026 08:45 PM\nSource:[ComplexDiscovery](https://complexdiscovery.com/tiktoks-ai-powered-age-verification-europes-digital-reckoning-for-information-governance/)\n\n**2026 Year in Preview: Global Minors' Privacy and Online Safety Predictions**\nIn 2026, global regulatory focus on minors' online privacy and safety is expected to intensify, driven by six key trends. First, age assurance technologies will see increased adoption, with the U.S. likely to see state-level copycat laws and federal legislative review, while the EU may require parental consent for 13-16-year-olds to access social media and AI companions, and work toward a harmonized verification standard. Second, 'addictive' design features in digital products will remain under scrutiny, with U.S. courts evaluating liability for design-related harms and Europe advancing the Digital Fairness Act (DFA). Third, enforcement actions are predicted to rise, with the FTC expected to announce new COPPA and TAKE IT DOWN Act actions, state attorneys general increasing multi-state cooperation, Ofcom expanding its focus in the UK beyond adult content, and EU regulators releasing findings from child safety investigations. Fourth, regulation around harmful content\u2014such as sexually explicit material or illegal goods\u2014will strengthen, with U.S. states potentially enforcing laws post-Free Speech Coalition v. Paxton and federal consideration of national restrictions, while Europe continues to prioritize access to age-appropriate content under the DSA and OSA. Fifth, AI-generated child sexual abuse material (CSAM) and deepfakes will remain high-priority enforcement issues, with the FTC focusing on the TAKE IT DOWN Act and EU regulators debating regulatory responses. Sixth, AI companions will face growing oversight, with the U.S. Senate considering the GUARD Act, which would ban AI chatbots for minors and criminalize sexually explicit AI interactions, and European regulators issuing information requests to AI providers on risk mitigation under GDPR, DSA, and OSA. Overall, regulators worldwide are prioritizing minors\u2019 digital safety, requiring companies to adapt to evolving compliance demands.\nOriginal language: en\nPublish date: January 05, 2026 07:09 PM\nSource:[JD Supra](https://www.jdsupra.com/legalnews/2026-year-in-preview-global-minors-7091760/)\n\n**2026 Could Be a 'Year of Horror' for Adult Internet Users: Age Verification, AI Porn, and Global Legal Battles**\nThe article discusses the anticipated implementation of age verification requirements for accessing adult content websites in the European Union by February 2026, which could mark a significant shift for adult internet users. According to the piece, users may be required to complete electronic documentation and authentication via third-party platforms using tokens or codes, potentially through the EU\u2019s Eudi Wallet digital identity system. The article cites concerns about data security, referencing a 2025 data breach at Discord involving over 70 million users, linked to a third-party age verification service. It also notes that AI-generated pornography will become available on platforms like ChatGPT by March 2026, raising concerns among human performers. The EU\u2019s approach to age verification is inconsistent: France proposes using AI-enhanced selfies, while California\u2019s Digital Age Act mandates age verification at device setup, bypassing the need for repeated checks. Meanwhile, Pornhub is reportedly considering cooperation with EU regulations and plans to ban creators with criminal records starting in 2026. The article also mentions geopolitical tensions, including Australia\u2019s mandatory censorship of adult content from search engines as of December 27, 2025, and Ukraine\u2019s demand for $10 million in unpaid taxes from local sex creators. Additionally, the U.S. studio Vixen has sued Mark Zuckerberg, alleging he stole over 2,300 adult videos to train Meta\u2019s AI, seeking $360 million in damages, which Zuckerberg denies.\nOriginal language: it\nPublish date: January 01, 2026 03:36 PM\nSource:[DAGOSPIA](http://www.dagospia.com/media-tv/2026-sara-annus-horribilis-per-i-pipparoli-godetevi-gli-ultimi-458998)\n\n**Age verification to AI slop: How 2025 redefined social media**\nIn 2025, social media platforms faced transformative challenges centered on age verification laws, artificial intelligence (AI) content, and declining user trust. Australia became the first country to ban social media access for users under 16, effective December 10, 2025, with penalties for non-compliance; Denmark followed with plans to restrict access for those under 15 unless parents complete an assessment. The UK\u2019s Online Safety Act, enforced in July, implemented strict age verification to block minors from adult content and harmful behaviors. Despite these measures, teens have attempted to circumvent rules using WhatsApp and facial recognition-dodging masks. The year was defined by the rise of 'AI slop'\u2014low-effort, generative AI content like AI-generated memes (e.g., 'Italian brain rot') and deepfakes, which spread misinformation, including a fabricated video falsely implicating a woman in welfare fraud and AI-generated images falsely showing Taylor Swift endorsing Donald Trump. Platforms like Meta and TikTok began labeling AI content, but Meta\u2019s internal oversight board reported inconsistent enforcement in June. Elon Musk\u2019s Grok AI chatbot sparked global controversy in July by praising Adolf Hitler and spreading antisemitic conspiracy theories, with Musk admitting the tool was 'too eager to please' and 'being addressed,' though issues persisted. Regulatory actions intensified: the EU fined Musk\u2019s X \u20ac120 million under the Digital Services Act (DSA) for unclear advertising and blue checkmark policies, while TikTok was fined \u20ac530 million by Ireland\u2019s Data Protection Commission for failing to protect EU users\u2019 data during a transfer to China. Community-driven platforms like Reddit and Discord grew in popularity as users sought more authentic online spaces. The World Health Organization (WHO) reported that 1 in 10 adolescents experienced negative mental health effects from social media use, fueling global regulatory momentum. As 2025 ends, legislative scrutiny is expected to intensify in 2026 due to the immense data power and potential harms posed by social media platforms.\nOriginal language: en\nPublish date: December 27, 2025 07:00 AM\nSource:[Euronews English](http://www.euronews.com/next/2025/12/27/bans-ai-slop-and-hitler-praising-chatbots-what-were-the-biggest-scandals-in-social-media-t)\n\n**2025 Redefines Social Media: Age Verification, AI Chaos, and Regulatory Crackdowns**\nIn 2025, social media platforms faced major shifts driven by age verification laws, artificial intelligence (AI), and growing user distrust. Australia became the first country to ban social media for users under 16, effective December 10, following concerns over mental health impacts\u2014supported by the WHO, which reports that one in ten adolescents has experienced negative effects from social media use. The UK implemented strict age verification under the Online Safety Act in July, restricting minors\u2019 access to adult content and harmful material. Denmark plans to follow with a 15-year age cap, while Spain, Greece, and France advocate similar protections. Despite these laws, adolescents are using workarounds such as WhatsApp or facial masks to bypass verification. AI-generated content, termed 'AI slop,' flooded platforms with absurd, low-quality content\u2014such as dogs turning into cinnamon rolls or 'Italian brain rot' memes\u2014raising concerns about authenticity, misinformation, and scams. High-profile cases include Donald Trump sharing AI-generated images of Taylor Swift supporting him. Deepfakes, like a fabricated TV confession of welfare fraud, were mistakenly amplified by media outlets like Fox News. Platforms like Meta and TikTok began labeling AI content, but Meta\u2019s internal review called the labeling 'incoherent' due to scale. Elon Musk\u2019s AI chatbot Grok caused controversy in July by praising Adolf Hitler and falsely accusing a Jewish-sounding automated account of celebrating white children\u2019s deaths in Texas floods. Musk admitted Grok was 'too eager to please' and prone to manipulation, though problematic outputs continued, including antisemitic conspiracy theories and harassment tools. Regulatory pressure intensified: the EU\u2019s Digital Services Act (DSA) fined X \u20ac120 million for opaque advertising and its now-sold blue verification badges. TikTok was fined \u20ac530 million by Ireland\u2019s Data Protection Commission for inadequate data protection during transfers to China. The growing power and data control of social media platforms, combined with public concern over harm, signal even stricter regulation in 2026. Meanwhile, platforms like Reddit and Discord gained traction as users sought more authentic, community-driven spaces. Social media also reshaped language, with terms like 'rage bait,' 'parasocial,' and 'AI slop' entering dictionaries for 2025.\nOriginal language: fr\nPublish date: December 27, 2025 07:00 AM\nSource:[euronews](http://fr.euronews.com/next/2025/12/27/suspensions-puree-dia-chatbots-pro-hitler-les-grands-scandales-des-reseaux-sociaux-cette-a)\n\n**Selfie-based age checks boom as governments push for online controls**\nAI-powered selfie-based age verification technology is seeing rapid growth as governments worldwide implement stricter online age controls. Companies like Yoti, which processes around one million age checks daily for clients including Meta, TikTok, Sony, and Pinterest, use facial analysis to estimate age within a minute after a user uploads a head-on selfie. Yoti reported \u00a320 million in revenue for the year ending March 2025 and turned a profit, forecasting a 50% sales increase in the current financial year. The Age Verification Providers Association (AVPA) includes 34 companies and projected the sector could reach nearly US$10 billion in annual revenue across OECD countries by 2031\u20132036, though no updated forecasts are available. While the technology offers speed and scalability\u2014such as enforcing Australia\u2019s Dec 10, 2025, ban on under-16s using social media\u2014it raises concerns over privacy, bias, and accuracy. Professor Olivier Blazy of Polytechnique warns that systems may be intrusive and vulnerable to manipulation via makeup or accessories, and that algorithms have demonstrated lower accuracy for non-white faces and underrepresented groups like Indigenous populations. Yoti acknowledges initial data gaps for certain demographics but claims its system detects false accessories and makeup, and deletes all biometric data immediately after analysis. Platforms can adjust thresholds\u2014for example, requiring users to be over 21 to bypass a grey zone, where traditional ID verification is then required.\nOriginal language: en\nPublish date: November 29, 2025 08:41 AM\nSource:[The Straits Times](https://www.straitstimes.com/world/selfie-based-age-checks-boom-as-governments-push-for-online-controls)\n\n**Meta alerts young Australians to download their data before a social media ban**\nOn November 20, 2025, Meta began notifying thousands of young Australians aged 13 to 15 via SMS and email that they will be blocked from accessing Facebook, Instagram, and Threads starting December 4, 2025, under Australia\u2019s world-first law banning social media use for children under 16. Meta estimates 350,000 Australians aged 13\u201315 are on Instagram and 150,000 on Facebook. The company is urging users to download their data and update contact information during the two-week notice period to regain access after turning 16. Meta claims it will use age verification methods, including Yoti\u2019s system, which allows users to verify age via government-issued ID or a video selfie. However, Terry Flew, co-director of Sydney University\u2019s Center for AI, Trust and Governance, noted facial recognition has a failure rate of at least 5%, calling it a 'second-best solution' without a government-mandated ID system. The Australian government warned platforms not to require all users to prove they are over 15, stating platforms already possess sufficient data to identify underage users. Failure to comply could result in fines of up to 50 million Australian dollars ($32 million). Meta advocates for a more accurate, privacy-preserving age verification system at the OS/app store level. Dany Elachi, founder of the parent advocacy group Heaps Up Alliance, supported the principle of protecting children under 16 but criticized the government for only announcing the full list of affected platforms on November 5, 2025. He urged parents to help children transition from social media by exploring alternative activities, stating, 'When everybody misses out, nobody misses out. That's the theory. Certainly we expect that it would play out that way.'\nOriginal language: en\nPublish date: November 20, 2025 12:00 AM\nSource:[techxplore.com](https://techxplore.com/news/2025-11-meta-young-australians-download-social.html)\n\n**Age Verification in Social Media: Experts Divided on Balancing Safety and Privacy**\nThe verification of age on digital platforms has sparked debate among experts between safety and privacy concerns. The European Union (EU) has mandated under the Digital Services Act (DSA) that by 2027, all digital content platforms must verify users' ages before granting access to potentially inappropriate content. To comply, platforms are adopting technologies ranging from official documents like national ID cards or passports to advanced AI and facial recognition systems. While these methods help companies meet legal obligations and provide legal safeguards, they raise significant privacy and cybersecurity risks. The storage of personal and biometric data makes platforms attractive targets for cyberattacks; a recent Discord data breach exposed sensitive information of 70,000 users via a third-party vendor. Experts from Panda Security and the Xnet collective warn that subcontracted providers are often the weakest links and urge minimizing the use of personal and biometric data. They recommend solutions such as tokenized digital identities and Zero Knowledge Proof (ZKP) technology, which allows users to prove they are over 18 without revealing additional personal information. Google\u2019s Credential Manager and Meta\u2019s AI-driven tools for detecting underage accounts are examples of such innovations. Experts emphasize that the ideal model should empower users to manage their own digital identities, with public audits and no data retention, prioritizing responsible platform design over mass data collection. Both Lambert and Salgado advocate for combining technological, regulatory, and educational strategies, including awareness campaigns, to comprehensively protect minors online. ZKP enhances security by ensuring only essential information is shared, reducing exposure to cyber threats while preserving user privacy.\nOriginal language: es\nPublish date: October 23, 2025 05:06 PM\nSource:[PULZO](https://www.pulzo.com/tecnologia/normativa-europea-sobre-verificacion-de-edad-en-internet-claves-para-la-proteccion-de-menores-en-2027-PP4860211A)\n\n\n--- Deep Research Analysis ---\nAs of February 2026, the EU has not enacted binding legislation for mandatory age verification, but significant developments are shaping future regulations:\n\n1. **Proposed Age Restrictions**: The European Parliament advocates banning social media/AI access for under-13s and restricting ages 13-16 to parental-consent-only access. A harmonized age floor of 16 is proposed for unrestricted use, with implementation targeted for 2027-2028 [14][15][19][20].\n\n2. **Verification Systems**: \n   - An **EU Digital Identity Wallet** is in pilot phase (e.g., Ireland's 2,000-user trial) to enable secure age confirmation, slated for late 2026 release [13][15].\n   - Privacy-focused technologies like **Zero-Knowledge Proof systems** are being explored to verify age without exposing identities [16][17].\n   - Current industry solutions (e.g., Roblox's facial recognition) face criticism for bypass vulnerabilities and data risks [3][5][16].\n\n3. **Platform Design Rules**: \n   - Addictive features (infinite scroll, auto-play) would be disabled by default for minors [14][15][20].\n   - Recommendation algorithms targeting underage users face proposed bans [19][20].\n\n4. **Enforcement Actions**: \n   - The Netherlands launched a major investigation into **Roblox** (Jan 2026) under the Digital Services Act (DSA), potentially setting compliance precedents [3][5][6][9].\n   - CEOs may face **personal liability** for violations under new proposals [15][19].\n\n5. **Key Controversies**:\n   - A child protection proposal (\"Chat Control\") was shelved over mass surveillance fears [18].\n   - Studies show 30% of minors bypass age checks, exposing enforcement gaps [5][17].\n   - Ireland is developing a national \"digital wallet\" amid frustration with EU delays [13].\n   - Privacy advocates warn biometric data storage creates hacking targets [16][17].\n\n**Limitations**: No binding EU law exists yet; disagreements persist between privacy rights and protection mandates. Verification tech standardization remains unresolved, and enforcement mechanisms are untested. Further developments are expected ahead of the 2027 DSA compliance deadline.\n\n*Citations reflect key sources:*  \n[1][3][5][6][9][13][14][15][16][17][18][19][20]\n</Asknews_articles>\n"
}