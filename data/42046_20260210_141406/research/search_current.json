{
  "context": "\n<Summary source=\"https://legalblogs.wolterskluwer.com/copyright-blog/second-and-third-drafts-of-the-general-purpose-ai-code-of-practice-have-been-released/\">\n# Summary of Article: Second and Third Drafts of GPAI Code of Practice\n\n**Source:** Kluwer Copyright Blog\n\n## Key Facts and Timeline:\n\n1. **Three drafts have been released:** The article discusses the second and third drafts of the General-Purpose AI (GPAI) Code of Practice.\n\n2. **Third draft timeline:**\n   - The third draft is set to be the last draft of the Code\n   - Stakeholders could provide written feedback by March 30, 2025\n   - The final version of the Code is expected by May 2, 2025\n\n3. **Second draft improvements:** Compared to the first draft, the second draft included:\n   - New obligations for AI providers of GPAI models and GPAI models with systemic risk (GPAISR)\n   - More detailed provisions and concrete examples\n   - Specific guidance on proportionality of measures and key performance indicators (KPIs)\n   - Refined approach to proportionality for different sizes and types of providers\n\n4. **Third draft changes:**\n   - Does NOT include KPIs (unlike the second draft)\n   - Instead sharpens reporting commitments\n   - Working Groups confirmed the final adopted version will not contain any KPIs\n   - Introduces a user-friendly Model Documentation Form\n   - Requires disclosure if external input (including from government actors) informs GPAISR development or use\n   - Adjusted commitment so providers only publicly share systemic risk information where necessary to assess and mitigate risks\n   - AI Office will conduct regular reviews every two years\n\n5. **Copyright-related measures:**\n   - Providers must take reasonable measures to exclude widely known piracy websites from crawling\n   - Must make public information about measures to comply with rights reservations\n   - Must designate a point of contact for rightsholders and enable complaint lodging\n\n## Opinions and Analysis:\n\n**From Working Groups (named source):**\n- The third draft \"still does not contain the level of clarity and coherence that we expect in the final adopted version of the Code\"\n\n**From article authors (unnamed analysis):**\n- The Code is \"generally a step in the right direction\"\n- Current draft doesn't cover significant issues like clear guidance on handling datasets with infringing content, deepfake labelling, and creator compensation strategies\n- Anticipate \"more meat on the bones\" in the final version\n- SME exclusions from some obligations \"may be seen as a loophole\"\n- Many large providers have indicated they will not sign the Code, arguing it should clarify the AI Act instead of imposing new obligations\n- Questions raised about overall usefulness since adherence doesn't constitute conclusive evidence of AI Act compliance\n- Predict the finalized Code will have widespread global influence beyond the EU\n\n**Links provided:**\n- Second draft available at specified link\n- Third draft available at specified link\n- AI Office Q&A document available\n</Summary>\n\n<Summary source=\"https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai\">\n# Summary of Article on General-Purpose AI Code of Practice\n\n## Key Facts and Timeline:\n\n1. **Publication Date**: The GPAI code of practice was published on **July 10, 2025**.\n\n2. **Current Status**: The code has been endorsed by the Commission and the AI Board as an adequate voluntary tool for GPAI model providers to demonstrate compliance with the AI Act.\n\n3. **Structure**: The code consists of three separately authored chapters:\n   - Transparency (with a Model Documentation Form)\n   - Copyright\n   - Safety and Security (only relevant for models with systemic risk)\n\n4. **Legal Framework**: \n   - Transparency and Copyright chapters help providers comply with Article 53 of the AI Act\n   - Safety and Security chapter addresses Article 55 obligations for advanced models with systemic risk\n\n5. **Voluntary Nature**: The code is a voluntary tool prepared by independent experts in a multi-stakeholder process\n\n6. **Signatories**: As of the article's publication, 28 entities have signed the code (list includes major AI companies like Amazon, Anthropic, Microsoft, OpenAI, etc.). Note: xAI signed only the Safety and Security Chapter.\n\n7. **Implementation**: A Signatory Taskforce has been established, chaired by the AI Office, to facilitate coherent application of the Code.\n\n## Relevant to the Forecasting Question:\n\nThe article describes the **current published version** of the code (July 10, 2025) but does **not mention any plans, timelines, or intentions to publish a revised draft or new version** of the code. The content focuses on the existing code's structure, signature process, and implementation mechanisms.\n</Summary>\n\n<Summary source=\"https://iapp.org/news/a/european-commission-receives-final-version-of-general-purpose-ai-code-of-practice\">\n# Summary of Article: \"European Commission receives final version of General-Purpose AI Code of Practice\"\n\n**Key Facts:**\n\n1. **Final Version Received**: The European Commission has received the final version of the General-Purpose AI Code of Practice, which is voluntary for organizations demonstrating compliance with the EU AI Act.\n\n2. **Timeline Information**:\n   - The code was originally supposed to come out in May (presumably 2025)\n   - This is months before the AI Act's rules on GPAI are scheduled to start in August (presumably 2025)\n   - The code was developed over several drafts beginning in September 2024\n\n3. **Development Process**: The code was developed by 13 independent experts with input from more than 1,000 stakeholders.\n\n4. **Next Steps**: Member states and the Commission will need to officially endorse the code before providers of GPAI can voluntarily sign on.\n\n**Named Source Opinions:**\n\n1. **Commission Executive Vice-President Henna Virkkunen**: Urged organizations to sign onto the code, stating it will make AI safe and transparent while allowing for innovation. She described it as \"co-designed by AI stakeholders\" and aligned with their needs.\n\n2. **MEP Brando Benifei**: Stated \"Model providers obtained important concessions, so there's no excuse not to uphold the Code.\" He emphasized that credibility depends on the AI Office's ability to translate commitments into practice with robust oversight.\n\n3. **Group of MEPs (including Benifei, Michael Mc Namara, Axel Voss, Sergey Lagodinsky, and Kim Van Sparrentak)**: Alleged the Commission allowed last-minute removals of elements around public transparency and weaker risk assessment provisions. They expressed concern that the code narrows the scope of the adopted act and creates legal uncertainty. They also complained that the European Parliament was not consulted on significant changes to the final draft.\n\n4. **Marco Leto Barone (Information Technology Industry Council policy director)**: Said companies will have to decide if the code is workable, and emphasized that \"clear and well-scoped Commission guidelines are now essential.\"\n\n**General Industry/Stakeholder Reactions (less specific attribution):**\n\n- Industry groups said the code continued to be too restrictive\n- Civil society and safety advocates argued the drafters were too deferential to technology companies' demands\n- Technology businesses have pressed the Commission to delay enforcement of the act (which the Commission has refused)\n- Companies have been described as \"left in the dark\" with little time for compliance\n\n**Compliance Requirements for Signatories:**\n\n- Must understand systemic risks and take steps to monitor and mitigate them\n- Must maintain estimates of timelines for when models might exceed highest risk tiers\n- Must provide descriptions of systemic risk acceptance criteria and security measures\n- Must maintain model documentation (with some exceptions for open-source models)\n</Summary>\n\n<Summary source=\"https://www.jonesday.com/en/insights/2025/08/eu-ai-act-european-commission-publishes-generalpurpose-ai-code-of-practice\">\n# Summary of Article: \"EU AI Act: European Commission Publishes General-Purpose AI Code of Practice\"\n\n**Source:** Jonesday\n\n## Key Facts and Timeline:\n\n1. **Publication Date:** On 10 July 2025, the EU Commission published the GPAI Code of Practice.\n\n2. **Structure:** The Code of Practice is divided into three chapters:\n   - Transparency\n   - Copyright\n   - Safety & Security\n\n3. **Development Process:** The Code resulted from several months of work with a multistakeholder drafting group and the EU AI Office, involving nearly 1,000 participants.\n\n4. **Voluntary Nature:** The Code of Practice is a voluntary tool that GPAI model providers can adopt to demonstrate compliance with Articles 53 and 55 of the AI Act.\n\n5. **Expected Endorsement Timeline:** According to the article, the Code of Practice \"is expected to be endorsed by the EU Member States and the EU Commission in the coming weeks\" (from the July 10, 2025 publication date). The timeline published on the EU Commission's GPAI Code of Practice webpage indicates the AI Office and AI Board will assess the Code and may approve it via an adequacy decision on 2 August 2025.\n\n6. **Compliance Deadlines:** \n   - AI Act provisions relating to GPAI models apply from 2 August 2025\n   - Fines apply from 2 August 2026 for certain models\n   - Fines apply from 2 August 2027 for other models\n\n7. **Complementary Documents:** The Code is complemented by:\n   - Guidelines on key concepts for GPAI models (published 18 July 2025)\n   - Template for summarizing training data in GPAI models (published 24 July 2025)\n\n## Relevant to the Question:\n\nThe article describes the publication of **the** GPAI Code of Practice on 10 July 2025, not a revised draft. The article mentions that starting on 2 August 2025, the AI Office will work closely (text appears cut off), but does not mention any plans for publishing a revised draft or new version of the Code of Practice.\n</Summary>\n\n<Summary source=\"https://www.jdsupra.com/legalnews/eu-ai-act-at-the-crossroads-gpai-rules-8567594/\">\n# Summary of Article: \"EU AI Act at the Crossroads: GPAI Rules, AI Literacy Guidance and Potential Delays\"\n\n**Source:** JD Supra (Pillsbury law firm publication)\n\n## Key Facts and Timeline Information:\n\n1. **EU AI Act Status:** The AI Act became effective in February 2025, with a phased implementation approach extending until Summer 2027.\n\n2. **GPAI Obligations Timeline:** Under current timelines, obligations for providers of general-purpose AI (GPAI) models are scheduled to come into effect on August 2, 2025.\n\n3. **GPAI Code of Practice Delay:** The article states that there has been a \"recent delay of the GPAI Code until August\" (referring to August 2025).\n\n4. **AI Literacy Requirements:** Article 4 of the AI Act became effective February 2, 2025, requiring providers and deployers to ensure sufficient AI literacy among personnel.\n\n## Relevant Information About Potential Delays:\n\n5. **Reported Potential Delays:** The article states it was \"reported in May\" (presumably May 2025) that the European Commission was considering delaying enforcement of GPAI obligations to allow for \"simplification\" of some rules.\n\n6. **Official Confirmation Status:** The article explicitly notes that \"the delay is yet to be confirmed publicly by official EU sources.\"\n\n7. **Support for Delays:** Various influential figures from Member States, including the Swedish Prime Minister, have voiced support for implementation delays, \"in some cases for up to two years.\"\n\n8. **Motivation:** The potential delays are connected to broader European Commission \"simplification efforts\" responding to business calls to reduce regulatory burden in the EU.\n\n## Opinions and Analysis (from law firm authors):\n\n- The article characterizes the potential delays as providing \"a window to strengthen compliance strategies but also introduce uncertainty.\"\n- The guidance suggests the delays create an evolving landscape that organizations must \"navigate carefully.\"\n\n**Note:** This article does not directly address whether a revised draft of the GPAI code of practice will be published, but rather discusses delays in the code's implementation and broader enforcement timelines.\n</Summary>\n\n<Summary source=\"https://www.crowell.com/en/insights/client-alerts/code-of-practice-for-general-purpose-ai-models-published-compliance-just-got-clearer-participation-still-optional\">\n# Summary of Crowell & Moring Article on GPAI Code of Practice\n\n**Publication Date:** July 17, 2025\n\n## Key Facts and Dates:\n\n1. **Final Code Published:** On July 11, 2025, the European Commission published the **final version** of its Code of Practice for General-Purpose Artificial Intelligence (GPAI).\n\n2. **AI Act Application Date:** The EU AI Act will become applicable on August 2, 2025.\n\n3. **Purpose:** The Code is intended to help AI model providers comply with the EU AI Act, specifically with transparency, copyright, and safety/security provisions (articles 53 and 55).\n\n4. **Voluntary Nature:** Adherence to the Code of Practice is **voluntary** and \"does not constitute conclusive evidence of compliance\" with the AI Act obligations.\n\n5. **Development Process:** The Code was developed by independent experts through a multi-stakeholder process.\n\n## Structure and Content:\n\nThe Code is organized into three chapters:\n- **Chapter 1: Transparency** - Covers documentation requirements (articles 53(1)(a) and (b) of AI Act)\n- **Chapter 2: Copyright** - Addresses copyright compliance policies\n- **Chapter 3: Safety and Security** - For GPAI models presenting systemic risk (not discussed in detail in this article)\n\n### Transparency Chapter Details:\n- Introduces a **Model Documentation Form** as a concrete tool\n- Requires providers to publicly disclose contact information for AI Office and downstream providers to request information\n- Documentation must cover model capabilities, acceptable use policies, technical information, distribution, and licensing\n\n### Copyright Chapter Details:\n- Focuses on compliance with EU copyright law, particularly Directives 2001/29 and 2019/790\n- Requires providers to draw up and implement a copyright policy in a single document\n- Addresses web-crawling practices, including respecting technological protection measures\n- Explicitly mentions the **Robot Exclusion Protocol (robots.txt)** as a protocol to follow for rights reservations\n\n## Important Qualifier:\nThe article emphasizes that while the Code may be helpful from a best practice perspective, it \"does not provide legal certainty\" due to its voluntary nature.\n\n**Note:** The article text appears to be cut off at the end, so the summary may not capture all content from the original article.\n</Summary>\n\n<Asknews_articles>\nQuery: Will the European Commission\u2019s AI Office publish a revised draft (a new version) of the general-purpose AI (GPAI) code of practice?\nHere are the relevant news articles:\n\n**EU Commission cautions Meta over blocking third-party AI assistants on WhatsApp**\nThe European Commission has issued a Statement of Objections, indicating its preliminary view that Meta may have violated EU antitrust rules by blocking third-party artificial intelligence (AI) assistants from operating on WhatsApp. This follows a formal antitrust investigation launched in December 2025, focusing on Meta\u2019s updated WhatsApp Business Solution terms introduced in October 2025, which prohibit AI providers from offering general-purpose AI assistants as standalone services on the platform. While businesses can still use AI for support functions like automated customer service, independent AI assistants are restricted from operating as primary services. The Commission\u2019s preliminary assessment, published on February 10, 2026, finds that Meta is likely dominant in the EEA consumer communication market, particularly through WhatsApp, which serves as a key gateway for AI services to reach users. Regulators warn that excluding competitors could cause serious and irreparable harm by raising barriers to entry and limiting market access, especially for smaller providers. The Commission signaled its intention to consider interim measures to suspend or reverse the policy during the ongoing investigation. If confirmed, the conduct could breach Article 102 of the Treaty on the Functioning of the European Union and Article 54 of the EEA Agreement. The case is part of the Commission\u2019s broader monitoring of AI markets, following consultations in January 2024 and a policy paper in September 2024. The Statement of Objections is not a final decision; Meta has the right to respond and defend itself before any measures are adopted. The investigation remains ongoing, with next steps including further review of Meta\u2019s response and potential adoption of interim or final measures. The outcome may shape how AI services integrate with major digital platforms in Europe and clarify the application of competition rules to emerging AI markets. Teresa Ribera, Executive Vice-President for Clean, Just and Competitive Transition, commented on the matter, though her full statement was not included in the article.\nOriginal language: en\nPublish date: February 10, 2026 05:44 AM\nSource:[FoneArena](https://www.fonearena.com/blog/475163/eu-commission-meta-blocking-third-party-ai-assistants-whatsapp.html)\n\n**Chinese Scientists Develop 'General-Purpose Brain' for Artificial Intelligence**\nA groundbreaking research breakthrough led by the Beijing Academy of Artificial Intelligence (BAAI), published in the prestigious journal Nature on February 9, 2026, introduces the Emu3 and Emu3.5 models\u2014multi-modal AI systems designed to function as a 'general-purpose brain' for artificial intelligence. The core innovation lies in a unified architecture that enables the AI to predict the 'next piece' in a sequence, whether that sequence is text, images, or video, effectively treating all data as 'digital building blocks.' This approach, inspired by OpenAI\u2019s 'predict the next word' method used in GPT models, extends beyond language to integrate vision, language, and video generation within a single framework. Unlike prior models that used separate tools for different tasks, Emu3 demonstrates 'one brain, multiple skills' by generating detailed images from text, answering visual questions, and producing continuous video sequences with accompanying descriptions. Emu3.5 further advances this by incorporating long-term video training, enabling the model to predict 'next states' over time, thus learning temporal dynamics of the world\u2014a critical step toward building a 'world model.' According to lead researcher Huang Tiejun, this unified modeling approach systematically bridges the gap between perception and generation across modalities, marking a significant leap toward general artificial intelligence. Nature\u2019s editors praised the work for its potential to enable scalable, unified multi-modal intelligent systems. The achievement represents the first original large model breakthrough from a Chinese research institution published in Nature\u2019s main journal.\nOriginal language: zh\nPublish date: February 09, 2026 10:14 PM\nSource:[\u65b0\u6d6a\u8d22\u7ecf](https://finance.sina.com.cn/jjxw/2026-02-10/doc-inhmhmhs4899171.shtml)\n\n**EU May Force Meta to Restore AI Assistant Access on WhatsApp**\nThe European Commission has formally notified Meta Platforms of its intent to impose provisional measures in an antitrust investigation concerning Meta's policy restricting third-party general-purpose artificial intelligence (AI) assistants' access to WhatsApp. In October 2024, Meta changed WhatsApp Business's terms of service, effectively blocking external AI developers from accessing the platform, a policy set to take full effect in January 2026. The Commission, led by Competition Commissioner Teresa Ribiera, emphasized the urgency of swift action due to the rapid evolution of AI markets, stating, 'We need to be fast in our actions.' The Commission argues that Meta is abusing its dominant position in messaging by leveraging WhatsApp as a gatekeeper to exclude emerging competitors in the AI assistant market. Provisional measures would require Meta to restore third-party access to the WhatsApp Business API under pre-October 2024 terms. The EU asserts that Meta's actions violate European antitrust laws by using its market dominance to restrict competition. This preventive approach marks a strategic shift from historically lengthy antitrust procedures, reflecting a new regulatory focus on rapid intervention in fast-moving tech sectors like AI. Meta has the right to present its defense, but Brussels appears determined to safeguard fair competition in emerging digital markets.\nOriginal language: es\nPublish date: February 09, 2026 03:46 PM\nSource:[Digital Trends Espa\u00f1ol](https://es.digitaltrends.com/sociales/whatsapp-podria-verse-obligado-a-regresar-chatgpt-y-otras-ia/)\n\n**European Commission Accuses Meta of Antitrust Violations in WhatsApp AI Exclusion**\nThe European Commission, the executive branch of the European Union (EU), has issued a 'Statement of Objections' to Meta, preliminarily accusing the company of violating EU antitrust rules by excluding third-party artificial intelligence (AI) assistants from accessing and interacting with users on WhatsApp. The Commission argues that Meta's conduct risks blocking competitors' entry or expansion in the rapidly growing AI assistant market and plans to impose provisional measures to prevent serious and irreparable harm to the market, subject to Meta's response and right to defense. The Commission preliminarily concludes that Meta is likely dominant in the European Economic Area (EEA) consumer communication app market, primarily through WhatsApp, and is abusing this dominant position. It emphasizes that WhatsApp serves as a key 'gateway' for general-purpose AI assistants to reach consumers. The Commission notes that on October 15, 2025, Meta announced an update to the WhatsApp Business Solution Terms, effectively banning third-party general-purpose AI assistants. As of January 15, 2026, only Meta's own AI assistant, Meta AI, is available on WhatsApp, with competitors excluded. The Commission states this policy change appears, on its face, to breach EU competition rules. Meta's core products include social media platforms like Facebook and Instagram, consumer communication apps such as WhatsApp and Messenger, online advertising services, and virtual and augmented reality products. Meta also offers the general-purpose AI assistant Meta AI.\nOriginal language: pt\nPublish date: February 09, 2026 03:43 PM\nSource:[InfoMoney](https://www.infomoney.com.br/mercados/comissao-europeia-acusa-meta-de-violar-regras-antitruste-no-whatsapp/)\n\n**EU Warns Meta of Interim Measures in WhatsApp AI Probe -- 2nd Update**\nThe European Union's executive body, the European Commission, issued a statement of objections to Meta Platforms on February 9, 2026, as part of its ongoing investigation into Meta's policy restricting rival artificial-intelligence chatbots from accessing WhatsApp's business programming interface. The policy, introduced in January 2026, prevents competing chatbots\u2014such as those from OpenAI and others\u2014from using WhatsApp's tool for business-to-customer communication. The EU alleges that Meta's actions may constitute an abuse of its dominant position in messaging apps, potentially raising barriers to entry and irreparably marginalizing smaller competitors in the general-purpose AI assistant market. The Commission stated there is an 'urgent need' for interim measures and may compel Meta to reverse its policy and restore access to rival chatbots until the investigation concludes. Meta responded by arguing that WhatsApp's business interface is not a primary distribution channel for AI chatbots, citing alternatives such as app stores, operating systems, devices, websites, and industry partnerships. Meta has until a formal response deadline to submit its rebuttal and request a hearing. The EU's action is part of a broader enforcement effort against major tech companies, despite pushback from the U.S. under President Trump. Italy is conducting its own investigation and previously ordered Meta to keep WhatsApp open to rivals, prompting Meta to announce plans to charge AI providers for messaging access in regulated markets. Meanwhile, a Brazilian court has suspended a similar interim injunction imposed by Brazil's antitrust regulator.\nOriginal language: en\nPublish date: February 09, 2026 02:23 PM\nSource:[Market Screener](https://www.marketscreener.com/news/eu-warns-meta-of-interim-measures-in-whatsapp-ai-probe-2nd-update-ce7e5aded180fe23)\n\n**EU targets Meta over WhatsApp AI access restrictions - Help Net Security**\nThe European Commission alleges that Meta violated EU competition rules by restricting third-party, general-purpose AI assistants from accessing and interacting with users on WhatsApp. This change, announced in an update to the WhatsApp Business Solution Terms on 15 October 2025, took effect on 15 January 2026, when Meta AI became the sole AI assistant available on the platform. The Commission is considering interim measures to prevent the policy from causing serious, long-term harm to competition while the investigation continues. Teresa Ribera, Executive Vice President for Clean, Just and Competitive Transition, emphasized the need to protect effective competition in the rapidly developing AI assistant market, stating that dominant tech companies must not use their market position to gain an unfair advantage. The Commission aims to preserve access for competitors during the investigation to prevent lasting damage to competition in Europe.\nOriginal language: en\nPublish date: February 09, 2026 01:45 PM\nSource:[Help Net Security](https://www.helpnetsecurity.com/2026/02/09/eu-meta-whatsapp-ai-services-competition-rules/)\n\n**Brussels Threatens WhatsApp with Forced Integration of ChatGPT and Other AI Services**\nThe European Commission has threatened Meta with immediate provisional measures to prevent the company from permanently excluding third-party artificial intelligence (AI) chatbots from WhatsApp, following Meta's policy change that restricted access to its WhatsApp Business Solutions (WBS) platform to only Meta AI. The Commission concluded that Meta's new policy may be illegal and has opened a deep investigation. It warns that the policy risks causing 'grave and irreparable harm' to competition, particularly by creating barriers to entry for smaller AI competitors like ChatGPT. The Commission argues that AI innovation in Europe must be protected, and that dominant tech firms cannot misuse their market power to gain unfair advantages. Teresa Ribera, Executive Vice President for Competition, stated that the EU is considering rapid provisional measures to preserve competitors' access to WhatsApp during the ongoing investigation. Meta claims that WhatsApp is not a distribution or intermediary platform for AI services, and disputes the Commission\u2019s interpretation. The Commission\u2019s concern stems from the fact that, as of January 15, 2026, only Meta AI can integrate with WBS, while other general-purpose AI assistants are excluded, despite allowing AI use in secondary business functions. The Commission emphasized the urgency of acting before irreparable damage occurs, citing the risk of marginalizing smaller AI competitors.\nOriginal language: es\nPublish date: February 09, 2026 12:22 PM\nSource:[El Confidencial](https://www.elconfidencial.com/tecnologia/2026-02-09/bruselas-whatsapp-meta-ai-ia-chatgpt-mensajeria-apps_4299972/)\n\n**Brussels Accuses Meta of Violating Competition Rules with AI Policy Change on WhatsApp**\nThe European Commission has issued a Statement of Objections to Meta, alleging that the company violated EU competition rules by blocking third-party AI assistants from accessing and interacting with WhatsApp users. The Commission's preliminary assessment indicates that Meta's policy change\u2014implemented on January 15, 2026\u2014excludes non-Meta AI assistants from WhatsApp and exclusively enables Meta AI, potentially hindering market entry or expansion for competitors in the rapidly growing AI assistant sector. The Commission warns that this change may cause 'serious and irreversible harm' to the market and intends to impose provisional measures pending Meta's response and its right to defend itself. Meta had announced the update to WhatsApp Business in October 2025, which led to the exclusion of general-purpose third-party AI assistants. The Commission considers this move a potential abuse of Meta's dominant market position in the EU. Meta\u2019s core products include Facebook, Instagram, WhatsApp, and Messenger, and it operates in online advertising, virtual reality, augmented reality, and AI, with Meta AI as its general-purpose AI assistant.\nOriginal language: pt\nPublish date: February 09, 2026 10:58 AM\nSource:[ECO](https://eco.sapo.pt/2026/02/09/bruxelas-acusa-meta-de-violar-regras-da-concorrencia-com-politica-de-ia-no-whatsapp/)\n\n**Meta Must Allow AI Provider Competition on WhatsApp \u2013 EU Warns**\nMeta faces scrutiny from the European Commission over changes to WhatsApp's business terms implemented in October 2025, which exclude companies whose primary business is artificial intelligence (AI). The move prevents AI providers\u2014such as those offering general-purpose chatbots similar to ChatGPT or Google Gemini\u2014from using WhatsApp's infrastructure to reach users, effectively blocking them from leveraging Meta's platform and server network. This restriction benefits Meta\u2019s own AI-powered WhatsApp chatbot. The EU Commission argues this practice violates EU competition rules and risks causing 'irreparable harm' to smaller AI competitors. Meta now has the opportunity to respond to the EU\u2019s concerns. If the Commission maintains its stance, it may impose interim measures requiring Meta to revert the terms or face substantial fines.\nOriginal language: de\nPublish date: February 09, 2026 09:32 AM\nSource:[oe3.ORF.at](https://oe3.orf.at/stories/3052251/)\n\n**Why AGI Research is Stalling**\nArtificial general intelligence (AGI) research is stalling despite rapid advancements in AI capabilities, according to a member-only article published on Medium.com on February 9, 2026. The author argues that while AI systems like OpenAI's GPT-5 (released in early 2025) have shown impressive improvements in reasoning, reduced hallucinations, and adaptive programming, they still lack autonomous goal-setting and lifelong learning\u2014key traits of true AGI. The article highlights that scaling models alone no longer yields the qualitative breakthroughs needed, creating a plateau in progress. Experts estimate a 50% chance of AGI emerging between 2040 and 2050, with a 90% likelihood by 2075, reflecting cautious optimism. The author questions whether AI itself can overcome these barriers by conducting better AI research, framing the current impasse as a fundamental challenge in autonomous reasoning and continuous learning.\nOriginal language: en\nPublish date: February 09, 2026 01:31 AM\nSource:[Medium.com](https://medium.com/@meisshaily/why-agi-research-is-stalling-bb47cf3caf78)\n\n**Winter AI wrap: a snapshot of key updates and developments**\nThe European Commission has proposed delaying certain obligations under the EU AI Act, including for high-risk AI systems, amid pressure from business and lobby groups. The delay hinges on approval of the broader digital omnibus package before the current compliance deadline of 2 August 2026; if not approved, a standalone fast-track proposal may be used to ensure timing flexibility. This move reflects an effort to balance innovation and regulation, maintaining EU competitiveness in the global AI landscape. In the US, President Trump signed an Executive Order on 11 December 2025 that seeks to limit enforcement of state-level AI laws, framing regulatory fragmentation as a threat to US AI competitiveness and citing Colorado\u2019s AI law as an example. However, the Order does not pre-empt state laws without new federal legislation, and prior attempts to pass such pre-emption have failed in the Senate. The Commission also published guidelines clarifying obligations for general-purpose AI (GPAI) model providers under the EU AI Act, and a voluntary GPAI Code of Practice that, if followed, will be deemed compliance with the Act. Additionally, a draft Code of Practice on transparency of AI-generated content was released on 17 December 2025, with further drafts expected in March 2026 and a final version by May or June 2026\u2014raising concerns about whether organizations will have sufficient time to implement it before the 2 August 2026 Article 50 deadline. The Commission also launched a public consultation on serious incident reporting under Article 73 of the EU AI Act, providing draft guidance and a reporting template for high-risk AI systems. Reportable incidents include serious health impacts, critical infrastructure disruptions, large-scale rights violations, and significant property or environmental damage. Providers must notify authorities quickly, investigate, and preserve evidence. Deployers must also escalate incidents. Ireland has adopted a distributed model for AI oversight, designating 15 national competent authorities and establishing a National AI Office to coordinate implementation by 2 August 2026.\nOriginal language: en\nPublish date: January 19, 2026 12:40 PM\nSource:[Lexology](https://www.lexology.com/library/detail.aspx?g=75e5bbd5-89d9-4b5c-9254-8c738b6a6344)\n\n**The EU AI Act And General-Purpose AI: Navigating The Compliance Landscape**\nThe European Union's Artificial Intelligence Act (AI Act) introduces comprehensive regulatory requirements for General-Purpose AI (GPAI) models, which are defined by their ability to perform a wide range of tasks across diverse applications, such as OpenAI's GPT series, DALL-E, and Midjourney. The Act's obligations for GPAI models became effective on 2 August 2025, with models already on the market before that date required to comply by 2 August 2027. The regulatory framework places the primary responsibility on model providers, not end-users, and distinguishes between standard GPAI models and those posing systemic risks\u2014models meeting specific technical criteria indicating potential significant societal or economic impact. All GPAI models must meet core obligations, including transparency, data governance, and risk management. Systemic-risk GPAI models face additional requirements, such as rigorous testing and impact assessments. Providers are advised to refer to the European Commission\u2019s voluntary Code of Practice, Guidelines for GPAI providers, and a training data summary template to ensure compliance. Enforcement is now a priority, with non-compliance punishable by fines of up to \u20ac15 million or 3% of annual worldwide turnover, whichever is higher, emphasizing the critical need for proactive risk assessment and compliance. The article was published on 28 October 2025 by Mondaq Business Briefing.\nOriginal language: en\nPublish date: October 28, 2025 03:20 PM\nSource:[Mondaq Business Briefing](https://www.mondaq.com/new-technology/1697210/the-eu-ai-act-and-general-purpose-ai-navigating-the-compliance-landscape)\n\n**How the EU AI Act shapes General-Purpose AI**\nThe European Union's Artificial Intelligence Act (AI Act) establishes comprehensive regulations for General-Purpose AI (GPAI) models, which are designed to perform a wide range of tasks across diverse applications, such as OpenAI's GPT series, DALL-E, and Midjourney. The Act imposes core obligations on GPAI providers, effective 2 August 2025, with a compliance deadline of 2 August 2027 for models already on the market. These obligations include maintaining detailed technical documentation, providing downstream providers with clear information on model capabilities and limitations, implementing a copyright policy that respects opt-out mechanisms, publishing a public summary of training data, and appointing an EU-based authorized representative if not established in the EU. Models deemed to pose systemic risks\u2014those meeting specific technical criteria indicating potential significant societal or economic impact\u2014must also conduct model evaluations, perform risk assessments with mitigation strategies, report serious incidents, and ensure robust cybersecurity. The European Commission supports compliance through a voluntary Code of Practice, provider guidelines, and a training data summary template. Non-compliance may result in fines of up to \u20ac15 million or 3% of annual worldwide turnover, whichever is higher, signaling a shift from policy development to active enforcement. The AI Act thus reshapes the governance of GPAI in the EU, emphasizing accountability and risk mitigation.\nOriginal language: en\nPublish date: October 27, 2025 10:45 AM\nSource:[timesofmalta.com](https://timesofmalta.com/article/how-eu-ai-act-shapes-generalpurpose-ai.1118472)\n\n**EU's AI Code Of Practice - A Step Closer To Navigating The AI Regulation's Copyright Obligations**\nOn 10 July 2025 the European Commission published a Code of Practice for general\u2011purpose artificial intelligence (GPAI) to help providers comply with the AI Regulation that entered force on 2 August 2025. The Code, adopted by the Commission and the AI Committee on 1 August 2025, is optional but gives signatories an administrative advantage by creating a presumption of compliance. It contains three chapters \u2013 transparency, copyright and safety & security \u2013 and requires providers to adopt a copyright\u2011compliance policy, identify responsible staff, set up a complaints mechanism and implement technical safeguards that prevent the model from reproducing training content. The policy must respect machine\u2011readable opt\u2011outs such as robots.txt, and signatories must warn users that open\u2011source models can still infringe copyright. The Code also mandates a summary of training data, prepared with a template supplied by the European AI Office, that is broad enough to protect trade secrets but detailed enough for rights holders to exercise their rights. Major players such as Google (Gemini), Microsoft and OpenAI (ChatGPT) have signed; Meta has declined. On 18 July 2025 the Commission issued further guidelines clarifying the scope of the rules and the distinction between model providers and users.\nOriginal language: en\nPublish date: September 26, 2025 09:10 AM\nSource:[Mondaq Business Briefing](https://www.mondaq.com/copyright/1683232/eus-ai-code-of-practice-a-step-closer-to-navigating-the-ai-regulations-copyright-obligations)\n\n**Artificial Intelligence | UK Regulatory Outlook September 2025**\nFollowing the Intellectual Property Office's consultation on copyright and AI, the Department for Science, Innovation and Technology and the Department for Culture, Media and Sport created expert working groups to discuss using publicly available copyright\u2011protected content to train AI systems. The groups aim to 'reset and refocus' and deliver a 'fresh start' in order to find 'practical solutions that support AI innovation while protecting creators', according to the article. They will initially focus on identifying 'impacts, opportunities, and common ground' in the AI\u2011copyright debate.\n\nThe Law Commission published a discussion paper on 'AI and the law', noting concerns such as the possibility of granting AI systems legal personality. The paper warns that AI could become a 'liability shield' for developers and argues that legal uncertainty may delay safe AI development.\n\nThe second tranche of the EU AI Act provisions entered into application on 2\u202fAugust. The headline obligations target providers of general\u2011purpose AI (GPAI) models, such as large language models. The final GPAI code of practice was published just before the 2\u202fAugust effective date. The European Commission and the European Artificial Intelligence Board confirmed that adherence to the code is an adequate voluntary tool for GPAI providers to demonstrate compliance with Articles\u202f53 and\u202f55 of the Act.\n\nOn 18\u202fJuly\u202f2025 the Commission issued guidance on the scope of GPAI rules, introducing a technical criterion that a model must require more than 1023 FLOPs to train and must be capable of generating language. The guidance clarifies that minor changes to a third\u2011party GPAI model do not trigger GPAI compliance and outlines exemptions for open\u2011source GPAI providers.\n\nThe Commission also launched a consultation on a code of practice for AI transparency, linked to Article\u202f50 of the EU AI Act. The consultation, which seeks input on guidance for labeling AI\u2011generated or manipulated content, is open until 2\u202fOctober. A separate call for expression of interest in drafting the code of practice also closes on 2\u202fOctober.\n\nIn an interview on 28\u202fAugust\u202f2025, Dr\u202fLucilla\u202fSioli, head of the AI Office, explained that companies may face delays if they do not sign the GPAI code of practice. She said the technical standards, currently being prepared by CEN\u2011CENELEC, will be ready in 2026 and that the deadline is 'part of the legislation', so any postponement would require agreement from the Commission, the European Parliament and the Council. She added that the assessment of the standards would be available 'very, very soon'.\n\nOther updates include the Commission\u2019s formal withdrawal of its AI Liability Directive proposal, as no challenge was made within the six\u2011month window. The Commission also launched a consultation on digitalisation and AI in the energy sector, with a deadline of 5\u202fNovember, to inform a strategic roadmap aimed at accelerating AI uptake in the energy system while improving efficiency and reliability.\nOriginal language: en\nPublish date: September 25, 2025 12:00 AM\nSource:[Lexology](https://www.lexology.com/library/detail.aspx?g=f3443907-a4ba-4319-b852-29e4fd39b7bc)\n\n**Navigating the AI Act: The GPAI Code of Practice and Guidelines**\nThe European Commission\u2019s GPAI Code of Practice and Guidelines offer a voluntary framework for General Purpose AI (GPAI) model providers to demonstrate compliance with the EU AI Act, which imposes obligations from 2\u202fAugust\u202f2025. The Code, published 10\u202fJuly\u202f2025, is organized into three core chapters\u2014Transparency, Safety and Security, and Copyright\u2014and is intended to reduce administrative burden and provide legal certainty, according to the Commission. Major platforms such as Google, Microsoft, OpenAI and Amazon have signed the Code, while Meta has declined, stating it introduces legal uncertainties and overreach; Meta\u2019s head of global affairs, Joel Kaplan, described the Code as \"overreach\". The Guidelines clarify thresholds, including FLOP\u2011based criteria, and outline practical implementation across the model lifecycle. The Commission claims the Code will streamline compliance, but critics warn that it could suppress advanced AI development in Europe and disadvantage EU businesses relative to US competitors. Providers are advised to assess whether their models meet the GPAI threshold, engage early with the AI Office, sign the Code, monitor significant model modifications, review open\u2011source exemptions, and ensure copyright safeguards and transparency measures align with both the Code and Guidelines.\nOriginal language: en\nPublish date: September 24, 2025 01:14 PM\nSource:[Lexology](https://www.lexology.com/library/detail.aspx?g=ab5312ed-8d4b-482e-bc8f-efa3f53ef7f6)\n\n**The EU's approach to governing general-purpose AI: The AI Act and Code of Practice**\nThe European Union\u2019s AI Act entered a decisive phase in summer 2025 with the launch of the General\u2011Purpose AI (GPAI) Code of Practice on 10\u202fJuly\u202f2025. The voluntary framework, developed with nearly 1,000 stakeholders, is designed to help GPAI providers demonstrate compliance with the new GPAI rules under Regulation (EU)\u202f2024/1689. Signatories to date include Microsoft, Amazon, Google and OpenAI.\n\nThe Act defines a GPAI model as \u2018an AI model, including where such an AI model is trained with a large amount of data using self\u2011supervision at scale, that displays significant generality and is capable of competently performing a wide range of distinct tasks regardless of the way the model is placed on the market and that can be integrated into a variety of downstream systems or applications\u2019.\n\nKey obligations under the Act are:\n\u2022 Disclosure of training data sources \u2013 providers must publish a summary of training content using a standardised template issued by the Commission in July\u202f2025, classifying data as public, licensed, scraped or user\u2011generated and documenting compliance with the EU Copyright Directive\u2019s opt\u2011out provisions.\n\u2022 Transparency \u2013 a model documentation toolkit is required for every GPAI placed on the market, covering training methods, data categories, resource consumption and intended use cases. Documentation must be shared with downstream developers and, when requested, with the AI Office or national authorities.\n\u2022 Copyright compliance \u2013 providers must implement a copyright compliance policy that ensures training aligns with EU copyright law.\n\u2022 Systemic\u2011risk management \u2013 for the most advanced GPAI models, Article\u202f55(1) requires continuous risk assessment, incident reporting to the AI Office and, where necessary, to national competent authorities, as well as cybersecurity safeguards.\n\nThe Code outlines ten commitments for systemic\u2011risk models, including a dedicated Safety and Security Framework and a Safety and Security Model Report that must be submitted to the AI Office before market launch.\n\nEnforcement timeline: from 2\u202fAugust\u202f2025 providers must comply with the Act; models with systemic risk must be notified to the AI Office. The Commission will exercise co\u2011operative enforcement for the first year, ending on 2\u202fAugust\u202f2026, after which full enforcement powers apply. GPAI models already on the market before 2\u202fAugust\u202f2025 have until 2\u202fAugust\u202f2027 to become fully compliant. The AI Office will review the Code biennially.\n\nLitigation highlights: Getty Images\u2019 action against Stability AI in the UK challenged the use of copyrighted photographs in training; the primary claim was dropped, but a secondary claim that output from an infringing model may itself infringe remains.\nIn France, authors and publishers sued Meta for training its GPAI model on copyrighted literary works. A CJEU reference will test whether training and output generation by large models constitute \u2018acts of reproduction\u2019 or \u2018communication to the public\u2019 under the EU Copyright Directive and the InfoSoc Directive, and whether training falls outside the text\u2011and\u2011data\u2011mining exception.\n\nThe Code of Practice therefore serves as the most practical roadmap for providers while courts resolve outstanding copyright questions.\nOriginal language: en\nPublish date: September 19, 2025 08:45 AM\nSource:[Lexology](https://www.lexology.com/library/detail.aspx?g=4286c8c2-0153-4296-9af1-c0913d6928bb)\n\n\n--- Deep Research Analysis ---\nError running deep research: ForbiddenError: 403012 - Usage limit exceeded for 'chat_tokens', please upgrade your plan at https://my.asknews.app/plans to increase your limits.\n</Asknews_articles>\n"
}