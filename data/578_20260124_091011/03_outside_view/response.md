# Outside View (Base Rate) Estimation

## Question
Will humans go extinct before 2100?

## Description
The question is about the probability of human extinction before the year 2100.

## Resolution Criteria
The question is asking for a probability estimate of human extinction before the year 2100.

## Your Task

### Step 1: Source Analysis

Data sources for this type of question are limited, as human extinction is a rare and unprecedented event. The historical record on human extinction is sparse and may be subject to biases, as information on past extinctions could be incomplete or unreliable.

### Step 2: Reference Class Analysis

**Reference Class 1: Mass Extinctions in Earth's History**
- Historical base rate: Approximately 5 major mass extinctions in the last 500 million years, with the most recent being the Cretaceous-Paleogene extinction event around 66 million years ago.
- Sample size: 5 major mass extinction events.
- Suitability score (1-10): 6. While mass extinctions provide a relevant reference class, the timescales and causes involved are vastly different from the current situation.
- Why this reference class: Mass extinctions provide a historical precedent for the possibility of a global catastrophic event leading to the extinction of a significant portion of life on Earth.

**Reference Class 2: Existential Risks to Humanity**
- Historical base rate: There have been no known cases of human extinction in recorded history.
- Sample size: 0 events of human extinction.
- Suitability score (1-10): 8. This reference class is more directly relevant to the question, as it focuses on risks that could lead to the extinction of the human species.
- Why this reference class: Existential risks, such as global pandemics, nuclear war, or environmental catastrophes, are the most relevant reference class for assessing the probability of human extinction.

**Reference Class 3: Technological Singularity and Transhumanism**
- Historical base rate: The concept of a technological singularity, where artificial intelligence surpasses human intelligence, is a hypothetical future event with no historical precedent.
- Sample size: 0 events of a technological singularity.
- Suitability score (1-10): 7. While the potential impact of a technological singularity on human extinction is significant, the likelihood and timing of such an event are highly uncertain.
- Why this reference class: The possibility of a technological singularity, where AI systems become superintelligent and potentially transform or replace humanity, is a relevant consideration for the probability of human extinction.

### Step 3: Fermi Estimation (if applicable)

Not applicable, as we have some relevant reference classes to consider.

### Step 4: Base Rate Integration

Weighting the reference classes by their suitability:
1. Existential Risks to Humanity: 50% weight
2. Mass Extinctions in Earth's History: 30% weight
3. Technological Singularity and Transhumanism: 20% weight

Integrated base rate:
(0% × 0.5) + (5% × 0.3) + (50% × 0.2) = 15%

### Step 5: Confidence Assessment

Confidence level: 6/10

The historical record on human extinction is very limited, and the potential causes and mechanisms involved are highly uncertain. While the reference classes provide some guidance, the overall confidence in this base rate estimate is moderate due to the lack of direct historical precedents.

**Base Rate Estimate:** 15%

**Reference Classes Used:**
1. Mass Extinctions in Earth's History: 5% base rate (weight: 30%)
2. Existential Risks to Humanity: 0% base rate (weight: 50%)
3. Technological Singularity and Transhumanism: 50% base rate (weight: 20%)

**Confidence Level:** 6/10

**Key Uncertainties:**
- The historical record on human extinction is very limited, making it difficult to establish a reliable base rate.
- The potential causes and mechanisms of human extinction, such as global catastrophic risks or technological developments, are highly uncertain and difficult to quantify.
- The timescale of 2100 is relatively short compared to the timescales involved in mass extinctions and technological singularity, adding further uncertainty.

Remember: This is the OUTSIDE VIEW only. Do not adjust for current events or recent news. That adjustment happens in the next stage.