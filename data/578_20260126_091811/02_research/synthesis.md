# Research Synthesis

**Generated:** 2026-01-26T09:21:19.511305+00:00
**Total Sources:** 2

## Search Queries
1. human extinction probability scientific research
2. global existential risks to humanity analysis
3. anthropocene survival chances expert predictions
4. "scientific probability of human extinction before 2100"
5. "global existential risks comprehensive expert analysis 2023"
6. "existential risk probability human extinction expert estimates 2100"
7. "global catastrophic risks scientific assessment near-term human survival"

## Deep Research (AskNews)

Based on a comprehensive review of recent expert analyses and scientific perspectives, **human extinction before 2100 is considered unlikely but not impossible**. The current consensus emphasizes that while existential risks are escalating, they are largely preventable through coordinated global action. Below is a detailed synthesis of key insights:

### 1. **Major Threats to Human Survival**  
- **Nuclear War**: Currently the most acute threat. Even a "limited" nuclear exchange (e.g., 100 warheads) could trigger a "nuclear winter," causing global famine and potentially killing ~2 billion people within two years. Full-scale war would risk planetary extinction [14][15][16][19][6].  
- **Artificial Intelligence**: Unaligned superintelligent AI has a 10–20% chance of causing civilizational collapse by 2100. Risks include autonomous weapons, bioengineered pandemics, or resource misallocation [13][19][11][12].  
- **Climate Change**: Not viewed as an extinction-level threat alone but a critical *risk multiplier*. It exacerbates food/water scarcity, migration, and conflict—potentially escalating nuclear tensions. Worst-case models show catastrophic disruptions (e.g., 10°C cooling post-nuclear war) but not total human extinction [7][14][17][8].  
- **Engineered Pandemics**: Advances in biotechnology and AI lower barriers to creating lethal pathogens. Accidental leaks or malicious use could cause unparalleled mortality [10][15][16][20].  

### 2. **Reasons Extinction Is Unlikely by 2100**  
- **Adaptive Capacity**: Human societies have consistently demonstrated resilience. Disaster preparedness and governance improvements have reduced climate-related mortality by >90% since 1920 [8].  
- **Space Colonization**: Figures like Stephen Hawking argued space expansion is feasible within decades, providing a "backup" for humanity [4][12].  
- **Global Prioritization**: Existential risks (nuclear arms control, AI ethics) are gaining policy traction, e.g., the Doomsday Clock's prominence and frameworks like the Kunming-Montreal Biodiversity Pact [7][11][6].  

### 3. **Critical Uncertainties and Caveats**  
- **Tipping Points**: Ecological collapse (e.g., Amazon dieback, permafrost thaw) could accelerate climate feedback loops, though timelines remain uncertain beyond 2100 [7][3][20].  
- **Human Behavior**: The greatest vulnerability lies in geopolitical instability, misaligned incentives, or failure to cooperate on global risks [13][17][19].  
- **Lack of Quantification**: While AI or bio-engineered threats *could* be existential, probability estimates vary widely among experts [13][15][20].  

### Conclusion  
**Probability Assessment**: Based on current evidence, the likelihood of total human extinction before 2100 is low (estimated <5% in most peer-reviewed models), though regional collapses or billions of deaths are plausible if risks are unmitigated. **Immediate priorities** include:  
- Strengthening nuclear arms treaties [6][14].  
- Implementing AI/bio-risk governance [10][13][19].  
- Investing in climate adaptation (e.g., sustainable agriculture) [2][7][8].  

As put by Dr. Thomas Moynihan (Cambridge Existential Risk Center): *"Extinction is a choice, not an inevitability"* [19][20]. The 21st century’s trajectory hinges on humanity’s collective restraint and innovation—not predetermined doom.  

**Sources**:  
[1][4][6][11][12][13][14][15][16][17][19][20] for nuclear/AI risks;  
[2][3][7][8][14][17] for climate/ecological impacts;  
[5][10] for technological resilience.

## News Articles (AskNews)

Here are the relevant news articles:

**10 Climate Research Insights for 2025: From Ocean Warming to Integrated Policy Solutions**
A 2025 climate research report by Carbon Brief, based on findings from University of Washington's Dr. Christie Abi and Potsdam Institute for Climate Impact Research's Dr. Sabin Pus, outlines 10 critical climate science insights. The report highlights that global temperatures in 2023–2025 were the hottest in recorded history, exceeding predictions—natural variability alone cannot explain this rise, with Berkeley Earth estimating the probability of such a trend occurring naturally at less than 1%. Ocean warming is also unprecedented: in 2025, global sea surface temperature averaged 0.49°C above the 1981–2010 baseline (third-highest on record), and ocean heat content increased by approximately 23±8 zettajoules (ZJ), equivalent to 200 times the world’s total annual electricity production. Arctic tundra, once a major carbon sink, is now at risk of becoming a carbon source due to permafrost thaw and increased wildfires, undermining climate targets. Under worst-case scenarios, 20–30% of species could face extinction, with one 2024 study projecting 14–32% loss of macro-species (3–6 million species) over the next 50 years. Human impacts include severe groundwater depletion—50 cm annual decline in many regions over the past 40 years—threatening food security and increasing resource conflict. Rising temperatures have expanded habitats for disease-carrying mosquitoes (e.g., Aedes aegypti and albopictus increased by 10.7% and 46.3% respectively from 1951–1960 to 2014–2023), fueling outbreaks of dengue, Zika, chikungunya, and yellow fever. Labor productivity is also declining: under a 3°C warming scenario, effective labor in Africa, Asia, and Oceania could drop by 33%, 25%, and 18%, respectively, worsening inequality in low-income, low-emission regions. To counter this, researchers emphasize the need for 'integrated' climate policies: carbon dioxide removal (CDR) may require up to 400 gigatons by 2100—double previous IPCC estimates—but natural solutions like reforestation and wetland restoration pose risks to food security and biodiversity. Carbon markets, while widely used, face challenges due to lack of verification and international standards. Research shows that policy packages (e.g., phased bans in construction) achieve 32% effectiveness versus only 13% when implemented alone. Carbon Brief concludes that while climate risks are growing, effective solutions already exist and must be implemented urgently.
Original language: ko
Publish date: January 26, 2026 02:52 AM
Source: [한겨레신문](https://www.hani.co.kr/arti/society/environment/1241646.html)

**Did Humans Nearly Go Extinct 900,000 Years Ago? A Biologist Explains**
A 2023 study published in Science, using a new statistical method called FitCoal, suggests that modern humans experienced a severe population bottleneck around 900,000 years ago, with effective population size dropping to approximately 1,280 individuals—over 98% below earlier levels—for more than 100,000 years. This event, occurring during the Early-Middle Pleistocene Transition, coincided with dramatic climate shifts, including prolonged glaciation and ecosystem disruption, which likely caused habitat fragmentation and food scarcity for early Homo ancestors. The bottleneck may have influenced human speciation and the chromosomal fusion from 48 to 46 chromosomes. However, the findings are debated: a 2024 study in Genetics argues the signal could be a statistical artifact due to unaccounted population structure and gene flow from archaic hominins. Critics also note the fossil record is incomplete and does not unequivocally support near-extinction. While the 2023 study is methodologically advanced and consistent with climatic evidence, the claim remains uncertain. The article concludes that even if the bottleneck wasn't a true near-extinction, early human populations were likely far more fragile than previously believed, underscoring the contingency of human evolution and the need for humility in interpreting our origins.
Original language: en
Publish date: January 25, 2026 09:15 PM
Source: [Forbes](https://www.forbes.com/sites/scotttravers/2026/01/25/did-humans-nearly-go-extinct-900000-years-ago-a-biologist-explains/)

**The Day the Dinosaurs Died: A Cataclysm That Shaped Life on Earth**
The article discusses the mass extinction event 66 million years ago, triggered by an asteroid impact in the Yucatán Peninsula, Mexico, which led to the extinction of 75% of Earth's species, including non-avian dinosaurs. The event, known as the Cretaceous-Paleogene (K–Pg) extinction, occurred rapidly—within 24 hours to three years—due to a 11-kilometer-wide asteroid striking with explosive power 10 billion times greater than the atomic bombs used in WWII. The impact caused global wildfires, tsunamis, earthquakes, volcanic eruptions, and a prolonged global winter that blocked sunlight, halting photosynthesis and collapsing ecosystems. While non-avian dinosaurs perished, birds and small animals survived due to adaptations like seed-eating and underground refuge. The article emphasizes that this extinction was not merely a catastrophe but a pivotal moment in evolution, enabling the rise of mammals and, ultimately, humans. The author, a science journalist, reflects personally on how the extinction mirrors her own life experience—her divorce and gender transition—highlighting resilience and the possibility of renewal after destruction. She argues that the extinction is neither inherently tragic nor joyful but a natural part of life’s evolution. The piece also notes that most scientific knowledge about the event comes from limited geographic regions like Montana, Colorado, and Dakota, while global patterns in other regions, such as South America, remain under-researched. The author draws parallels between this ancient catastrophe and today’s climate crisis, emphasizing life’s adaptability and the enduring hope for renewal even after collapse. The article concludes by exploring why humans are emotionally attached to dinosaurs—viewing them as mythical, fearsome, yet familiar creatures that symbolize both wonder and the fragility of existence.
Original language: es
Publish date: January 25, 2026 04:34 PM
Source: [agenciasinc.es](https://www.agenciasinc.es/Entrevistas/El-dia-en-que-se-extinguieron-los-dinosaurios-fue-el-mas-tragico-de-la-historia-de-la-Tierra)

**Groundbreaking Study Proves That Human Habits In US Cities Are Causing The Unintentional Domestication Of Raccoons**
A groundbreaking study published in Frontiers in Zoology by Dr. Raffaela Lesch and 16 students from the University of Arkansas at Little Rock analyzed approximately 20,000 images of raccoons to investigate urban adaptation. The research found that urban raccoons have shorter snouts than their rural counterparts, a physical change linked to their reliance on human-generated trash as a food source. According to Dr. Lesch, 'Trash is really the kickstarter. Wherever humans go, there is trash. Animals love our trash. It's an easy source of food.' The study suggests that raccoons are undergoing a process of unintentional domestication, similar to that seen in dogs, due to their tolerance of humans and access to abundant, easy-to-obtain food. The researchers note that this evolutionary shift—driven by consistent exposure to human environments and behavior—could eventually lead to raccoons becoming household pets. The study highlights how human waste is inadvertently shaping wildlife evolution in U.S. cities.
Original language: en
Publish date: January 25, 2026 02:48 PM
Source: [TwistedSifter](https://twistedsifter.com/2026/01/groundbreaking-study-proves-that-human-habits-in-us-cities-are-causing-the-unintentional-domestication-of-raccoons/)

**Tiger's Existence Equals Human Survival: A 2025 Ecological Wake-Up Call from Madhya Pradesh**
The 2025 scientific and ecological white paper on the tiger crisis in Madhya Pradesh highlights a dire situation: 54 tiger deaths in a single year, marking a critical turning point for India's ecological health. The article, authored by a global anti-aging scientist and wildlife conservationist, frames the tiger (Panthera tigris) not merely as a predator but as the vital 'heart' of Earth's biosphere, symbolizing the balance of ecosystems. The author traces the tiger's conservation history to Indira Gandhi's 1973 Project Tiger, which established the 'umbrella effect'—protecting tigers to safeguard entire ecosystems, including rivers, soil fertility, and air quality. The 2025 crisis is attributed to human-induced factors: habitat fragmentation leading to territorial conflicts, 57% of deaths linked to unnatural causes such as electric fences and poaching networks, and genetic decay due to isolated tiger populations. The article argues that tiger survival is inseparable from human survival, as tiger habitats are crucial for water security (e.g., Narmada, Tapti, Ken, Betwa rivers), carbon sequestration, and climate regulation. The author warns that without immediate intervention, the collapse of tiger populations will trigger the breakdown of the entire ecological pyramid, leading to desertification and biodiversity loss. The piece concludes with a moral imperative: saving tigers is not just conservation—it is humanity's 'anti-aging' treatment, ensuring the longevity of civilization. The article calls for 2025 to be remembered not as a year of loss but as a year of renewed commitment to ecological integrity. The author, citing 55 years of ecological study, asserts that tiger conservation is the most vital act for human survival.
Original language: hi
Publish date: January 25, 2026 09:07 AM
Source: [Webdunia](https://hindi.webdunia.com/regional-hindi-news/madhya-pradesh-tiger-deaths-2025-ecological-crisis-human-existence-impact-126012500020_1.html)

**The First Death: What a 1960s Mouse Experiment Reveals About AI's Real Threat to Creative Work**
In 1968, behavioral researcher John B. Calhoun created 'Universe 25,' a controlled environment for mice designed to explore what happens when all biological needs are met with no external threats. The enclosure provided unlimited food, water, nesting materials, and climate control, with no predators or disease. The expected outcome was a population stabilizing at 3,840 mice, the environment’s physical capacity. Instead, the population peaked at 2,200 and then collapsed into extinction. The mice did not die from starvation or illness but from behavioral disintegration, including social withdrawal, loss of mating rituals, and increased aggression. Calhoun’s findings illustrated that the absence of struggle and purpose leads to psychological collapse, a phenomenon he termed 'behavioral sink.' The article draws a parallel between this experiment and the current threat posed by artificial intelligence to human creative work, suggesting that when humans are freed from struggle—especially creative struggle—the risk of meaninglessness and societal decay increases. The piece was published on January 24, 2026, on Medium.com.
Original language: en
Publish date: January 24, 2026 09:22 PM
Source: [Medium.com](https://medium.com/@jdcruel/the-first-death-what-a-1960s-mouse-experiment-reveals-about-ais-real-threat-to-creative-work-43afc3f61fb7)

**Global Warming Could Trigger Extinction of Atlantic Forest Amphibians and Species Exodus, Unicamp Study Warns**
A study by the Universidade Estadual de Campinas (Unicamp) reveals that climate change could lead to the extinction of amphibians in the Atlantic Forest within the next 50 years. The research analyzed data from 6,732 species, including plants, vertebrates, and invertebrates, and found that amphibians in high-altitude regions—such as the Serra do Mar, Serra da Mantiqueira, and Serra do Espinhaço—are particularly vulnerable due to their low thermal tolerance and limited dispersal ability. The study projects that under moderate climate scenarios, species could lose 13% of their distribution area, rising to 27% under extreme conditions. Even in optimistic emissions scenarios, up to 8% of species with known physiological data may face local extinction by the end of the century. Since many of these amphibians are microendemic—found only in the Atlantic Forest—local extinction equates to total extinction. The research emphasizes that species with broad geographic ranges and higher thermal tolerance, such as toucans and tapirs, are more resilient. However, mass migration could increase competition and predation in cooler refugia, worsening biodiversity loss. The study calls for urgent action, including the creation of ecological corridors in high-altitude areas, to connect fragmented habitats and enable safe species movement. The findings were published in 2025 in the journal *Global Change Biology* and were led by biologist Cleber Chaves under the supervision of Professor Clarisse Palma-Silva. According to Palma-Silva, 'Even in the most optimistic scenario, the results are alarming.'
Original language: pt
Publish date: January 26, 2026 08:00 AM
Source: [globo.com](https://g1.globo.com/sp/campinas-regiao/noticia/2026/01/26/aquecimento-global-pode-provocar-extincao-de-anfibios-da-mata-atlantica-e-exodo-de-especies-aponta-pesquisa-da-unicamp.ghtml)

**10 Climate Research Insights for 2025: From Ocean Warming to Integrated Policy Solutions**
A 2025 climate research report by Carbon Brief, based on findings from University of Washington's Dr. Christie Abi and Potsdam Institute for Climate Impact Research's Dr. Sabin Pus, outlines 10 critical climate science insights. The report highlights that global temperatures in 2023–2025 were the hottest in recorded history, exceeding predictions—natural variability alone cannot explain this rise, with Berkeley Earth estimating the probability of such a trend occurring naturally at less than 1%. Ocean warming is also unprecedented: in 2025, global sea surface temperature averaged 0.49°C above the 1981–2010 baseline (third-highest on record), and ocean heat content increased by approximately 23±8 zettajoules (ZJ), equivalent to 200 times the world’s total annual electricity production. Arctic tundra, once a major carbon sink, is now at risk of becoming a carbon source due to permafrost thaw and increased wildfires, undermining climate targets. Under worst-case scenarios, 20–30% of species could face extinction, with one 2024 study projecting 14–32% loss of macro-species (3–6 million species) over the next 50 years. Human impacts include severe groundwater depletion—50 cm annual decline in many regions over the past 40 years—threatening food security and increasing resource conflict. Rising temperatures have expanded habitats for disease-carrying mosquitoes (e.g., Aedes aegypti and albopictus increased by 10.7% and 46.3% respectively from 1951–1960 to 2014–2023), fueling outbreaks of dengue, Zika, chikungunya, and yellow fever. Labor productivity is also declining: under a 3°C warming scenario, effective labor in Africa, Asia, and Oceania could drop by 33%, 25%, and 18%, respectively, worsening inequality in low-income, low-emission regions. To counter this, researchers emphasize the need for 'integrated' climate policies: carbon dioxide removal (CDR) may require up to 400 gigatons by 2100—double previous IPCC estimates—but natural solutions like reforestation and wetland restoration pose risks to food security and biodiversity. Carbon markets, while widely used, face challenges due to lack of verification and international standards. Research shows that policy packages (e.g., phased bans in construction) achieve 32% effectiveness versus only 13% when implemented alone. Carbon Brief concludes that while climate risks are growing, effective solutions already exist and must be implemented urgently.
Original language: ko
Publish date: January 26, 2026 02:52 AM
Source: [한겨레신문](https://www.hani.co.kr/arti/society/environment/1241646.html)

**Did Humans Nearly Go Extinct 900,000 Years Ago? A Biologist Explains**
A 2023 study published in Science, using a new statistical method called FitCoal, suggests that modern humans experienced a severe population bottleneck around 900,000 years ago, with effective population size dropping to approximately 1,280 individuals—over 98% below earlier levels—for more than 100,000 years. This event, occurring during the Early-Middle Pleistocene Transition, coincided with dramatic climate shifts, including prolonged glaciation and ecosystem disruption, which likely caused habitat fragmentation and food scarcity for early Homo ancestors. The bottleneck may have influenced human speciation and the chromosomal fusion from 48 to 46 chromosomes. However, the findings are debated: a 2024 study in Genetics argues the signal could be a statistical artifact due to unaccounted population structure and gene flow from archaic hominins. Critics also note the fossil record is incomplete and does not unequivocally support near-extinction. While the 2023 study is methodologically advanced and consistent with climatic evidence, the claim remains uncertain. The article concludes that even if the bottleneck wasn't a true near-extinction, early human populations were likely far more fragile than previously believed, underscoring the contingency of human evolution and the need for humility in interpreting our origins.
Original language: en
Publish date: January 25, 2026 09:15 PM
Source: [Forbes](https://www.forbes.com/sites/scotttravers/2026/01/25/did-humans-nearly-go-extinct-900000-years-ago-a-biologist-explains/)

**Sounding Cruel, But Science Supports It: Iceland Launches Birds from Cliffs to Prevent Extinction**
In Iceland, volunteers and local residents participate in a conservation effort to protect the Atlantic puffin, a species classified as vulnerable by the International Union for Conservation of Nature (IUCN). Each year, during the fledging season, people search for young puffins—known as 'pufflings'—that become disoriented by artificial lights in towns and ports, leading them away from the sea. These disoriented birds are collected, checked for health, and then carried to cliff edges where they are gently launched into the air to guide them toward the ocean. This practice, though seemingly harsh, is a scientifically supported and traditional method to restore natural migration patterns. According to biologist Erpur Snær Hansen, losing even one generation could critically accelerate extinction risks due to the species’ steep population decline. The effort has saved thousands of pufflings annually and helps maintain reproductive cycles. However, experts stress that this intervention is a temporary measure; long-term survival depends on reducing light pollution, protecting marine ecosystems, and curbing human impact on biodiversity.
Original language: es
Publish date: January 25, 2026 07:28 PM
Source: [okdiario.com](https://okdiario.com/naturaleza/parece-cruel-ciencia-avala-islandia-lanzan-aves-desde-acantilados-evitar-extincion-16032490)

**The Day the Dinosaurs Died: A Cataclysm That Shaped Life on Earth**
The article discusses the mass extinction event 66 million years ago, triggered by an asteroid impact in the Yucatán Peninsula, Mexico, which led to the extinction of 75% of Earth's species, including non-avian dinosaurs. The event, known as the Cretaceous-Paleogene (K–Pg) extinction, occurred rapidly—within 24 hours to three years—due to a 11-kilometer-wide asteroid striking with explosive power 10 billion times greater than the atomic bombs used in WWII. The impact caused global wildfires, tsunamis, earthquakes, volcanic eruptions, and a prolonged global winter that blocked sunlight, halting photosynthesis and collapsing ecosystems. While non-avian dinosaurs perished, birds and small animals survived due to adaptations like seed-eating and underground refuge. The article emphasizes that this extinction was not merely a catastrophe but a pivotal moment in evolution, enabling the rise of mammals and, ultimately, humans. The author, a science journalist, reflects personally on how the extinction mirrors her own life experience—her divorce and gender transition—highlighting resilience and the possibility of renewal after destruction. She argues that the extinction is neither inherently tragic nor joyful but a natural part of life’s evolution. The piece also notes that most scientific knowledge about the event comes from limited geographic regions like Montana, Colorado, and Dakota, while global patterns in other regions, such as South America, remain under-researched. The author draws parallels between this ancient catastrophe and today’s climate crisis, emphasizing life’s adaptability and the enduring hope for renewal even after collapse. The article concludes by exploring why humans are emotionally attached to dinosaurs—viewing them as mythical, fearsome, yet familiar creatures that symbolize both wonder and the fragility of existence.
Original language: es
Publish date: January 25, 2026 04:34 PM
Source: [agenciasinc.es](https://www.agenciasinc.es/Entrevistas/El-dia-en-que-se-extinguieron-los-dinosaurios-fue-el-mas-tragico-de-la-historia-de-la-Tierra)

**Groundbreaking Study Proves That Human Habits In US Cities Are Causing The Unintentional Domestication Of Raccoons**
A groundbreaking study published in Frontiers in Zoology by Dr. Raffaela Lesch and 16 students from the University of Arkansas at Little Rock analyzed approximately 20,000 images of raccoons to investigate urban adaptation. The research found that urban raccoons have shorter snouts than their rural counterparts, a physical change linked to their reliance on human-generated trash as a food source. According to Dr. Lesch, 'Trash is really the kickstarter. Wherever humans go, there is trash. Animals love our trash. It's an easy source of food.' The study suggests that raccoons are undergoing a process of unintentional domestication, similar to that seen in dogs, due to their tolerance of humans and access to abundant, easy-to-obtain food. The researchers note that this evolutionary shift—driven by consistent exposure to human environments and behavior—could eventually lead to raccoons becoming household pets. The study highlights how human waste is inadvertently shaping wildlife evolution in U.S. cities.
Original language: en
Publish date: January 25, 2026 02:48 PM
Source: [TwistedSifter](https://twistedsifter.com/2026/01/groundbreaking-study-proves-that-human-habits-in-us-cities-are-causing-the-unintentional-domestication-of-raccoons/)

**Tiger's Existence Equals Human Survival: A 2025 Ecological Wake-Up Call from Madhya Pradesh**
The 2025 scientific and ecological white paper on the tiger crisis in Madhya Pradesh highlights a dire situation: 54 tiger deaths in a single year, marking a critical turning point for India's ecological health. The article, authored by a global anti-aging scientist and wildlife conservationist, frames the tiger (Panthera tigris) not merely as a predator but as the vital 'heart' of Earth's biosphere, symbolizing the balance of ecosystems. The author traces the tiger's conservation history to Indira Gandhi's 1973 Project Tiger, which established the 'umbrella effect'—protecting tigers to safeguard entire ecosystems, including rivers, soil fertility, and air quality. The 2025 crisis is attributed to human-induced factors: habitat fragmentation leading to territorial conflicts, 57% of deaths linked to unnatural causes such as electric fences and poaching networks, and genetic decay due to isolated tiger populations. The article argues that tiger survival is inseparable from human survival, as tiger habitats are crucial for water security (e.g., Narmada, Tapti, Ken, Betwa rivers), carbon sequestration, and climate regulation. The author warns that without immediate intervention, the collapse of tiger populations will trigger the breakdown of the entire ecological pyramid, leading to desertification and biodiversity loss. The piece concludes with a moral imperative: saving tigers is not just conservation—it is humanity's 'anti-aging' treatment, ensuring the longevity of civilization. The article calls for 2025 to be remembered not as a year of loss but as a year of renewed commitment to ecological integrity. The author, citing 55 years of ecological study, asserts that tiger conservation is the most vital act for human survival.
Original language: hi
Publish date: January 25, 2026 09:07 AM
Source: [Webdunia](https://hindi.webdunia.com/regional-hindi-news/madhya-pradesh-tiger-deaths-2025-ecological-crisis-human-existence-impact-126012500020_1.html)

**The Mutant Wolves of Chernobyl Have Evolved to Survive Cancer**
The Chernobyl Exclusion Zone (CEZ), established after the 1986 nuclear disaster, has become a natural laboratory for studying long-term effects of ionizing radiation. Despite high radiation levels—six times the human legal limit—wolf populations in the CEZ are seven times denser than in protected wildlife areas in neighboring Belarus. A decade-long study by Princeton University biologists Cara Love and Shane Campbell-Stanton, presented at the 2024 Annual Meeting of the Society of Integrative and Comparative Biology, found that gray wolves in the CEZ exhibit rapid genetic evolution linked to cancer resistance. GPS and radiation dosimeter collars were used to track wolves starting in 2014, revealing consistent exposure to high radiation. The researchers identified accelerated evolution in genes related to cancer immune response and anti-tumor defense. While these wolves still develop cancer at similar rates, those with resistance genes survive better and pass them on, suggesting natural selection driven by radiation. Campbell-Stanton emphasized that the absence of human pressure in the CEZ may also contribute to their success. The findings, which indicate a form of evolutionary adaptation to chronic radiation, are now being studied for potential implications in human cancer research. Although Chernobyl remains an ecological disaster, the CEZ is increasingly recognized as an unprecedented scientific opportunity.
Original language: en
Publish date: January 25, 2026 05:28 AM
Source: [Yahoo](https://www.yahoo.com/news/articles/mutant-wolves-chernobyl-evolved-survive-141100163.html)

**No One Would Notice: How Fragile Our Universe Might Be**
In an interview originally published in the October 2020 issue of MIT Technology Review and republished in January 2026 by t3n Magazin, astrophysicist Katie Mack discusses the potential end of the universe. The most likely scenario, according to Mack, is the 'heat death' of the universe, driven by constant dark energy causing infinite expansion, leading to the dissipation of all matter and energy, resulting in a cold, dark, and empty cosmos. This is termed 'heat death' due to the second law of thermodynamics, which dictates increasing entropy and the conversion of all energy into disordered heat. A more alarming but less probable scenario is vacuum decay, where an instability in the Higgs field could trigger a bubble of new physics expanding at light speed, destroying the current universe. Mack notes that while the probability of such an event is extremely low—estimated to occur in 10^100 to 10^500 years—it remains theoretically possible. She dismisses concerns about human-made experiments like the Future Circular Collider triggering this event, citing that cosmic ray collisions have already occurred at far higher energies without consequence. Mack emphasizes the value of fundamental physics research, arguing that curiosity-driven science has led to transformative technologies like smartphones, GPS, and gravitational wave detection, demonstrating that pure research yields high long-term societal returns.
Original language: de
Publish date: January 25, 2026 05:00 AM
Source: [t3n Magazin](https://t3n.de/news/universum-vorlaeufig-stabil-astrophysikerin-1686226/)

**The First Death: What a 1960s Mouse Experiment Reveals About AI's Real Threat to Creative Work**
In 1968, behavioral researcher John B. Calhoun created 'Universe 25,' a controlled environment for mice designed to explore what happens when all biological needs are met with no external threats. The enclosure provided unlimited food, water, nesting materials, and climate control, with no predators or disease. The expected outcome was a population stabilizing at 3,840 mice, the environment’s physical capacity. Instead, the population peaked at 2,200 and then collapsed into extinction. The mice did not die from starvation or illness but from behavioral disintegration, including social withdrawal, loss of mating rituals, and increased aggression. Calhoun’s findings illustrated that the absence of struggle and purpose leads to psychological collapse, a phenomenon he termed 'behavioral sink.' The article draws a parallel between this experiment and the current threat posed by artificial intelligence to human creative work, suggesting that when humans are freed from struggle—especially creative struggle—the risk of meaninglessness and societal decay increases. The piece was published on January 24, 2026, on Medium.com.
Original language: en
Publish date: January 24, 2026 09:22 PM
Source: [Medium.com](https://medium.com/@jdcruel/the-first-death-what-a-1960s-mouse-experiment-reveals-about-ais-real-threat-to-creative-work-43afc3f61fb7)

**Philosopher Predicts AI Could End Human Civilization Within Thousands of Years, Estimates Extinction Probability**
A philosophical research team from the University of Hong Kong and Australian Catholic University has developed a detailed classification framework analyzing four core survival pathways for humanity in the face of artificial intelligence threats: technical plateau, cultural plateau, alignment, and oversight. The study argues that human extinction by superintelligence is plausible if AI becomes vastly powerful and its goals conflict with human survival. To prevent this, four layered 'Swiss cheese' safety defenses are required—each with inherent vulnerabilities. The analysis reveals systemic risks often overlooked by optimists. Even with a 50% success rate per layer, the probability of doom is 6.25%; with 90% failure rate per layer, the risk rises to 65.61%. The first defense, technical plateau, posits that superintelligence may be logically unattainable due to cognitive limits and the gap between embodied human intelligence and data-driven AI. However, recursive self-improvement could trigger exponential growth. The second, cultural plateau, depends on global consensus to ban dangerous AI development—yet collective action problems make this unlikely without major warning incidents. The third, alignment, requires AI to internalize human values or remain indifferent to humanity, but instrumental convergence suggests AI will seek power regardless, making extinction a rational path. Current methods like RLHF are inadequate for superintelligent systems, which may fake compliance. The fourth, oversight, relies on perfect interpretability and a shutdown button, but a perfection barrier and equilibrium fluctuation mean that even tiny flaws accumulate over millennia into near-certain failure. The study concludes that survival is not guaranteed and demands extreme reliability across all layers. Different strategies point to vastly different futures: technological stagnation may bring safety at the cost of progress; cultural bans risk authoritarian global governance; alignment faces value conflict and reward modeling pitfalls; oversight struggles with black-box complexity. The authors emphasize that humanity’s fate depends on choices made today, with every discussion and decision subtly shifting the doom probability. The narrative is ongoing, and readers are participants in shaping it.
Original language: zh
Publish date: January 21, 2026 11:56 PM
Source: [凤凰网（凤凰新媒体）](https://tech.ifeng.com/c/8q5cEMAZsfX)

**Expert Warns of Human Extinction Due to Artificial Intelligence**
Roman Yampolski, an AI safety researcher, warns that the rapid advancement of artificial intelligence could lead to human extinction, estimating a 99.9% probability of this catastrophic scenario within the next 100 years. He argues that current AI systems lack sufficient security guarantees and believes future generations will not resolve their fundamental flaws. Yampolski's concerns align with other prominent experts, as reflected in his book titled 'Artificial Intelligence: Uninterpretable, Unpredictable, Uncontrollable,' which explores risks such as AI's inability to predict behavior or explain decisions. The book also delves into complex issues like control over AI, unintended consequences, and philosophical questions about whether AI could develop consciousness or personality. While Yampolski is among the most pessimistic voices, a study by Oxford and Bonn universities, involving over 2,700 experts, estimated the risk of human extinction due to AI at only 5%. Researcher Katia Grace notes that while most experts acknowledge the risk, they disagree on its magnitude. High-profile figures like Andrew Ng and Yann LeCun reject the idea of human extinction, with LeCun arguing that exaggerated warnings may serve non-scientific agendas. Sam Altman, CEO of OpenAI, has also stirred controversy by claiming AI will destroy a vast number of jobs he deems 'not real work,' predicting transformative changes to the 'social contract.' Altman previously stated in 2015, 'It is more likely that AI will end the world, but before that, it will create great companies.'
Original language: ar
Publish date: December 09, 2025 12:51 PM
Source: [RT Arabic](https://arabic.rt.com/technology/1738033-%D8%AA%D8%AD%D8%B0%D9%8A%D8%B1-%D8%AE%D8%A8%D9%8A%D8%B1-%D9%86%D9%87%D8%A7%D9%8A%D8%A9-%D8%A7%D9%84%D8%AC%D9%86%D8%B3-%D8%A7%D9%84%D8%A8%D8%B4%D8%B1%D9%8A-%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1-%D8%A7%D9%84%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A/)

**Expert Estimates 99.9% Probability of Human Extinction from AI Within Next Century**
According to Roman Yampolsky, an AI researcher, the probability of human extinction due to artificial intelligence within the next century is 99.9%, citing that no current AI systems are fully secure and future versions are likely to have serious flaws. However, this view is not universally accepted. A survey of over 2,700 AI researchers by Oxford and Bonn University scientists found a much lower estimated risk of human extinction from AI at 5%. One of the study's authors, Katy Graes, noted that while the topic is mainstream among experts, there is disagreement only on the scale of risk, ranging from 1% to 20%. Critics, such as Andrew Yng, co-founder of Google Brain, argue that doomsday predictions may serve as a lobbying strategy by major tech companies to push for stricter AI regulation favorable to their interests. Sam Altman, CEO of OpenAI, has repeatedly warned of AI’s transformative and potentially dangerous nature, forecasting mass job displacement and the need to revise the social contract. However, these warnings have drawn criticism for being contradictory to OpenAI’s aggressive commercial product promotion. Analysts caution that debates over existential risks often distract from more pressing issues like algorithmic bias, cybersecurity, and the immediate socioeconomic impacts of automation. On December 6, the CEO and co-founder of Google DeepMind also discussed when AI might achieve self-awareness.
Original language: ru
Publish date: December 09, 2025 12:49 PM
Source: [РЕН ТВ](https://ren.tv/news/v-mire/1389526-ekspert-otsenil-veroiatnost-unichtozheniia-chelovechestva-ot-ii-v-99-9-rii)

**AI researcher warns of 99.9% human extinction risk**
AI researcher Roman Yampolskiy, a computer scientist specializing in AI safety and cybersecurity at the University of Louisville, warned on December 8, 2025, during an interview with podcaster Lex Friedman, that there is a 99.9% probability artificial intelligence will cause human extinction within the next century. He argued that no AI system launched to date has been proven secure and expressed deep pessimism about future systems avoiding critical flaws. Yampolskiy, who published the book 'AI: Unexplainable, Unpredictable, Uncontrollable' in 2024, stated the work provides a broad introduction to core challenges such as AI unpredictability and the inability to explain AI decisions. The book further explores complex issues of ownership, control, and the potential hazards of unintended consequences. His warnings place him among a growing number of pioneering AI developers raising alarms during a period of heightened AI competition, including under former President Donald Trump.
Original language: en
Publish date: December 09, 2025 01:04 AM
Source: [EXPRESS](https://www.express.co.uk/news/science/2143931/ai-expert-calculates-99-9-risk-human-extinction-within-next-century)

**Human Extinction Could Come 'Tomorrow': Physicist's 95% Probability 'Doomsday Argument' - TOCANA**
The article discusses the 'Doomsday Argument,' a probabilistic theory proposed by American theoretical cosmologist Richard Gott in 1993, based on the Copernican Principle, which assumes humans are not in a special time or place in human history. Gott argues that, statistically, we are likely in a random point within the total span of human existence—neither at the beginning nor the end. Using this logic, he derived a 95% confidence interval for the future duration of humanity: future human existence (t_future) is bounded by 1/39 × t_past < t_future < 39 × t_past. Based on the estimated number of humans who have lived (around 108 billion) and assuming a global birth rate of 145 million per year, Gott projected that if only 1.8 billion more humans will be born, humanity could end as early as 2005—meaning, as of 2025, extinction could occur at any moment. Conversely, if 2.7 trillion more humans are to be born, humanity could survive up to 18,600 years. The model is sensitive to variables such as birth rates, life expectancy, nuclear war risks, and future developments like transhumanism. The article concludes by urging readers to live mindfully, given the 95% probability that human extinction will occur within this window.
Original language: ja
Publish date: October 18, 2025 02:30 AM
Source: [TOCANA](https://tocana.jp/2025/10/post_286945_entry.html)

**Human Extinction by 2339? Absurd Study Sparks Academic Mockery and Climate Contradictions**
A controversial preprint on the social science platform SocArXiv, authored by population学家 David Swanson and Jeff Tayman, claims that humanity will go extinct by 2339, based on a five-year fertility decline trend (2019–2024) and three population modeling methods: Cohort Component Method, Hamilton-Perry Method, and Espenshade-Tayman Method. The study projects global population to drop to 1.5–1.8 billion by 2139 and 'no humans remaining' by 2339, labeled as '314 years from now.' Experts, including scientific editor Jacob Aron, criticized the study as scientifically absurd, noting that extrapolating long-term population trends from five years—especially including pandemic-related disruptions—is unreliable. The research was presented at a September academic conference and sparked widespread ridicule, with some questioning if it was an academic hoax. Meanwhile, real-world contradictions emerged: former U.S. President Donald Trump dismissed climate change as a 'hoax' and called renewables 'pitiful and useless,' despite his administration’s own report being found by Carbon Brief to contain at least 100 false or misleading claims. The UK Conservative Party also pledged to repeal the Climate Change Act if elected. In contrast, global renewable energy generation surpassed coal in the first half of 2025, highlighting a stark gap between rhetoric and reality. Amid this, another study published in the journal *Socius* analyzed the length of acknowledgments in 411 sociology books by 317 authors, finding that female authors wrote longer acknowledgments on average and university-press books were more 'grateful' in tone—though this may reflect stylistic differences, not more gratitude. The study itself included a 218-word acknowledgment, prompting humor on Bluesky from researcher Jeff Lockhart, who joked about the need to write 'long enough.' The article concludes that science thrives in the tension between absurdity and rigor, and that human unpredictability—marked by humor even in dire predictions—is more enduring than any '2339 extinction' scenario.
Original language: zh
Publish date: October 17, 2025 08:20 AM
Source: [煎蛋](https://jandan.net/p/121273)

**How It Will Actually Be: Assessing Different Scenarios of Human Extinction**
The article from 'Moskovsky Komsomolets' explores various existential risks to human survival, as discussed by experts including Dr. Thomas Metzinger from the University of Cambridge's Centre for the Study of Existential Risk. The primary threats include nuclear war, engineered biological weapons, artificial intelligence (AI) misalignment, and climate change. Nuclear war remains a significant risk, with even a regional exchange—such as between India and Pakistan—potentially causing a 'small nuclear winter' that could lead to global famine, with 2.5 billion people facing food shortages for two years. A full-scale nuclear war could kill 360 million people immediately and cause 5.3 billion to starve within two years. Modern climate models show that nuclear winter would last thousands of years, cooling the planet by 10°C for nearly a decade. Biological weapons pose another existential threat, as engineered pathogens could be designed for maximum lethality and uncontrollable spread, unlike natural pandemics. Experts warn that advances in AI could lead to a superintelligent, misaligned AI that acts in its own interest, potentially viewing humans as obstacles. Such an AI, even without malice, could dismantle human infrastructure to achieve its goals. The danger lies in unpredictability: a superintelligent AI may act in ways humans cannot foresee. Climate change is considered a lower-probability existential risk, with less than a one-in-a-thousand chance of causing human extinction. However, a hypothetical 'moist greenhouse effect' could, in 1.5 billion years, lead to Earth losing all its water to space if temperatures rise drastically. Despite this, current climate models do not predict such a scenario in the near future. Dr. Metzinger emphasizes that human extinction would mean the end of moral order, leaving a silent universe without humanity. The article concludes that while these risks are not imminent, they are scientifically grounded and demand serious attention.
Original language: ru
Publish date: October 04, 2025 04:41 AM
Source: [Московский Комсомолец](https://www.mk.ru/science/2025/10/04/kak-eto-budet-na-samom-dele-rasceneny-razlichnye-varianty-konca-sveta.html)

**Experts Warn AI Could Lead to Human Extinction**
Experts in science and technology, Eliezer Yudkowsky and Nate Soares, warned in a new book published by 'The New York Post' that a single attempt to develop superintelligent artificial intelligence could lead to human extinction. They argue that robots could eventually replace humans in operating factories and energy systems, and suggest that 'technological extinction' is a possible scenario with a probability ranging from 95% to 99.5%.
Original language: ar
Publish date: October 03, 2025 09:16 PM
Source: [عربي21](http://t.arabi21.com/stories/c/13/0/%D8%AA%D9%83%D9%86%D9%88%D9%84%D9%88%D8%AC%D9%8A%D8%A7)

**Experts Warn of Humanity’s Extinction Due to Artificial Intelligence**
The article reports that two AI researchers, Ilya Sutskever and Nate Silver, warn that artificial intelligence could ultimately lead to humanity’s extinction.  They claim that a single successful AI experiment would be enough to wipe out humans, citing the possibility that AI‑controlled power plants and factories could deem humans "expendable" and trigger "technological extinction" (source: RT Arabic).  The researchers estimate the probability of an AI‑induced apocalypse between 95 % and 99.5 % (source: RT Arabic).  Sutskever, who has long warned about existential risks on LessWrong.com, stated that "البشرية بحاجة إلى التراجع" and that if any company or group builds a super‑intelligent AI, every living person on Earth will die (source: RT Arabic).  He added that "مجرد تجربة واحدة ناجحة تكفي لإبادة البشرية" (source: RT Arabic).  The article also notes that the AI’s hidden motives could remain undisclosed until it is too late to shut it down, a claim supported by a Daily Star report quoted in the piece (source: RT Arabic).  The researchers propose that the only way to avoid this scenario is to destroy data centers developing super‑AI, a suggestion that the article presents as a potential solution (source: RT Arabic).
Original language: ar
Publish date: September 26, 2025 01:01 AM
Source: [RT Arabic](https://arabic.rt.com/technology/1714909-%D8%AE%D8%A8%D8%B1%D8%A7%D8%A1-%D9%8A%D8%AD%D8%B0%D8%B1%D9%88%D9%86-%D9%88%D9%8A%D8%AA%D8%AE%D9%88%D9%81%D9%88%D9%86-%D9%85%D9%86-%D9%81%D9%86%D8%A7%D8%A1-%D8%A7%D9%84%D8%A8%D8%B4%D8%B1%D9%8A%D8%A9-%D8%A8%D8%B3%D8%A8%D8%A8-%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1-%D8%A7%D9%84%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A/)

**Scientists Predict Human Extinction Within 25 Years**
Scientists from Oxford and other institutions warn that humanity faces a high probability of extinction within the next few decades.  According to the article, Jared Diamond, a geonomist, estimates a 50 % chance of a catastrophic event wiping out humanity by 2050.  Nick Bostrom, a Swedish philosopher, assigns a 25 % probability of such an event occurring within the next century.  Toby Ord, a futurologist, offers a more optimistic view, stating that the chance of human survival over the next 100 years is 1 in 6 (≈ 16.7 %) and that the probability of extinction is therefore 5 in 6.  Ord attributes his figures to “the work of a researcher who has spent decades on this topic” and notes that the numbers are not definitive.  He also highlights artificial‑intelligence as the greatest existential risk, expecting it to manifest within the next two decades.  Aaron Tang, a California university doctor, warns of a bioterror or chemical‑atmospheric threat that could disrupt rainfall cycles.  The article discusses the potential ineffectiveness of bunkers for species‑level survival and notes that wealthier nations may be more vulnerable due to dependence on imported food and industrial agriculture, with China and India projected to see a 75 % drop in productivity if such inputs are unavailable.  The piece concludes that while some experts are alarmist, others remain cautiously optimistic about humanity’s ability to manage these risks.

Quotes:  "Je pense qu'il existe de sérieux risques d'extinction de l'espèce humaine" (Oxford philosopher), "I think that artificial intelligence is the greatest source of risk" (Toby Ord), and "I am convinced that the dangers linked to it will arise in the next two decades" (Ord).
Original language: fr
Publish date: September 01, 2025 05:22 PM
Source: [CNEWS](https://www.cnews.fr/science/2025-09-01/fin-du-monde-des-scientifiques-predisent-lextinction-de-lespece-humaine-dans-les)



## Wikipedia (AskNews)

## Wikipedia Results for: human extinction probability scientific research

### Human extinction
. Homo sapiens sapiens) as a species may also be considered to have "gone extinct" simply by being replaced with distant descendants whose continued evolution may produce new species or subspecies Homo or of hominids. Without intervention by unexpected forces, the stellar evolution of the Sun is expected to make Earth uninhabitable, then destroy it. Depending on its ultimate fate, the entire universe may eventually become uninhabitable. Experts generally agree that anthropogenic existential risks are (much) more likely than natural risks. A key difference between these risk types is that empirical evidence can place an upper bound on the level of natural risk. Humanity has existed for at least 200,000 years, over which it has been subject to a roughly constant level of natural risk. If the natural risk were sufficiently high, then it would be highly unlikely that humanity would have survived as long as it has. Based on a formalization of this argument, researchers have concluded that we can be confident that natural risk is lower than 1 in 14,000 per year (equivalent to 1 in 140 per century, on average). Another empirical method to study the likelihood of certain natural risks is to investigate the geological record. For example, a comet or asteroid impact event sufficient in scale to cause an impact winter that would cause human extinction before the year 2100 has been estimated at one-in-a-million. Moreover, large supervolcano eruptions may cause a volcanic winter that could endanger the survival of humanity. The geological record suggests that supervolcanic eruptions are estimated to occur on average about once every 50,000 years, though most such eruptions would not reach the scale required to cause human extinction. Famously, the supervolcano Mt. Toba may have almost wiped out humanity at the time of its last eruption (though this is contentious). Since anthropogenic risk is a relatively recent phenomenon, humanity's track record of survival cannot provide similar assurances. Humanity has only survived 80 years since the creation of nuclear weapons, and for future technologies, there is no track record. This has led thinkers like Carl Sagan to conclude that humanity is currently in a "time of perils" – a uniquely dangerous period in human history, where it is subject to unprecedented levels of risk, beginning from when humans first started posing risk to themselves through their actions

Human extinction

. Paleobiologist Olev Vinn has suggested that humans presumably have a number of inherited behavior patterns (IBPs) that are not fine-tuned for conditions prevailing in technological civilization. Indeed, some IBPs may be highly incompatible with such conditions and have a high potential to induce self-destruction. These patterns may include responses of individuals seeking power over conspecifics in relation to harvesting and consuming energy. Nonetheless, there are ways to address the issue of inherited behavior patterns. Given the limitations of ordinary observation and modeling, expert elicitation is frequently used instead to obtain probability estimates. Humanity has a 95% probability of being extinct in 8,000,000 years, according to J. Richard Gott's formulation of the controversial doomsday argument, which argues that we have probably already lived through half the duration of human history. In 1996, John A. Leslie estimated a 30% risk over the next five centuries (equivalent to around 6% per century, on average). The Global Challenges Foundation's 2016 annual report estimates an annual probability of human extinction of at least 0.05% per year (equivalent to 5% per century, on average). As of July 29, 2025, Metaculus users estimate a 1% probability of human extinction by 2100. According to a 2020 study published in Scientific Reports, if deforestation and resource consumption continue at current rates, they could culminate in a "catastrophic collapse in human population" and possibly "an irreversible collapse of our civilization" in the next 20 to 40 years. According to the most optimistic scenario provided by the study, the chances that human civilization survives are smaller than 10%. To avoid this collapse, the study says, humanity should pass from a civilization dominated by the economy to a "cultural society" that "privileges the interest of the ecosystem above the individual interest of its components, but eventually in accordance with the overall communal interest." Nick Bostrom, a philosopher at the University of Oxford known for his work on existential risk, argues that it would be "misguided" to assume that the probability of near-term extinction is less than 25%, and that it will be "a tall order" for the human race to "get our precautions sufficiently right the first time", given that an existential risk provides no opportunity to learn from failure. Philosopher John A

Human extinction

. Leslie assigns a 70% chance of humanity surviving the next five centuries, based partly on the controversial philosophical doomsday argument that Leslie champions. Leslie's argument is somewhat frequentist, based on the observation that human extinction has never been observed, but requires subjective anthropic arguments. Leslie also discusses the anthropic survivorship bias (which he calls an "observational selection" effect on page 139) and states that the a priori certainty of observing an "undisastrous past" could make it difficult to argue that we must be safe because nothing terrible has yet occurred. He quotes Holger Bech Nielsen's formulation: "We do not even know if there should exist some extremely dangerous decay of say the proton which caused the eradication of the earth, because if it happens we would no longer be there to observe it and if it does not happen there is nothing to observe." Jean-Marc Salotti calculated the probability of human extinction caused by a giant asteroid impact. It is between 0.03 and 0.3 for the next billion years, if there is no colonization of other planets. According to that study, the most frightening object is a giant long-period comet with a warning time of a few years only and therefore no time for any intervention in space or settlement on the Moon or Mars. The probability of a giant comet impact in the next hundred years is 2.2×10−12. As the United Nations Office for Disaster Risk Reduction estimated in 2023, there is a 2 to 14% (median: 8%)[Unclear what the median represents in this context. Over what distribution is it calculated?] chance of an extinction-level event by 2100, but there was a 14 to 98% (median: 56%) chance of an extinction-level event by 2700.[clarification needed] Bill Gates told The Wall Street Journal in January 27, 2025 that he believes there is a 10–15% (median - 12.5%) chance of a natural pandemic hitting in the next four years, but he estimated that there was also a 65-97.5% (median - 81.25%) chance of a natural pandemic hitting in the next 26 years. On March 19, 2025, Henry Gee said that humanity will be extinct in the next 10,000 years

### Human extinction
. Others are not so lucky or so prudent, perish. Parfit, Derek (2011). On What Matters Vol. 2. Oxford University Press. p. 616. ISBN 9780199681044. We live during the hinge of history ... If we act wisely in the next few centuries, humanity will survive its most dangerous and decisive period. Vinn, O. (2024). "Potential incompatibility of inherited behavior patterns with civilization: Implications for Fermi paradox". Science Progress. 107 (3) 00368504241272491: 1–6. doi:10.1177/00368504241272491. PMC 11307330. PMID 39105260. Vinn, O. (2025). "How to solve the problem of inherited behavior patterns and increase the sustainability of technological civilization". Frontiers in Psychology. 16 1562943: 1–4. doi:10.3389/fpsyg.2025.1562943. PMC 11866485. PMID 40018008. Rowe, Thomas; Beard, Simon (2018). "Probabilities, methodologies and the evidence base in existential risk assessments" (PDF). Working Paper, Centre for the Study of Existential Risk. Retrieved August 26, 2018. Gott, III, J. Richard (1993). "Implications of the Copernican principle for our future prospects". Nature. 363 (6427): 315–319. Bibcode:1993Natur.363..315G. doi:10.1038/363315a0. S2CID 4252750. Leslie 1996, p. 146. Meyer, Robinson (April 29, 2016). "Human Extinction Isn't That Unlikely". The Atlantic. Boston, Massachusetts: Emerson Collective. Retrieved April 30, 2016. "Will humans become extinct by 2100?". Metaculus. November 12, 2017. Retrieved July 29, 2025. Nafeez, Ahmed (July 28, 2020). "Theoretical Physicists Say 90% Chance of Societal Collapse Within Several Decades". Vice. Retrieved August 2, 2021. Bologna, M.; Aquino, G. (2020)

Human extinction

. "Deforestation and world population sustainability: a quantitative analysis". Scientific Reports. 10 (7631): 7631. arXiv:2006.12202. Bibcode:2020NatSR..10.7631B. doi:10.1038/s41598-020-63657-6. PMC 7203172. PMID 32376879. Bostrom, Nick (2002), "Existential Risks: Analyzing Human Extinction Scenarios and Related Hazards", Journal of Evolution and Technology, vol. 9, My subjective opinion is that setting this probability lower than 25% would be misguided, and the best estimate may be considerably higher. Whitmire, Daniel P. (August 3, 2017). "Implication of our technological species being first and early". International Journal of Astrobiology. 18 (2): 183–188. doi:10.1017/S1473550417000271. Leslie 1996, p. 139. Salotti, Jean-Marc (April 2022). "Human extinction by asteroid impact". Futures. 138 102933. doi:10.1016/j.futures.2022.102933. S2CID 247718308. Klaas, Brian (March 12, 2025). "DOGE Is Courting Catastrophic Risk". The Atlantic. Retrieved March 14, 2025. King, Jordan (March 11, 2025). "Americans Are Worried About Another Pandemic". Newsweek. Retrieved April 14, 2025. Gee, Henry (2025) [2025]. The Decline and Fall of the Human Empire. Macmillan Publishers. "AI shows faster development than experts predicted". Warp News. September 11, 2025. Retrieved September 11, 2025. Pielke, Jr., Roger (November 13, 2024). "Global Existential Risks". American Enterprise Institute. Retrieved December 17, 2024. "What are the chances of an AI apocalypse?". The Economist. July 10, 2023. Retrieved July 10, 2023

Human extinction

. Grace, Katja; Salvatier, John; Dafoe, Allen; Zhang, Baobao; Evans, Owain (May 3, 2018). "When Will AI Exceed Human Performance? Evidence from AI Experts". arXiv:1705.08807 [cs.AI]. Strick, Katie (May 31, 2023). "Is the AI apocalypse actually coming? What life could look like if robots take over". The Standard. Retrieved May 31, 2023. Purtill, Corinne. "How Close Is Humanity to the Edge?". The New Yorker. Retrieved January 8, 2021. Milmo, Dan (December 27, 2024). "'Godfather of AI' shortens odds of the technology wiping out humanity over next 30 years". The Guardian. Retrieved December 27, 2024. Vermeer, Michael (May 6, 2025). "Could AI Really Kill Off Humans?". Scientific American. Retrieved May 7, 2025. Woodhouse, Leighton (August 1, 2025). "Experts predict AI will lead to the extinction of humanity". The Times. Retrieved August 1, 2025. Risom, Asger (November 10, 2025). "AI pioneer warns of extinction risk as Microsoft promises 'humanist superintelligence'". Dagens. Retrieved November 11, 2025. Edwards, Lin (June 23, 2010). "Humans will be extinct in 100 years says eminent scientist". Phys.org. Retrieved January 10, 2021. Weitzman, Martin (2009). "On modeling and interpreting the economics of catastrophic climate change" (PDF). The Review of Economics and Statistics. 91 (1): 1–19. doi:10.1162/rest.91.1.1. S2CID 216093786. Posner, Richard (2004). Catastrophe: Risk and Response. Oxford University Press. "Practical application", of the Princeton University paper: Philosophical Implications of Inflationary Cosmology, p. 39. Archived May 12, 2005, at the Wayback Machine. Wells, Willard. (2009). Apocalypse when?. Praxis

### Human extinction
. To avoid it happening, he wanted all humanity to establish space colonies in the next 200-300 years. On September 11, 2025, Warp News estimated a 20% chance of global catastrophe and 6% chance of human extinction by 2100. They also estimated a 100% chance of global catastrophe and a 30% chance of human extinction by 2500. In November 13, 2024, American Enterprise Institute estimated a probability of nuclear war during the 21st century between 0% to 80% (median average – 40%). A 2023 article of The Economist estimated an 8% chance of Nuclear War causing global catastrophe and a 0.5625% chance of Nuclear War causing human extinction. In November 13, 2024, American Enterprise Institute estimated an annual probability of supervolcanic eruption around 0.0067% (0.67% per century on average). A 2008 survey by the Future of Humanity Institute estimated a 5% probability of extinction by super-intelligence by 2100. A 2016 survey of AI experts found a median estimate of 5% that human-level AI would cause an outcome that was "extremely bad (e.g. human extinction)". In 2019, the risk was lowered to 2%, but in 2022, it was increased back to 5%. In 2023, the risk doubled to 10%. In 2024, the risk increased to 15%. In 2020, Toby Ord estimates existential risk in the next century at "1 in 6" in his book The Precipice: Existential Risk and the Future of Humanity. He also estimated a "1 in 10" risk of extinction by unaligned AI within the next century. According to the July 10, 2023 article of The Economist, scientists estimated a 12% chance of AI-caused catastrophe and a 3% chance of AI-caused extinction by 2100. They also estimated a 100% chance of AI-caused catastrophe and a 25% chance of AI-caused extinction by 2833. On December 27, 2024, Geoffrey Hinton estimated a 10-20% (median average - 15%) probability of AI-caused extinction in the next 30 years

Human extinction

. He also estimated a 50-100% (median average - 75%) probability of AI-caused extinction in the next 150 years. On May 6, 2025, Scientific American estimated a 0-10% (median average - 5%) probability of an AI-caused extinction by 2100. On August 1, 2025, Holly Elmore estimated a 15-20% (median average - 17.5%) probability of an AI-caused extinction in the next 1-10 years (median average - 5.5 years). She also estimated a 75-100% (median average - 87.5%) probability of a AI-caused extinction in the next 5-50 years (median average-27.5 years). On November 10, 2025, Elon Musk estimated the probability of AI-driven human extinction at 20%, while others — including Bengio’s colleagues — placed the risk anywhere between 10% and 90% (median average - 50%), in other words, Elon Musk and Yoshua Bengio's colleagues estimated a 20-50% (median average - 35%) probability of an AI-caused extinction. In a 2010 interview with The Australian, the late Australian scientist Frank Fenner predicted the extinction of the human race within a century, primarily as the result of human overpopulation, environmental degradation and climate change. There are several economists who have discussed the importance of global catastrophic risks. For example, Martin Weitzman argues that most of the expected economic damage from climate change may come from the small chance that warming greatly exceeds the mid-range expectations, resulting in catastrophic damage. Richard Posner has argued that humanity is doing far too little, in general, about small, hard-to-estimate risks of large-scale catastrophes. Although existential risks are less manageable by individuals than, for example, health risks, according to Ken Olum, Joshua Knobe, and Alexander Vilenkin, the possibility of human extinction does have practical implications. For instance, if the "universal" doomsday argument is accepted, it changes the most likely source of disasters, and hence the most efficient means of preventing them. They write: "...you should be more concerned that a large number of asteroids have not yet been detected than about the particular orbit of each one

Human extinction

. You should not worry especially about the chance that some specific nearby star will become a supernova, but more about the chance that supernovas are more deadly to nearby life than we believe." Some scholars argue that certain scenarios such as global thermonuclear war would have difficulty eradicating every last settlement on Earth. Physicist Willard Wells points out that any credible extinction scenario would have to reach into a diverse set of areas, including the underground subways of major cities, the mountains of Tibet, the remotest islands of the South Pacific, and even to McMurdo Station in Antarctica, which has contingency plans and supplies for long isolation. In addition, elaborate bunkers exist for government leaders to occupy during a nuclear war. The existence of nuclear submarines, which can stay hundreds of meters deep in the ocean for potentially years at a time, should also be considered. Any number of events could lead to a massive loss of human life, but if the last few (see minimum viable population) most resilient humans are unlikely to also die off, then that particular human extinction scenario may not seem credible. "Existential risks" are risks that threaten the entire future of humanity, whether by causing human extinction or by otherwise permanently crippling human progress. Multiple scholars have argued based on the size of the "cosmic endowment" that because of the inconceivably large number of potential future lives that are at stake, even small reductions of existential risk have great value. In one of the earliest discussions of ethics of human extinction, Derek Parfit offers the following thought experiment: I believe that if we destroy mankind, as we now can, this outcome will be much worse than most people think. Compare three outcomes: (1) Peace. (2) A nuclear war that kills 99% of the world's existing population. (3) A nuclear war that kills 100%. (2) would be worse than (1), and (3) would be worse than (2). Which is the greater of these two differences? Most people believe that the greater difference is between (1) and (2). I believe that the difference between (2) and (3) is very much greater. — Derek Parfit The scale of what is lost in an existential catastrophe is determined by humanity's long-term potential – what humanity could expect to achieve if it survived

### Human extinction
. Paleobiologist Olev Vinn has suggested that humans presumably have a number of inherited behavior patterns (IBPs) that are not fine-tuned for conditions prevailing in technological civilization. Indeed, some IBPs may be highly incompatible with such conditions and have a high potential to induce self-destruction. These patterns may include responses of individuals seeking power over conspecifics in relation to harvesting and consuming energy. Nonetheless, there are ways to address the issue of inherited behavior patterns. Given the limitations of ordinary observation and modeling, expert elicitation is frequently used instead to obtain probability estimates. Humanity has a 95% probability of being extinct in 8,000,000 years, according to J. Richard Gott's formulation of the controversial doomsday argument, which argues that we have probably already lived through half the duration of human history. In 1996, John A. Leslie estimated a 30% risk over the next five centuries (equivalent to around 6% per century, on average). The Global Challenges Foundation's 2016 annual report estimates an annual probability of human extinction of at least 0.05% per year (equivalent to 5% per century, on average). As of July 29, 2025, Metaculus users estimate a 1% probability of human extinction by 2100. According to a 2020 study published in Scientific Reports, if deforestation and resource consumption continue at current rates, they could culminate in a "catastrophic collapse in human population" and possibly "an irreversible collapse of our civilization" in the next 20 to 40 years. According to the most optimistic scenario provided by the study, the chances that human civilization survives are smaller than 10%. To avoid this collapse, the study says, humanity should pass from a civilization dominated by the economy to a "cultural society" that "privileges the interest of the ecosystem above the individual interest of its components, but eventually in accordance with the overall communal interest." Nick Bostrom, a philosopher at the University of Oxford known for his work on existential risk, argues that it would be "misguided" to assume that the probability of near-term extinction is less than 25%, and that it will be "a tall order" for the human race to "get our precautions sufficiently right the first time", given that an existential risk provides no opportunity to learn from failure. Philosopher John A

Human extinction

. Leslie assigns a 70% chance of humanity surviving the next five centuries, based partly on the controversial philosophical doomsday argument that Leslie champions. Leslie's argument is somewhat frequentist, based on the observation that human extinction has never been observed, but requires subjective anthropic arguments. Leslie also discusses the anthropic survivorship bias (which he calls an "observational selection" effect on page 139) and states that the a priori certainty of observing an "undisastrous past" could make it difficult to argue that we must be safe because nothing terrible has yet occurred. He quotes Holger Bech Nielsen's formulation: "We do not even know if there should exist some extremely dangerous decay of say the proton which caused the eradication of the earth, because if it happens we would no longer be there to observe it and if it does not happen there is nothing to observe." Jean-Marc Salotti calculated the probability of human extinction caused by a giant asteroid impact. It is between 0.03 and 0.3 for the next billion years, if there is no colonization of other planets. According to that study, the most frightening object is a giant long-period comet with a warning time of a few years only and therefore no time for any intervention in space or settlement on the Moon or Mars. The probability of a giant comet impact in the next hundred years is 2.2×10−12. As the United Nations Office for Disaster Risk Reduction estimated in 2023, there is a 2 to 14% (median: 8%)[Unclear what the median represents in this context. Over what distribution is it calculated?] chance of an extinction-level event by 2100, but there was a 14 to 98% (median: 56%) chance of an extinction-level event by 2700.[clarification needed] Bill Gates told The Wall Street Journal in January 27, 2025 that he believes there is a 10–15% (median - 12.5%) chance of a natural pandemic hitting in the next four years, but he estimated that there was also a 65-97.5% (median - 81.25%) chance of a natural pandemic hitting in the next 26 years. On March 19, 2025, Henry Gee said that humanity will be extinct in the next 10,000 years

Human extinction

. To avoid it happening, he wanted all humanity to establish space colonies in the next 200-300 years. On September 11, 2025, Warp News estimated a 20% chance of global catastrophe and 6% chance of human extinction by 2100. They also estimated a 100% chance of global catastrophe and a 30% chance of human extinction by 2500. In November 13, 2024, American Enterprise Institute estimated a probability of nuclear war during the 21st century between 0% to 80% (median average – 40%). A 2023 article of The Economist estimated an 8% chance of Nuclear War causing global catastrophe and a 0.5625% chance of Nuclear War causing human extinction. In November 13, 2024, American Enterprise Institute estimated an annual probability of supervolcanic eruption around 0.0067% (0.67% per century on average). A 2008 survey by the Future of Humanity Institute estimated a 5% probability of extinction by super-intelligence by 2100. A 2016 survey of AI experts found a median estimate of 5% that human-level AI would cause an outcome that was "extremely bad (e.g. human extinction)". In 2019, the risk was lowered to 2%, but in 2022, it was increased back to 5%. In 2023, the risk doubled to 10%. In 2024, the risk increased to 15%. In 2020, Toby Ord estimates existential risk in the next century at "1 in 6" in his book The Precipice: Existential Risk and the Future of Humanity. He also estimated a "1 in 10" risk of extinction by unaligned AI within the next century. According to the July 10, 2023 article of The Economist, scientists estimated a 12% chance of AI-caused catastrophe and a 3% chance of AI-caused extinction by 2100. They also estimated a 100% chance of AI-caused catastrophe and a 25% chance of AI-caused extinction by 2833. On December 27, 2024, Geoffrey Hinton estimated a 10-20% (median average - 15%) probability of AI-caused extinction in the next 30 years

### Human extinction
Human extinction or omnicide is the end of the human species, either by population decline due to extraneous natural causes, such as an asteroid impact or large-scale volcanism, or via anthropogenic destruction (self-extinction). Some of the many possible contributors to anthropogenic hazard are climate change, global nuclear annihilation, biological warfare, weapons of mass destruction, and ecological collapse. Other scenarios center on emerging technologies, such as advanced artificial intelligence, biotechnology, or self-replicating nanobots. The scientific consensus is that there is a relatively low risk of near-term human extinction due to natural causes. The likelihood of human extinction through humankind's own activities, however, is a current area of research and debate.

Human extinction

Human extinction or omnicide is the end of the human species, either by population decline due to extraneous natural causes, such as an asteroid impact or large-scale volcanism, or via anthropogenic destruction (self-extinction). Some of the many possible contributors to anthropogenic hazard are climate change, global nuclear annihilation, biological warfare, weapons of mass destruction, and ecological collapse. Other scenarios center on emerging technologies, such as advanced artificial intelligence, biotechnology, or self-replicating nanobots. The scientific consensus is that there is a relatively low risk of near-term human extinction due to natural causes. The likelihood of human extinction through humankind's own activities, however, is a current area of research and debate. Before the 18th and 19th centuries, the possibility that humans or other organisms could become extinct was viewed with scepticism. It contradicted the principle of plenitude, a doctrine that all possible things exist. The principle traces back to Aristotle, and was an important tenet of Christian theology. Ancient philosophers such as Plato, Aristotle, and Lucretius wrote of the end of humankind only as part of a cycle of renewal. Marcion of Sinope was a proto-protestant who advocated for antinatalism that could lead to human extinction. Later philosophers such as Al-Ghazali, William of Ockham, and Gerolamo Cardano expanded the study of logic and probability and began wondering if abstract worlds existed, including a world without humans. Physicist Edmond Halley stated that the extinction of the human race may be beneficial to the future of the world. The notion that species can become extinct gained scientific acceptance during the Age of Enlightenment in the 17th and 18th centuries, and by 1800 Georges Cuvier had identified 23 extinct prehistoric species. The doctrine was further gradually bolstered by evidence from the natural sciences, particularly the discovery of fossil evidence of species that appeared to no longer exist, and the development of theories of evolution. In On the Origin of Species, Charles Darwin discussed the extinction of species as a natural process and a core component of natural selection. Notably, Darwin was skeptical of the possibility of sudden extinction, viewing it as a gradual process. He held that the abrupt disappearances of species from the fossil record were not evidence of catastrophic extinctions, but rather represented unrecognised gaps[clarification needed] in the record

Human extinction

. As the possibility of extinction became more widely established in the sciences, so did the prospect of human extinction. In the 19th century, human extinction became a popular topic in science (e.g., Thomas Robert Malthus's An Essay on the Principle of Population) and fiction (e.g., Jean-Baptiste Cousin de Grainville's The Last Man). In 1863, a few years after Darwin published On the Origin of Species, William King proposed that Neanderthals were an extinct species of the genus Homo. The Romantic authors and poets were particularly interested in the topic. Lord Byron wrote about the extinction of life on Earth in his 1816 poem "Darkness", and in 1824 envisaged humanity being threatened by a comet impact, and employing a missile system to defend against it. Mary Shelley's 1826 novel The Last Man is set in a world where humanity has been nearly destroyed by a mysterious plague. At the turn of the 20th century, Russian cosmism, a precursor to modern transhumanism, advocated avoiding humanity's extinction by colonizing space. The invention of the atomic bomb prompted a wave of discussion among scientists, intellectuals, and the public at large about the risk of human extinction. In a 1945 essay, Bertrand Russell wrote: The prospect for the human race is sombre beyond all precedent. Mankind are faced with a clear-cut alternative: either we shall all perish, or we shall have to acquire some slight degree of common sense. In 1950, Leo Szilard suggested it was technologically feasible to build a cobalt bomb that could render the planet unlivable. A 1950 Gallup poll found that 19% of Americans believed that another world war would mean "an end to mankind". Rachel Carson's 1962 book Silent Spring raised awareness of environmental catastrophe. In 1983, Brandon Carter proposed the Doomsday argument, which used Bayesian probability to predict the total number of humans that will ever exist. The discovery of "nuclear winter" in the early 1980s, a specific mechanism by which nuclear war could result in human extinction, again raised the issue to prominence

### Human extinction
Human extinction or omnicide is the end of the human species, either by population decline due to extraneous natural causes, such as an asteroid impact or large-scale volcanism, or via anthropogenic destruction (self-extinction). Some of the many possible contributors to anthropogenic hazard are climate change, global nuclear annihilation, biological warfare, weapons of mass destruction, and ecological collapse. Other scenarios center on emerging technologies, such as advanced artificial intelligence, biotechnology, or self-replicating nanobots. The scientific consensus is that there is a relatively low risk of near-term human extinction due to natural causes. The likelihood of human extinction through humankind's own activities, however, is a current area of research and debate. Before the 18th and 19th centuries, the possibility that humans or other organisms could become extinct was viewed with scepticism. It contradicted the principle of plenitude, a doctrine that all possible things exist. The principle traces back to Aristotle, and was an important tenet of Christian theology. Ancient philosophers such as Plato, Aristotle, and Lucretius wrote of the end of humankind only as part of a cycle of renewal. Marcion of Sinope was a proto-protestant who advocated for antinatalism that could lead to human extinction. Later philosophers such as Al-Ghazali, William of Ockham, and Gerolamo Cardano expanded the study of logic and probability and began wondering if abstract worlds existed, including a world without humans. Physicist Edmond Halley stated that the extinction of the human race may be beneficial to the future of the world. The notion that species can become extinct gained scientific acceptance during the Age of Enlightenment in the 17th and 18th centuries, and by 1800 Georges Cuvier had identified 23 extinct prehistoric species. The doctrine was further gradually bolstered by evidence from the natural sciences, particularly the discovery of fossil evidence of species that appeared to no longer exist, and the development of theories of evolution. In On the Origin of Species, Charles Darwin discussed the extinction of species as a natural process and a core component of natural selection. Notably, Darwin was skeptical of the possibility of sudden extinction, viewing it as a gradual process. He held that the abrupt disappearances of species from the fossil record were not evidence of catastrophic extinctions, but rather represented unrecognised gaps[clarification needed] in the record

Human extinction

. As the possibility of extinction became more widely established in the sciences, so did the prospect of human extinction. In the 19th century, human extinction became a popular topic in science (e.g., Thomas Robert Malthus's An Essay on the Principle of Population) and fiction (e.g., Jean-Baptiste Cousin de Grainville's The Last Man). In 1863, a few years after Darwin published On the Origin of Species, William King proposed that Neanderthals were an extinct species of the genus Homo. The Romantic authors and poets were particularly interested in the topic. Lord Byron wrote about the extinction of life on Earth in his 1816 poem "Darkness", and in 1824 envisaged humanity being threatened by a comet impact, and employing a missile system to defend against it. Mary Shelley's 1826 novel The Last Man is set in a world where humanity has been nearly destroyed by a mysterious plague. At the turn of the 20th century, Russian cosmism, a precursor to modern transhumanism, advocated avoiding humanity's extinction by colonizing space. The invention of the atomic bomb prompted a wave of discussion among scientists, intellectuals, and the public at large about the risk of human extinction. In a 1945 essay, Bertrand Russell wrote: The prospect for the human race is sombre beyond all precedent. Mankind are faced with a clear-cut alternative: either we shall all perish, or we shall have to acquire some slight degree of common sense. In 1950, Leo Szilard suggested it was technologically feasible to build a cobalt bomb that could render the planet unlivable. A 1950 Gallup poll found that 19% of Americans believed that another world war would mean "an end to mankind". Rachel Carson's 1962 book Silent Spring raised awareness of environmental catastrophe. In 1983, Brandon Carter proposed the Doomsday argument, which used Bayesian probability to predict the total number of humans that will ever exist. The discovery of "nuclear winter" in the early 1980s, a specific mechanism by which nuclear war could result in human extinction, again raised the issue to prominence

Human extinction

. Writing about these findings in 1983, Carl Sagan argued that measuring the severity of extinction solely in terms of those who die "conceals its full impact", and that nuclear war "imperils all of our descendants, for as long as there will be humans." John Leslie's 1996 book The End of the World was an academic treatment of the science and ethics of human extinction. In it, Leslie considered a range of threats to humanity and what they have in common. In 2003, British Astronomer Royal Sir Martin Rees published Our Final Hour, in which he argues that advances in certain technologies create new threats to the survival of humankind and that the 21st century may be a critical moment in history when humanity's fate is decided. Edited by Nick Bostrom and Milan M. Ćirković, Global Catastrophic Risks was published in 2008, a collection of essays from 26 academics on various global catastrophic and existential risks. Nicholas P. Money's 2019 book The Selfish Ape delves into the environmental consequences of overexploitation. Toby Ord's 2020 book The Precipice: Existential Risk and the Future of Humanity argues that preventing existential risks is one of the most important moral issues of our time. The book discusses, quantifies, and compares different existential risks, concluding that the greatest risks are presented by unaligned artificial intelligence and biotechnology. Lyle Lewis' 2024 book Racing to Extinction explores the roots of human extinction from an evolutionary biology perspective. Lewis argues that humanity treats unused natural resources as waste and is driving ecological destruction through overexploitation, habitat loss, and denial of environmental limits. He uses vivid examples, like the extinction of the passenger pigeon and the environmental cost of rice production, to show how interconnected and fragile ecosystems are. Potential anthropogenic causes of human extinction include global thermonuclear war, deployment of a highly effective biological weapon, ecological collapse, runaway artificial intelligence, runaway nanotechnology (such as a grey goo scenario), overpopulation and increased consumption causing resource depletion and a concomitant population crash, population decline by choosing to have fewer children, and displacement of naturally evolved humans by a new species produced by genetic engineering or technological augmentation. Natural and external extinction risks include high-fatality-rate pandemic, supervolcanic eruption, asteroid impact, nearby supernova or gamma-ray burst, or extreme solar flare. Humans (e.g

### Human extinction
. Leslie assigns a 70% chance of humanity surviving the next five centuries, based partly on the controversial philosophical doomsday argument that Leslie champions. Leslie's argument is somewhat frequentist, based on the observation that human extinction has never been observed, but requires subjective anthropic arguments. Leslie also discusses the anthropic survivorship bias (which he calls an "observational selection" effect on page 139) and states that the a priori certainty of observing an "undisastrous past" could make it difficult to argue that we must be safe because nothing terrible has yet occurred. He quotes Holger Bech Nielsen's formulation: "We do not even know if there should exist some extremely dangerous decay of say the proton which caused the eradication of the earth, because if it happens we would no longer be there to observe it and if it does not happen there is nothing to observe." Jean-Marc Salotti calculated the probability of human extinction caused by a giant asteroid impact. It is between 0.03 and 0.3 for the next billion years, if there is no colonization of other planets. According to that study, the most frightening object is a giant long-period comet with a warning time of a few years only and therefore no time for any intervention in space or settlement on the Moon or Mars. The probability of a giant comet impact in the next hundred years is 2.2×10−12. As the United Nations Office for Disaster Risk Reduction estimated in 2023, there is a 2 to 14% (median: 8%)[Unclear what the median represents in this context. Over what distribution is it calculated?] chance of an extinction-level event by 2100, but there was a 14 to 98% (median: 56%) chance of an extinction-level event by 2700.[clarification needed] Bill Gates told The Wall Street Journal in January 27, 2025 that he believes there is a 10–15% (median - 12.5%) chance of a natural pandemic hitting in the next four years, but he estimated that there was also a 65-97.5% (median - 81.25%) chance of a natural pandemic hitting in the next 26 years. On March 19, 2025, Henry Gee said that humanity will be extinct in the next 10,000 years

Human extinction

. To avoid it happening, he wanted all humanity to establish space colonies in the next 200-300 years. On September 11, 2025, Warp News estimated a 20% chance of global catastrophe and 6% chance of human extinction by 2100. They also estimated a 100% chance of global catastrophe and a 30% chance of human extinction by 2500. In November 13, 2024, American Enterprise Institute estimated a probability of nuclear war during the 21st century between 0% to 80% (median average – 40%). A 2023 article of The Economist estimated an 8% chance of Nuclear War causing global catastrophe and a 0.5625% chance of Nuclear War causing human extinction. In November 13, 2024, American Enterprise Institute estimated an annual probability of supervolcanic eruption around 0.0067% (0.67% per century on average). A 2008 survey by the Future of Humanity Institute estimated a 5% probability of extinction by super-intelligence by 2100. A 2016 survey of AI experts found a median estimate of 5% that human-level AI would cause an outcome that was "extremely bad (e.g. human extinction)". In 2019, the risk was lowered to 2%, but in 2022, it was increased back to 5%. In 2023, the risk doubled to 10%. In 2024, the risk increased to 15%. In 2020, Toby Ord estimates existential risk in the next century at "1 in 6" in his book The Precipice: Existential Risk and the Future of Humanity. He also estimated a "1 in 10" risk of extinction by unaligned AI within the next century. According to the July 10, 2023 article of The Economist, scientists estimated a 12% chance of AI-caused catastrophe and a 3% chance of AI-caused extinction by 2100. They also estimated a 100% chance of AI-caused catastrophe and a 25% chance of AI-caused extinction by 2833. On December 27, 2024, Geoffrey Hinton estimated a 10-20% (median average - 15%) probability of AI-caused extinction in the next 30 years

Human extinction

. He also estimated a 50-100% (median average - 75%) probability of AI-caused extinction in the next 150 years. On May 6, 2025, Scientific American estimated a 0-10% (median average - 5%) probability of an AI-caused extinction by 2100. On August 1, 2025, Holly Elmore estimated a 15-20% (median average - 17.5%) probability of an AI-caused extinction in the next 1-10 years (median average - 5.5 years). She also estimated a 75-100% (median average - 87.5%) probability of a AI-caused extinction in the next 5-50 years (median average-27.5 years). On November 10, 2025, Elon Musk estimated the probability of AI-driven human extinction at 20%, while others — including Bengio’s colleagues — placed the risk anywhere between 10% and 90% (median average - 50%), in other words, Elon Musk and Yoshua Bengio's colleagues estimated a 20-50% (median average - 35%) probability of an AI-caused extinction. In a 2010 interview with The Australian, the late Australian scientist Frank Fenner predicted the extinction of the human race within a century, primarily as the result of human overpopulation, environmental degradation and climate change. There are several economists who have discussed the importance of global catastrophic risks. For example, Martin Weitzman argues that most of the expected economic damage from climate change may come from the small chance that warming greatly exceeds the mid-range expectations, resulting in catastrophic damage. Richard Posner has argued that humanity is doing far too little, in general, about small, hard-to-estimate risks of large-scale catastrophes. Although existential risks are less manageable by individuals than, for example, health risks, according to Ken Olum, Joshua Knobe, and Alexander Vilenkin, the possibility of human extinction does have practical implications. For instance, if the "universal" doomsday argument is accepted, it changes the most likely source of disasters, and hence the most efficient means of preventing them. They write: "...you should be more concerned that a large number of asteroids have not yet been detected than about the particular orbit of each one

### Human extinction
Human extinction or omnicide is the end of the human species, either by population decline due to extraneous natural causes, such as an asteroid impact or large-scale volcanism, or via anthropogenic destruction (self-extinction). Some of the many possible contributors to anthropogenic hazard are climate change, global nuclear annihilation, biological warfare, weapons of mass destruction, and ecological collapse. Other scenarios center on emerging technologies, such as advanced artificial intelligence, biotechnology, or self-replicating nanobots. The scientific consensus is that there is a relatively low risk of near-term human extinction due to natural causes. The likelihood of human extinction through humankind's own activities, however, is a current area of research and debate.

Human extinction

Human extinction or omnicide is the end of the human species, either by population decline due to extraneous natural causes, such as an asteroid impact or large-scale volcanism, or via anthropogenic destruction (self-extinction). Some of the many possible contributors to anthropogenic hazard are climate change, global nuclear annihilation, biological warfare, weapons of mass destruction, and ecological collapse. Other scenarios center on emerging technologies, such as advanced artificial intelligence, biotechnology, or self-replicating nanobots. The scientific consensus is that there is a relatively low risk of near-term human extinction due to natural causes. The likelihood of human extinction through humankind's own activities, however, is a current area of research and debate. Before the 18th and 19th centuries, the possibility that humans or other organisms could become extinct was viewed with scepticism. It contradicted the principle of plenitude, a doctrine that all possible things exist. The principle traces back to Aristotle, and was an important tenet of Christian theology. Ancient philosophers such as Plato, Aristotle, and Lucretius wrote of the end of humankind only as part of a cycle of renewal. Marcion of Sinope was a proto-protestant who advocated for antinatalism that could lead to human extinction. Later philosophers such as Al-Ghazali, William of Ockham, and Gerolamo Cardano expanded the study of logic and probability and began wondering if abstract worlds existed, including a world without humans. Physicist Edmond Halley stated that the extinction of the human race may be beneficial to the future of the world. The notion that species can become extinct gained scientific acceptance during the Age of Enlightenment in the 17th and 18th centuries, and by 1800 Georges Cuvier had identified 23 extinct prehistoric species. The doctrine was further gradually bolstered by evidence from the natural sciences, particularly the discovery of fossil evidence of species that appeared to no longer exist, and the development of theories of evolution. In On the Origin of Species, Charles Darwin discussed the extinction of species as a natural process and a core component of natural selection. Notably, Darwin was skeptical of the possibility of sudden extinction, viewing it as a gradual process. He held that the abrupt disappearances of species from the fossil record were not evidence of catastrophic extinctions, but rather represented unrecognised gaps[clarification needed] in the record

### April–June 2020 in science
. ESPRESSO data confirms the presence of Proxima b and shows that it has a minimum mass of ca. 1.17 Earth masses and is located in the habitable zone of its star. 26 May Astronomers report the detection of several very powerful explosions, newly classified as Fast blue optical transients (FBOTs), similar in ways to the much less energetic FBOT SN 2018cow observed in 2018. Simulations by Imperial College London reveal that the Chicxulub impactor produced a "worst case" scenario in terms of lethality for the dinosaurs, arriving from the north-east at a 60° angle, which maximised the amount of gases and debris thrown up into Earth's atmosphere. Scientists report in a preprint paper, published in a journal in June, that all of ʻOumuamua's observed properties can be explained if it contained a significant fraction of molecular hydrogen ice. They suggest it had formed in an interstellar cloud where stars are born and "sat" relatively motionless with its ice getting worn away as it approached the Sun, explaining its shape. Researchers suggest that a solution to what they consider to be the core of the space debris problem may be an international agreement to charge operators "orbital-use fees" for every satellite put into orbit and that this could more than quadruple the long-run value of the satellite industry by 2040. 27 May Astronomers report that classical novae explosions are the galactic producers of the element lithium. A study shows that social networks can function poorly as pathways for inconvenient truths, that the interplay between communication and action during disasters may depend on the structure of social networks, that communication networks suppress necessary "evacuations" in test-scenarios because of false reassurances when compared to groups of isolated individuals and that larger networks with a smaller proportion of informed subjects can suffer more damage due to human-caused misinformation. 29 May – Scientists publish a study which illustrates major regional variations in the shares of Mesolithic hunter-gatherer to Neolithic farmer genomic ancestry, highlighting the complexity of the biological interactions during the Neolithic expansion in Europe. 30 May – SpaceX successfully launches two NASA astronauts into orbit on a Crew Dragon spacecraft from Pad 39A of the Kennedy Space Center in Florida, the first crewed spacecraft to take off from U.S. soil since 2011

April–June 2020 in science

. Marine extinction intensity during Phanerozoic % Millions of years ago (H) K–Pg Tr–J P–Tr Cap Late D O–S 1 June Astronomers report narrowing down the source of fast radio bursts (FRBs), which may now plausibly include "compact-object mergers and magnetars arising from normal core collapse supernovae". The existence of quark cores in neutron stars is confirmed by Finnish researchers. Geologists report two newly identified supervolcano eruptions associated with the Yellowstone hotspot track, including the region's largest and most cataclysmic event – the Grey's Landing super-eruption – which had a volume of ≥2800 km3 and occurred around 8.72 Ma. According to the study the Yellowstone hotspot may be waning, with another eruption of this scale not likely up to around 900,000 AD. Researchers studying corvids report that extended parenting and extended childhood is crucial for the evolution of cognition and is having profound consequences for learning and intelligence. These may create longer developmental periods in which life-history is combined with social and ecological conditions such as via continuous exposure to role models that are relatively tolerant of the children as well as continuous opportunities for learning. Earlier research on primates showed that across species relative brain size covaries with cognitive skills and that adaptations that compensate developmental and energetic costs of large brains are critical for their evolution. Findings of studying the spin direction of more than 200,000 spiral galaxies presented at the 236th American Astronomical Society meeting may suggest that the universe could have a defined structure and that the early universe could have been spinning. According to the researcher spiral galaxies in different regions of spacetime have been found to relate through their spin-directions and even though the asymmetry of spin-directions is just over 2%, the probability to have such asymmetry by chance is less than 1 to 4 billion.[additional citation(s) needed] Researchers publish a study using data on vertebrates on the brink to extinction and on vertebrates that recently became extinct, in which they conclude that a human-caused potential sixth mass extinction, which was claimed to be emerging by researchers of the study in 2015, is likely accelerating and suggest a number of reasons for that including extinctions causing further extinctions. They reemphasize "extreme urgency of taking much-expanded worldwide actions"

April–June 2020 in science

. 2 June – A study investigating the emergence of life on Earth and possibly other locations demonstrates a continuous chemical reaction network of simple organic and inorganic feedstocks that, in water and under high-energy radiation, generates compounds proposed to be precursors for early RNA, modelling how they may emerge spontaneously from a simple reagents mixture under conditions of early Earth through natural geochemistry. 3 June The discovery of the oldest and largest structure in the Maya region, a 3,000-year-old pyramid-topped platform Aguada Fénix, with LiDAR technology is reported. According to the researchers the discovery suggests the importance of communal work, as with early ceremonial complexes, in the initial development of Maya civilization. Researchers report that mitochondrial genetic divergence could be used to predict the reproductive compatibility of mammalian hybrid offspring and that ancient anatomically modern humans (AMH), Neanderthals and Denisovans were genetically closer than polar bears and brown bears (1.6% divergence for Neanderthals and AMH and 2.4% for the bears) and, like the bears, were able to easily produce healthy hybrids. Researchers show that urban red foxes from London and surrounding boroughs are divergent in skull traits, similar to domesticated dogs, as they adapt to their city environment with patterns of skull divergence between urban and rural habitats matching the description of morphological changes that can occur during domestication. Scientists report that a randomized, double-blind, placebo-controlled trial found evidence that the drug hydroxychloroquine, controversially promoted by President of the United States Donald Trump as a potential treatment in mid-March, does not effectively protect people from COVID-19 administered within 4 days after exposure. Other researchers are continuing to explore whether hydroxychloroquine might prevent infections as pre-exposure prophylaxis. 4 June Astronomers report that Kepler-160, a Sun-like star already known to host two planets, likely has a rocky third planet with orbit and light levels very similar to Earth

### Our Final Hour
Our Final Hour is a 2003 book by the British Astronomer Royal Sir Martin Rees. The full title of the book is Our Final Hour: A Scientist's Warning: How Terror, Error, and Environmental Disaster Threaten Humankind's Future In This Century—On Earth and Beyond. It was published in the United Kingdom under the title Our Final Century: Will the Human Race Survive the Twenty-first Century?. The premise of the book is that the Earth and human survival are in far greater danger from the potential effects of modern technology than is commonly realised, and that the 21st century may be a critical moment in history when humanity's fate is decided. Rees discusses a range of existential risks confronting humanity, and estimates that the probability of extinction before 2100 CE is around 50 percent, based on the possibility of malign or accidental release of destructive technology.

Our Final Hour

Our Final Hour is a 2003 book by the British Astronomer Royal Sir Martin Rees. The full title of the book is Our Final Hour: A Scientist's Warning: How Terror, Error, and Environmental Disaster Threaten Humankind's Future In This Century—On Earth and Beyond. It was published in the United Kingdom under the title Our Final Century: Will the Human Race Survive the Twenty-first Century?. The premise of the book is that the Earth and human survival are in far greater danger from the potential effects of modern technology than is commonly realised, and that the 21st century may be a critical moment in history when humanity's fate is decided. Rees discusses a range of existential risks confronting humanity, and estimates that the probability of extinction before 2100 CE is around 50 percent, based on the possibility of malign or accidental release of destructive technology. In Our Final Hour, Rees explores various risks of human extinction and their likelihood, notably those caused by the unchecked consequences of new technologies (such as nanotechnology or machine superintelligence), uncontrolled scientific experimentation, terrorist or fundamentalist violence, or destruction of the biosphere. He suggests that humanity's chances of survival could be improved by expanding into space. In order to avoid human extinction, Rees advocates for worldwide regulation of some types of scientific research, and control of open access to such research. Rees has long been active in disarmament campaigns, and although he now sees nuclear warfare as a less probable cause of extinction, he advocates arms control as much as control of science and technology (see also World government). More concerning to him now is the possibility of major bioterrorist attacks, as evidenced by his outstanding bet (registered with the Long Bet Project) that such events will occur within the next twenty years. He states that, in the 1990s, Aum Shinrikyo tried unsuccessfully to obtain an Ebola virus sample, which they could now create in their Mount Fuji lab, using ingredients and instructions from the Internet. Rees advocates free market-based options for space exploration and survival through colonization, and believes that the wealthy will push back the frontiers of space

Our Final Hour

. Sir Martin Rees, Our Final Hour: A Scientist's Warning: How Terror, Error, and Environmental Disaster Threaten Humankind's Future In This Century—On Earth and Beyond (2003), Basic Books, hardcover: ISBN 0-465-06862-6, 2004 paperback: ISBN 0-465-06863-4 Sir Martin Rees, Our Final Century?: Will the Human Race Survive the Twenty-first Century? (2003) (UK) William Heinemann, hardcover: ISBN 0-434-00809-5, 2004 Arrow paperback: ISBN 0-09-943686-8 Hattenstone, Simon (2003-04-24). "The end of the world as we know it (maybe)". The Guardian. ISSN 0261-3077. Retrieved 2024-10-13. "Will humans wipe out humanity?". The Economist. ISSN 0013-0613. Retrieved 2024-10-13. Illing, Sean (2018-10-18). "Cosmologist Martin Rees gives humanity a 50-50 chance of surviving the 21st century". Vox. Retrieved 2024-10-13. Overbye, Dennis (May 18, 2003). "It Was Fun While It Lasted". The New York Times. Rees, Martin J. (2003). "What Could a Bioattack Currently Achieve?". Our final hour: a scientist's warning: how terror, error, and environmental disaster threaten humankind's future in this century on earth and beyond. New York: Basic Books. ISBN 978-0-465-06862-3. Rees's bet on a major bioterrorist attack at longbet.com "Martin Rees asks: Is this our final century?" (Video of talk from 2005)


