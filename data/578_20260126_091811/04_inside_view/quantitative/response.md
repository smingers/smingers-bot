# Quantitative Analysis: Human Extinction Before 2100

## Step 1: Source Analysis

**Recency and Quality:**
- Research synthesis dated 2026-01-26 (current)
- Sources include Cambridge Existential Risk Center, Potsdam Institute, Berkeley Earth, Carbon Brief
- Mix of peer-reviewed research and expert assessments
- Climate data through 2025 is most recent quantitative evidence

**Credibility Assessment:**
- High credibility: Academic institutions (Cambridge, Potsdam), established climate research organizations
- Moderate credibility: Expert probability estimates vary widely (AI risk: 10-20% civilizational collapse)
- Potential bias: Existential risk researchers may overweight catastrophic scenarios (selection bias)

**Base Rate Integration:**
The 0.5% base rate appears derived from biological/historical precedents (mammalian extinction rates, Homo genus survival). Current evidence on anthropogenic risks (nuclear, AI, engineered pandemics) represents **novel information** not fully captured in biological base rates, as these are <100-year-old phenomena.

## Step 2: Evidence Classification

### STRONG Evidence

**S1: Nuclear Arsenal Quantification**
- ~12,500 nuclear warheads exist globally (as of 2024-2026)
- Modeling shows 100-warhead exchange → ~2 billion deaths within 2 years
- Full-scale exchange creates extinction-level risk via nuclear winter
- *Relevance*: Provides concrete probability pathway with known trigger mechanisms

**S2: Historical Temperature Anomalies**
- 2023-2025: Hottest on record
- Berkeley Earth: <1% probability natural variability explains trend
- Ocean warming: +0.49°C above baseline, +23±8 ZJ heat content increase
- *Relevance*: Quantifies climate acceleration, though not directly extinction-level

**S3: Human Adaptive Capacity Data**
- Climate-related mortality reduced >90% since 1920
- Demonstrates quantifiable resilience trend
- *Relevance*: Counter-evidence to extinction scenarios

### MODERATE Evidence

**M1: AI Risk Expert Estimates**
- 10-20% civilizational collapse probability by 2100
- Wide variance in expert opinions
- *Relevance*: Novel risk category, but low consensus on quantification

**M2: Biotechnology Accessibility**
- Barriers to engineered pathogens decreasing
- No quantified probability estimates provided
- *Relevance*: Emerging threat vector, but speculative timeline

**M3: Space Colonization Feasibility**
- Hawking: feasible within decades
- No population established yet (as of 2026)
- *Relevance*: Potential extinction hedge, but unproven at scale

### WEAK Evidence

**W1: Doomsday Clock Positioning**
- Symbolic metric, not quantitative risk measure
- Subject to political/advocacy framing

**W2: Tipping Point Speculation**
- Amazon dieback, permafrost thaw mentioned
- "Timelines uncertain beyond 2100" = outside forecast window

## Step 3: Direction of Update

**S1 (Nuclear Risk): UP by +0.3-0.5%**
- Base rate doesn't account for concentrated risk from 12,500 warheads
- However: 74 years of non-use (1945-2019), deterrence theory, arms control treaties
- Net: Modest upward adjustment for tail risk that didn't exist in mammalian base rates

**S2 (Climate Data): NEUTRAL to +0.05%**
- Research explicitly states "not extinction-level threat alone"
- Functions as risk multiplier, not direct extinction mechanism
- Minimal direct adjustment, but increases nuclear war probability slightly

**S3 (Adaptive Capacity): DOWN by -0.1%**
- 90% mortality reduction demonstrates quantifiable resilience
- Suggests base rate may overweight historical vulnerability
- Small downward adjustment

**M1 (AI Risk): UP by +0.2%**
- 10-20% civilizational collapse ≠ extinction, but correlated
- Novel risk not in biological base rates
- Conservative interpretation: ~1-2% of collapse scenarios → extinction
- 15% (midpoint) × 10% (extinction given collapse) = 1.5% standalone risk
- But: high uncertainty, limited track record → weight at ~15% confidence
- Contribution: ~0.2%

**M2 (Biotech Risk): UP by +0.1%**
- Qualitative evidence of increasing accessibility
- No quantified probabilities; historical pandemics (even Spanish Flu) didn't cause extinction
- Minimal adjustment given lack of data

**M3 (Space Colonization): DOWN by -0.05%**
- Theoretical hedge but no operational backup by 2100
- Negligible adjustment given uncertainty

## Step 4: Integration

**Starting Point:** 0.5%

**Adjustments:**
1. Nuclear risk (novel anthropogenic threat): +0.4%
2. AI risk (novel, quantified by experts): +0.2%
3. Biotech risk (emerging, low quantification): +0.1%
4. Climate as risk multiplier: +0.05%
5. Demonstrated adaptive capacity: -0.1%
6. Other factors (space, governance improvements): -0.05%

**Cumulative Adjustment:** +0.6%

**Preliminary Estimate:** 1.1%

## Step 5: Sanity Checks

**1. Extremity Check (1.1% is low but not extreme):**
- For me to be wrong (underestimate): Multiple catastrophic events would need to cascade (e.g., nuclear war → bioengineered pandemic → climate collapse), AND human resilience would need to completely fail, AND no refugia populations survive
- For me to be wrong (overestimate): Current risk assessments from existential risk community are systematically biased upward

**2. Base Rate Anchor Justification:**
- 2.2× increase from base rate (0.5% → 1.1%)
- Justified by: (a) anthropogenic risks are fundamentally different from natural extinction processes, (b) concentration of destructive capability is unprecedented, (c) 74-year timeframe is too short to establish reliable base rates for nuclear/AI risks

**3. Update Magnitude Proportionality:**
- Largest update (+0.4%) for nuclear risk has strongest quantitative backing (warhead counts, modeling)
- AI risk (+0.2%) weighted lower due to expert disagreement and novelty
- Climate minimal direct impact aligns with research stating "not extinction-level alone"

**4. Regression to Mean:**
- Expert estimates of AI risk (10-20% civilizational collapse) may be inflated due to:
  - Availability bias (recent AI progress highly salient)
  - Expert domain focus (existential risk researchers)
- My adjustment applies only 15% confidence weight to these estimates
- Conservative interpretation: most "civilizational collapse" scenarios ≠ total extinction

## Step 6: Final Reasoning

As a quantitative analyst, I'm anchoring to the biological base rate of 0.5% but adjusting upward for anthropogenic risks that represent categorically new extinction pathways absent from the reference classes (mammalian species, Homo genus survival).

**Key Quantitative Insights:**

1. **Nuclear Risk Quantification**: The existence of ~12,500 warheads with modeled extinction pathways (nuclear winter scenarios) represents a concrete, quantifiable risk. However, 74 years of non-use, mutual deterrence, and arms control treaties suggest probability of full-scale exchange remains low (<5% over 74 years). Conservatively: ~0.4% additional extinction risk by 2100.

2. **AI Risk Uncertainty**: Expert estimates of 10-20% civilizational collapse are highly uncertain and represent upper bounds. Converting to extinction probability requires assuming: (a) collapse occurs, (b) collapse is total rather than regional, (c) no recovery occurs. My calculation: 15% (midpoint collapse) × 10% (extinction given collapse) × 15% (confidence in estimates) ≈ 0.2% contribution.

3. **Climate as Multiplier, Not Direct Cause**: Berkeley Earth data showing <1% natural probability for current warming confirms anthropogenic acceleration, but research consensus is clear: "not extinction-level threat alone." Primary effect is increasing probability of conflict/nuclear use, already captured in nuclear risk adjustment.

4. **Resilience Data**: The 90% reduction in climate-related mortality since 1920 provides quantitative evidence of improving adaptive capacity, partially offsetting upward adjustments.

5. **Timeframe Considerations**: 74 years (2026-2100) is relatively short for extinction-level events. Most biological extinctions occur over millennia. The concentration of risk in this window is driven by rapid technological change (AI, biotech) and existing arsenals (nuclear), not natural processes.

**Limitations of Analysis:**
- Tail risk probabilities are inherently difficult to quantify
- Limited historical precedent for anthropogenic extinction scenarios
- Expert estimates show wide variance (potential for both over- and under-estimation)
- Interaction effects between risks (e.g., AI-enabled bioweapons) not fully modeled

**Final Calculation:**
Base rate (0.5%) + Nuclear risk (0.4%) + AI risk (0.2%) + Biotech (0.1%) + Climate multiplier (0.05%) - Adaptive capacity (0.1%) - Governance/other (0.05%) = **1.1%**

This represents a 120% increase from the base rate, justified by novel anthropogenic risks with quantifiable mechanisms absent from biological reference classes.

---

**Evidence Summary:**
- **Strong evidence pointing UP:** Nuclear arsenal quantification (12,500 warheads, modeled extinction pathways), Historical temperature anomalies confirming anthropogenic acceleration
- **Strong evidence pointing DOWN:** Human adaptive capacity (90% mortality reduction since 1920)
- **Net direction:** UP (anthropogenic risks outweigh demonstrated resilience for tail-risk scenarios)

**Adjustment Calculation:**
- Base rate: 0.5%
- Total adjustment: +0.6%
- Final estimate: 1.1%

**Confidence in Adjustment:** 6/10

(Moderate confidence due to: high-quality quantitative data on nuclear/climate risks, but substantial uncertainty in AI/biotech probability estimates and interaction effects)

**Probability: 1.1%**